{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "from collections import deque\n",
    "import json\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_dir = 'results/toy/'\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from cbpy import net, plot, utils, dataset, train\n",
    "except:\n",
    "    import sys\n",
    "    sys.path.append('../')\n",
    "    from cbpy import net, plot, utils, dataset, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_toy(toy_name,\n",
    "            train_params,\n",
    "            model_str,\n",
    "            seed=1,\n",
    "            onehot=False,\n",
    "            act_layer=nn.ReLU(),\n",
    "            init_mode=None,\n",
    "            plot_n_weight=[4, 4],\n",
    "            save_best_loss_model=False,\n",
    "            result_dir=None,\n",
    "            record_weight=False,\n",
    "            whole_weight=False,\n",
    "            save_result=True):\n",
    "    \n",
    "    zs = np.repeat(np.asarray(train_params['zs']), 2)\n",
    "    cbp_epoch = train_params['cbp_epoch']\n",
    "    max_epoch = train_params['max_epoch']\n",
    "    cbp_lr = train_params['cbp_lr']\n",
    "    bp_lr = train_params['bp_lr']\n",
    "    beta = train_params['beta']\n",
    "    record_acc = train_params['record_acc']\n",
    "\n",
    "    utils.set_random_seed(seed)\n",
    "    trainloader = dataset.create_toy_dataloader(toy_name)\n",
    "    loss_func = nn.MSELoss() if onehot else nn.CrossEntropyLoss()\n",
    "    in_D, hid_D, out_D = [int(n) for n in model_str.split('-')]\n",
    "    model = net.MLPS([in_D, hid_D, out_D], act_layer=act_layer, init_mode=init_mode)\n",
    "\n",
    "    algo = 'CBP' if cbp_epoch > 0 else 'BP'\n",
    "    loss_func_str = 'MSE' if onehot else 'CE'\n",
    "    model_str = '-'.join([str(i) for i in [in_D, hid_D, out_D]])\n",
    "    seed_str = str(seed)\n",
    "    init_str = str(init_mode)\n",
    "    if isinstance(act_layer, nn.ReLU):\n",
    "        act_str = 'relu'\n",
    "    elif isinstance(act_layer, nn.Sigmoid):\n",
    "        act_str = 'sig'\n",
    "    else:\n",
    "        raise ValueError(f'Unrecognized act_layer: {act_layer}, must be ReLU or Sigmoid')\n",
    "\n",
    "    if result_dir is None:\n",
    "        result_dir = f'results/toy/{toy_name}'\n",
    "\n",
    "    logdir = f'{result_dir}/{model_str}/{algo}_{loss_func_str}_{act_str}_init{init_str}_seed{seed_str}/'\n",
    "    if not os.path.exists(logdir):\n",
    "        tl_list, ta_list, ws_list, os_list = train.train_with_chaos(\n",
    "            model,\n",
    "            trainloader,\n",
    "            trainloader,\n",
    "            loss_func,\n",
    "            zs=zs,\n",
    "            cbp_epoch=cbp_epoch,\n",
    "            max_epoch=max_epoch,\n",
    "            cbp_lr=cbp_lr,\n",
    "            bp_lr=bp_lr,\n",
    "            beta=beta,\n",
    "            record_weight=record_weight,\n",
    "            logdir=logdir,\n",
    "            record_acc=record_acc,\n",
    "            onehot=onehot,\n",
    "            save_best_loss_model=save_best_loss_model,\n",
    "            whole_weight=whole_weight\n",
    "        )\n",
    "\n",
    "        if not save_result:\n",
    "            logdir = None\n",
    "\n",
    "        if record_weight:\n",
    "            if whole_weight:\n",
    "                ws = np.array([w['model.0.weight'].flatten() for w in ws_list])\n",
    "                ws2 = np.array([w['model.1.weight'].flatten() for w in ws_list])\n",
    "            else:\n",
    "                ws = np.array([w[0].flatten() for w in ws_list])\n",
    "                ws2 = np.array([w[1].flatten() for w in ws_list])\n",
    "\n",
    "            n1 = min(ws.shape[1], plot_n_weight[0])\n",
    "            n2 = min(ws2.shape[1], plot_n_weight[1])\n",
    "            plot.plot_w_traj(ws, first=n1, save_prefix=logdir, suffix='fc1_weight',\n",
    "                             suptitle=f'{algo} layer1 weight')\n",
    "            plot.plot_w_traj(ws2, first=n2, save_prefix=logdir, suffix='fc2_weight',\n",
    "                             suptitle=f'{algo} layer2 weight')\n",
    "\n",
    "        plot.plot_loss_acc(tl_list, ta_list, log_scale=True, save_prefix=logdir,\n",
    "                           acc_train=True, suptitle=f'{algo} loss and acc')\n",
    "\n",
    "        if logdir is not None:\n",
    "            np.savetxt(logdir + 'loss.txt', np.asarray(tl_list))\n",
    "            np.savetxt(logdir + 'acc.txt', np.asarray(ta_list))\n",
    "\n",
    "            result = [algo, loss_func_str, model_str, seed_str, init_str, act_str,\n",
    "                      min(tl_list), tl_list[-1], max(ta_list), ta_list[-1]]\n",
    "            np.savetxt(logdir + 'result.txt', np.asarray(result).reshape(1, -1), fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_toy_params():\n",
    "    default_toy_params = {\n",
    "        'digits': {\n",
    "            'BP': {\n",
    "                'zs': None,\n",
    "                'cbp_epoch': 0,\n",
    "                'max_epoch': 1000,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.99,\n",
    "                'record_acc': [0.96, 0.98]\n",
    "            },\n",
    "            'CBP': {\n",
    "                'zs': [3., 1.],\n",
    "                'cbp_epoch': 150,\n",
    "                'max_epoch': 1000,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.99,\n",
    "                'record_acc': [0.96, 0.98]}\n",
    "        },\n",
    "        'wine': {\n",
    "            'BP': {\n",
    "                'zs': None,\n",
    "                'cbp_epoch': 0,\n",
    "                'max_epoch': 1000,\n",
    "                'cbp_lr': 0.2,\n",
    "                'bp_lr': 0.2,\n",
    "                'beta': 0.99,\n",
    "                'record_acc': [0.98, 1.]\n",
    "            },\n",
    "            'CBP': {\n",
    "                'zs': [3., 1.],\n",
    "                'cbp_epoch': 100,\n",
    "                'max_epoch': 1000,\n",
    "                'cbp_lr': 0.2,\n",
    "                'bp_lr': 0.2,\n",
    "                'beta': 0.99,\n",
    "                'record_acc': [0.98, 1.]}\n",
    "        },\n",
    "        'twonorm': {\n",
    "            'BP': {\n",
    "                'zs': None,\n",
    "                'cbp_epoch': 0,\n",
    "                'max_epoch': 300,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.98,\n",
    "                'record_acc': [0.95, 0.97]\n",
    "            },\n",
    "            'CBP': {\n",
    "                'zs': [5., 1.],\n",
    "                'cbp_epoch': 100,\n",
    "                'max_epoch': 300,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.98,\n",
    "                'record_acc': [0.95, 0.97]}\n",
    "        },\n",
    "        'breast': {\n",
    "            'BP': {\n",
    "                'zs': None,\n",
    "                'cbp_epoch': 0,\n",
    "                'max_epoch': 2000,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.96, 0.97]\n",
    "            },\n",
    "            'CBP': {\n",
    "                'zs': [9., 3.],\n",
    "                'cbp_epoch': 200,\n",
    "                'max_epoch': 2000,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.96, 0.97]}\n",
    "        },\n",
    "        'blood': {\n",
    "            'BP': {\n",
    "                'zs': None,\n",
    "                'cbp_epoch': 0,\n",
    "                'max_epoch': 2000,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.77, 0.78]\n",
    "            },\n",
    "            'CBP': {\n",
    "                'zs': [12., 2.],\n",
    "                'cbp_epoch': 200,\n",
    "                'max_epoch': 2000,\n",
    "                'cbp_lr': 0.1,\n",
    "                'bp_lr': 0.1,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.77, 0.78]}\n",
    "        },\n",
    "        'titanic': {\n",
    "            'BP': {\n",
    "                'zs': None,\n",
    "                'cbp_epoch': 0,\n",
    "                'max_epoch': 2000,\n",
    "                'cbp_lr': 0.2,\n",
    "                'bp_lr': 0.2,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.78, 0.79]\n",
    "            },\n",
    "            'CBP': {\n",
    "                'zs': [6., 3.],\n",
    "                'cbp_epoch': 200,\n",
    "                'max_epoch': 2000,\n",
    "                'cbp_lr': 0.2,\n",
    "                'bp_lr': 0.2,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.78, 0.79]}\n",
    "        },\n",
    "        'iris': {\n",
    "            'BP': {\n",
    "                'zs': None,\n",
    "                'cbp_epoch': 0,\n",
    "                'max_epoch': 3000,\n",
    "                'cbp_lr': 0.5,\n",
    "                'bp_lr': 0.5,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.98, 1.]\n",
    "            },\n",
    "            'CBP': {\n",
    "                'zs': [9., 3.],\n",
    "                'cbp_epoch': 200,\n",
    "                'max_epoch': 3000,\n",
    "                'cbp_lr': 0.5,\n",
    "                'bp_lr': 0.5,\n",
    "                'beta': 0.995,\n",
    "                'record_acc': [0.98, 1.]}\n",
    "        }\n",
    "    }\n",
    "    return default_toy_params\n",
    "\n",
    "\n",
    "def dump_default_toy_params(toy_params=None,\n",
    "                            json_file=\"toy_params.json\"):\n",
    "    if toy_params is None:\n",
    "        toy_params = get_default_toy_params()\n",
    "\n",
    "    with open(json_file, \"w\") as f:\n",
    "        f.write(json.dumps(toy_params, ensure_ascii=False,\n",
    "                           indent=4, separators=(',', ':')))\n",
    "\n",
    "\n",
    "def get_default_plot_params(name):\n",
    "    if name == 'digits':\n",
    "        acc1, acc2 = 96, 98\n",
    "        max_y = 30\n",
    "        loss_lim = [.02, .11]\n",
    "        acc_lim = [.975, 1.]\n",
    "    elif name == 'wine':\n",
    "        acc1, acc2 = 98, 100\n",
    "        max_y = 4\n",
    "        loss_lim = [.004, .018]\n",
    "        acc_lim = [.9, 1.01]\n",
    "    elif name == 'twonorm':\n",
    "        acc1, acc2 = 95, 97\n",
    "        max_y = 40\n",
    "        loss_lim = [.1, .5]\n",
    "        acc_lim = [.95, .98]\n",
    "    elif name == 'breast':\n",
    "        acc1, acc2 = 96, 97\n",
    "        max_y = 20\n",
    "        loss_lim = [.085, .105]\n",
    "        acc_lim = [.96, .975]\n",
    "    elif name == 'blood':\n",
    "        acc1, acc2 = 77, 78\n",
    "        max_y = 20\n",
    "        loss_lim = [0.46, .475]\n",
    "        acc_lim = [.76, .8]\n",
    "    elif name == 'titanic':\n",
    "        acc1, acc2 = 78, 79\n",
    "        max_y = 60\n",
    "        loss_lim = [.483, .498]\n",
    "        acc_lim = [.775, .792]\n",
    "    elif name == 'iris':\n",
    "        acc1, acc2 = 98, 100\n",
    "        max_y = 8\n",
    "        loss_lim = [.01, .05]\n",
    "        acc_lim = [.97, 1.0]\n",
    "    else:\n",
    "        raise ValueError(f'Unrecognized dataset name: {name}')\n",
    "    return acc1, acc2, loss_lim, acc_lim, max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_toy_example(name,\n",
    "                    seeds,\n",
    "                    model,\n",
    "                    train=True,\n",
    "                    analysis=True,\n",
    "                    **params):\n",
    "    assert name in ['digits', 'wine', 'twonorm', 'breast', 'blood', 'titanic', 'iris']\n",
    "    result_dir = f'results/toy/{name}'\n",
    "\n",
    "    if train:\n",
    "        toy_params = get_default_toy_params()\n",
    "        for lm in ['BP', 'CBP']:\n",
    "            train_params = toy_params[name][lm]\n",
    "            for seed in seeds:\n",
    "                run_toy(name, train_params, model_str=model, seed=seed, result_dir=result_dir, **params)\n",
    "\n",
    "    if analysis:\n",
    "        acc1, acc2, loss_lim, acc_lim, max_y = get_default_plot_params(name)\n",
    "        columns = ['method', 'loss_func', 'net', 'seed', 'init', 'act_func',\n",
    "                   'train loss', 'train loss (last)', 'train acc', 'train acc (last)']\n",
    "        save_prefix = f'{result_dir}/{model}/'\n",
    "\n",
    "        results = []\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        for lm in ['BP', 'CBP']:\n",
    "            for seed in seeds:\n",
    "                dir = f'{save_prefix}{lm}_CE_relu_initNone_seed{seed}/'\n",
    "                results.append(pd.read_csv(dir + 'result.txt', sep='\\s+', names=columns))\n",
    "                train_loss.append(np.loadtxt(dir + 'loss.txt'))\n",
    "                train_acc.append(np.loadtxt(dir + 'acc.txt'))\n",
    "        df = pd.concat(results)\n",
    "        df.to_csv(f'{save_prefix}results.txt', sep=',', index=False)\n",
    "        plot.plot_compare_loss_acc(df, save_prefix=save_prefix, acc_train=True, \n",
    "                                   ylabels=['minimal loss', 'maximal accuracy'])\n",
    "\n",
    "        if len(seeds) > 1:\n",
    "            sum_df = utils.results_summary(df, acc_train=True)\n",
    "            sum_df.to_csv(f'{save_prefix}results_summary.txt', sep=',', index=False)\n",
    "\n",
    "        train_loss = np.asarray(train_loss).T\n",
    "        train_acc = np.asarray(train_acc).T\n",
    "        np.savetxt(f'{save_prefix}loss.txt', train_loss)\n",
    "        np.savetxt(f'{save_prefix}acc.txt', train_acc)\n",
    "        plot.plot_mul_loss_acc(train_loss, train_acc, save_prefix=save_prefix,\n",
    "                               acc1=acc1, acc2=acc2, alpha=1, acc_train=True)\n",
    "        plot.plot_mul_loss_acc(train_loss, train_acc, save_prefix=save_prefix,\n",
    "                               acc1=acc1, acc2=acc2, loss_lim=loss_lim,\n",
    "                               acc_lim=acc_lim, alpha=1, acc_train=True)\n",
    "\n",
    "        time_records = []\n",
    "        for lm in ['BP', 'CBP']:\n",
    "            for seed in seeds:\n",
    "                dir = f'{save_prefix}{lm}_CE_relu_initNone_seed{seed}/'\n",
    "                file = open(dir + 'train.log', 'r')\n",
    "                output = deque(file, 5)\n",
    "                l = list(output)\n",
    "                train_time = float(l[0].split(' ')[-2])\n",
    "                time_record = [lm, seed, train_time]\n",
    "                for i in [3, 4]:\n",
    "                    t = l[i].split(' ')[-2]\n",
    "                    try:\n",
    "                        int(t)\n",
    "                        t = train_time # using train time instead if don't reach\n",
    "                    except:\n",
    "                        t = float(t)\n",
    "                    time_record.append(t)\n",
    "                time_records.append(time_record)\n",
    "                file.close()\n",
    "        df = pd.DataFrame(time_records, columns=[\n",
    "            'method', 'seed', 'train time (s)', f'time for {acc1}% (s)', f'time for {acc2}% (s)'])\n",
    "        plot.plot_train_time(df, acc1=acc1, acc2=acc2, max_y=max_y, save_prefix=save_prefix)\n",
    "        df.to_csv(f'{save_prefix}times.txt', sep=',', index=False)\n",
    "\n",
    "        if len(seeds) > 1:\n",
    "            sum_df = utils.times_summary(df)\n",
    "            sum_df.to_csv(f'{save_prefix}times_summary.txt', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Train Params:\n",
      "  zs: [None None]\n",
      "  beta: 0.99\n",
      "  cbp_epoch: 0\n",
      "  max_epoch: 1000\n",
      "  cbp_lr: 0.1\n",
      "  bp_lr: 0.1\n",
      "  bp_momentum: 0\n",
      "  bp_adam: False\n",
      "  logfile: results/toy/digits/64-129-10/BP_CE_relu_initNone_seed7/train.log\n",
      "--------------------------------------------------\n",
      "==================== start training ====================\n",
      "EPOCH:     1 | BP | train loss: 2.2897 | test acc: 0.0890\n",
      "EPOCH:     2 | BP | train loss: 2.2801 | test acc: 0.1208\n",
      "EPOCH:     3 | BP | train loss: 2.2706 | test acc: 0.1553\n",
      "EPOCH:     4 | BP | train loss: 2.2613 | test acc: 0.1920\n",
      "EPOCH:     5 | BP | train loss: 2.2520 | test acc: 0.2287\n",
      "EPOCH:     6 | BP | train loss: 2.2428 | test acc: 0.2649\n",
      "EPOCH:     7 | BP | train loss: 2.2335 | test acc: 0.3016\n",
      "EPOCH:     8 | BP | train loss: 2.2243 | test acc: 0.3372\n",
      "EPOCH:     9 | BP | train loss: 2.2150 | test acc: 0.3678\n",
      "EPOCH:    10 | BP | train loss: 2.2057 | test acc: 0.3984\n",
      "EPOCH:    11 | BP | train loss: 2.1962 | test acc: 0.4296\n",
      "EPOCH:    12 | BP | train loss: 2.1867 | test acc: 0.4680\n",
      "EPOCH:    13 | BP | train loss: 2.1771 | test acc: 0.5025\n",
      "EPOCH:    14 | BP | train loss: 2.1673 | test acc: 0.5459\n",
      "EPOCH:    15 | BP | train loss: 2.1574 | test acc: 0.5793\n",
      "EPOCH:    16 | BP | train loss: 2.1474 | test acc: 0.6311\n",
      "EPOCH:    17 | BP | train loss: 2.1372 | test acc: 0.6689\n",
      "EPOCH:    18 | BP | train loss: 2.1269 | test acc: 0.7012\n",
      "EPOCH:    19 | BP | train loss: 2.1164 | test acc: 0.7351\n",
      "EPOCH:    20 | BP | train loss: 2.1057 | test acc: 0.7585\n",
      "EPOCH:    21 | BP | train loss: 2.0948 | test acc: 0.7785\n",
      "EPOCH:    22 | BP | train loss: 2.0838 | test acc: 0.7891\n",
      "EPOCH:    23 | BP | train loss: 2.0726 | test acc: 0.7963\n",
      "EPOCH:    24 | BP | train loss: 2.0612 | test acc: 0.8047\n",
      "EPOCH:    25 | BP | train loss: 2.0496 | test acc: 0.8169\n",
      "EPOCH:    26 | BP | train loss: 2.0378 | test acc: 0.8208\n",
      "EPOCH:    27 | BP | train loss: 2.0258 | test acc: 0.8275\n",
      "EPOCH:    28 | BP | train loss: 2.0135 | test acc: 0.8353\n",
      "EPOCH:    29 | BP | train loss: 2.0011 | test acc: 0.8375\n",
      "EPOCH:    30 | BP | train loss: 1.9884 | test acc: 0.8425\n",
      "EPOCH:    31 | BP | train loss: 1.9756 | test acc: 0.8425\n",
      "EPOCH:    32 | BP | train loss: 1.9625 | test acc: 0.8442\n",
      "EPOCH:    33 | BP | train loss: 1.9491 | test acc: 0.8436\n",
      "EPOCH:    34 | BP | train loss: 1.9356 | test acc: 0.8436\n",
      "EPOCH:    35 | BP | train loss: 1.9218 | test acc: 0.8459\n",
      "EPOCH:    36 | BP | train loss: 1.9077 | test acc: 0.8492\n",
      "EPOCH:    37 | BP | train loss: 1.8935 | test acc: 0.8497\n",
      "EPOCH:    38 | BP | train loss: 1.8790 | test acc: 0.8486\n",
      "EPOCH:    39 | BP | train loss: 1.8643 | test acc: 0.8509\n",
      "EPOCH:    40 | BP | train loss: 1.8494 | test acc: 0.8497\n",
      "EPOCH:    41 | BP | train loss: 1.8343 | test acc: 0.8481\n",
      "EPOCH:    42 | BP | train loss: 1.8189 | test acc: 0.8481\n",
      "EPOCH:    43 | BP | train loss: 1.8034 | test acc: 0.8497\n",
      "EPOCH:    44 | BP | train loss: 1.7877 | test acc: 0.8525\n",
      "EPOCH:    45 | BP | train loss: 1.7718 | test acc: 0.8536\n",
      "EPOCH:    46 | BP | train loss: 1.7557 | test acc: 0.8548\n",
      "EPOCH:    47 | BP | train loss: 1.7394 | test acc: 0.8553\n",
      "EPOCH:    48 | BP | train loss: 1.7230 | test acc: 0.8553\n",
      "EPOCH:    49 | BP | train loss: 1.7065 | test acc: 0.8559\n",
      "EPOCH:    50 | BP | train loss: 1.6898 | test acc: 0.8536\n",
      "EPOCH:    51 | BP | train loss: 1.6730 | test acc: 0.8548\n",
      "EPOCH:    52 | BP | train loss: 1.6560 | test acc: 0.8548\n",
      "EPOCH:    53 | BP | train loss: 1.6390 | test acc: 0.8548\n",
      "EPOCH:    54 | BP | train loss: 1.6219 | test acc: 0.8559\n",
      "EPOCH:    55 | BP | train loss: 1.6046 | test acc: 0.8553\n",
      "EPOCH:    56 | BP | train loss: 1.5873 | test acc: 0.8553\n",
      "EPOCH:    57 | BP | train loss: 1.5700 | test acc: 0.8553\n",
      "EPOCH:    58 | BP | train loss: 1.5526 | test acc: 0.8553\n",
      "EPOCH:    59 | BP | train loss: 1.5352 | test acc: 0.8548\n",
      "EPOCH:    60 | BP | train loss: 1.5178 | test acc: 0.8559\n",
      "EPOCH:    61 | BP | train loss: 1.5003 | test acc: 0.8581\n",
      "EPOCH:    62 | BP | train loss: 1.4829 | test acc: 0.8581\n",
      "EPOCH:    63 | BP | train loss: 1.4654 | test acc: 0.8592\n",
      "EPOCH:    64 | BP | train loss: 1.4481 | test acc: 0.8609\n",
      "EPOCH:    65 | BP | train loss: 1.4307 | test acc: 0.8620\n",
      "EPOCH:    66 | BP | train loss: 1.4134 | test acc: 0.8631\n",
      "EPOCH:    67 | BP | train loss: 1.3962 | test acc: 0.8642\n",
      "EPOCH:    68 | BP | train loss: 1.3791 | test acc: 0.8648\n",
      "EPOCH:    69 | BP | train loss: 1.3620 | test acc: 0.8664\n",
      "EPOCH:    70 | BP | train loss: 1.3451 | test acc: 0.8676\n",
      "EPOCH:    71 | BP | train loss: 1.3283 | test acc: 0.8687\n",
      "EPOCH:    72 | BP | train loss: 1.3116 | test acc: 0.8709\n",
      "EPOCH:    73 | BP | train loss: 1.2950 | test acc: 0.8726\n",
      "EPOCH:    74 | BP | train loss: 1.2786 | test acc: 0.8742\n",
      "EPOCH:    75 | BP | train loss: 1.2623 | test acc: 0.8742\n",
      "EPOCH:    76 | BP | train loss: 1.2462 | test acc: 0.8759\n",
      "EPOCH:    77 | BP | train loss: 1.2302 | test acc: 0.8781\n",
      "EPOCH:    78 | BP | train loss: 1.2145 | test acc: 0.8787\n",
      "EPOCH:    79 | BP | train loss: 1.1989 | test acc: 0.8798\n",
      "EPOCH:    80 | BP | train loss: 1.1835 | test acc: 0.8804\n",
      "EPOCH:    81 | BP | train loss: 1.1682 | test acc: 0.8815\n",
      "EPOCH:    82 | BP | train loss: 1.1532 | test acc: 0.8815\n",
      "EPOCH:    83 | BP | train loss: 1.1384 | test acc: 0.8843\n",
      "EPOCH:    84 | BP | train loss: 1.1238 | test acc: 0.8854\n",
      "EPOCH:    85 | BP | train loss: 1.1094 | test acc: 0.8870\n",
      "EPOCH:    86 | BP | train loss: 1.0952 | test acc: 0.8887\n",
      "EPOCH:    87 | BP | train loss: 1.0812 | test acc: 0.8898\n",
      "EPOCH:    88 | BP | train loss: 1.0674 | test acc: 0.8920\n",
      "EPOCH:    89 | BP | train loss: 1.0539 | test acc: 0.8932\n",
      "EPOCH:    90 | BP | train loss: 1.0405 | test acc: 0.8937\n",
      "EPOCH:    91 | BP | train loss: 1.0274 | test acc: 0.8948\n",
      "EPOCH:    92 | BP | train loss: 1.0145 | test acc: 0.8954\n",
      "EPOCH:    93 | BP | train loss: 1.0018 | test acc: 0.8954\n",
      "EPOCH:    94 | BP | train loss: 0.9893 | test acc: 0.8959\n",
      "EPOCH:    95 | BP | train loss: 0.9770 | test acc: 0.8971\n",
      "EPOCH:    96 | BP | train loss: 0.9650 | test acc: 0.8993\n",
      "EPOCH:    97 | BP | train loss: 0.9531 | test acc: 0.8993\n",
      "EPOCH:    98 | BP | train loss: 0.9415 | test acc: 0.8998\n",
      "EPOCH:    99 | BP | train loss: 0.9301 | test acc: 0.8998\n",
      "EPOCH:   100 | BP | train loss: 0.9189 | test acc: 0.9009\n",
      "EPOCH:   101 | BP | train loss: 0.9079 | test acc: 0.9009\n",
      "EPOCH:   102 | BP | train loss: 0.8971 | test acc: 0.9021\n",
      "EPOCH:   103 | BP | train loss: 0.8864 | test acc: 0.9032\n",
      "EPOCH:   104 | BP | train loss: 0.8760 | test acc: 0.9037\n",
      "EPOCH:   105 | BP | train loss: 0.8658 | test acc: 0.9037\n",
      "EPOCH:   106 | BP | train loss: 0.8558 | test acc: 0.9037\n",
      "EPOCH:   107 | BP | train loss: 0.8459 | test acc: 0.9048\n",
      "EPOCH:   108 | BP | train loss: 0.8363 | test acc: 0.9060\n",
      "EPOCH:   109 | BP | train loss: 0.8268 | test acc: 0.9054\n",
      "EPOCH:   110 | BP | train loss: 0.8175 | test acc: 0.9054\n",
      "EPOCH:   111 | BP | train loss: 0.8084 | test acc: 0.9065\n",
      "EPOCH:   112 | BP | train loss: 0.7995 | test acc: 0.9071\n",
      "EPOCH:   113 | BP | train loss: 0.7907 | test acc: 0.9071\n",
      "EPOCH:   114 | BP | train loss: 0.7821 | test acc: 0.9087\n",
      "EPOCH:   115 | BP | train loss: 0.7736 | test acc: 0.9082\n",
      "EPOCH:   116 | BP | train loss: 0.7653 | test acc: 0.9098\n",
      "EPOCH:   117 | BP | train loss: 0.7572 | test acc: 0.9115\n",
      "EPOCH:   118 | BP | train loss: 0.7492 | test acc: 0.9115\n",
      "EPOCH:   119 | BP | train loss: 0.7414 | test acc: 0.9126\n",
      "EPOCH:   120 | BP | train loss: 0.7337 | test acc: 0.9126\n",
      "EPOCH:   121 | BP | train loss: 0.7262 | test acc: 0.9126\n",
      "EPOCH:   122 | BP | train loss: 0.7188 | test acc: 0.9126\n",
      "EPOCH:   123 | BP | train loss: 0.7115 | test acc: 0.9126\n",
      "EPOCH:   124 | BP | train loss: 0.7044 | test acc: 0.9126\n",
      "EPOCH:   125 | BP | train loss: 0.6974 | test acc: 0.9132\n",
      "EPOCH:   126 | BP | train loss: 0.6905 | test acc: 0.9132\n",
      "EPOCH:   127 | BP | train loss: 0.6838 | test acc: 0.9132\n",
      "EPOCH:   128 | BP | train loss: 0.6771 | test acc: 0.9132\n",
      "EPOCH:   129 | BP | train loss: 0.6706 | test acc: 0.9137\n",
      "EPOCH:   130 | BP | train loss: 0.6643 | test acc: 0.9137\n",
      "EPOCH:   131 | BP | train loss: 0.6580 | test acc: 0.9143\n",
      "EPOCH:   132 | BP | train loss: 0.6518 | test acc: 0.9149\n",
      "EPOCH:   133 | BP | train loss: 0.6458 | test acc: 0.9154\n",
      "EPOCH:   134 | BP | train loss: 0.6398 | test acc: 0.9160\n",
      "EPOCH:   135 | BP | train loss: 0.6340 | test acc: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   136 | BP | train loss: 0.6283 | test acc: 0.9160\n",
      "EPOCH:   137 | BP | train loss: 0.6226 | test acc: 0.9160\n",
      "EPOCH:   138 | BP | train loss: 0.6171 | test acc: 0.9160\n",
      "EPOCH:   139 | BP | train loss: 0.6117 | test acc: 0.9165\n",
      "EPOCH:   140 | BP | train loss: 0.6063 | test acc: 0.9165\n",
      "EPOCH:   141 | BP | train loss: 0.6011 | test acc: 0.9182\n",
      "EPOCH:   142 | BP | train loss: 0.5959 | test acc: 0.9188\n",
      "EPOCH:   143 | BP | train loss: 0.5908 | test acc: 0.9193\n",
      "EPOCH:   144 | BP | train loss: 0.5858 | test acc: 0.9193\n",
      "EPOCH:   145 | BP | train loss: 0.5809 | test acc: 0.9193\n",
      "EPOCH:   146 | BP | train loss: 0.5761 | test acc: 0.9193\n",
      "EPOCH:   147 | BP | train loss: 0.5713 | test acc: 0.9188\n",
      "EPOCH:   148 | BP | train loss: 0.5667 | test acc: 0.9193\n",
      "EPOCH:   149 | BP | train loss: 0.5621 | test acc: 0.9193\n",
      "EPOCH:   150 | BP | train loss: 0.5575 | test acc: 0.9193\n",
      "EPOCH:   151 | BP | train loss: 0.5531 | test acc: 0.9193\n",
      "EPOCH:   152 | BP | train loss: 0.5487 | test acc: 0.9204\n",
      "EPOCH:   153 | BP | train loss: 0.5444 | test acc: 0.9204\n",
      "EPOCH:   154 | BP | train loss: 0.5402 | test acc: 0.9204\n",
      "EPOCH:   155 | BP | train loss: 0.5360 | test acc: 0.9204\n",
      "EPOCH:   156 | BP | train loss: 0.5319 | test acc: 0.9204\n",
      "EPOCH:   157 | BP | train loss: 0.5278 | test acc: 0.9204\n",
      "EPOCH:   158 | BP | train loss: 0.5239 | test acc: 0.9210\n",
      "EPOCH:   159 | BP | train loss: 0.5199 | test acc: 0.9210\n",
      "EPOCH:   160 | BP | train loss: 0.5161 | test acc: 0.9210\n",
      "EPOCH:   161 | BP | train loss: 0.5123 | test acc: 0.9210\n",
      "EPOCH:   162 | BP | train loss: 0.5085 | test acc: 0.9210\n",
      "EPOCH:   163 | BP | train loss: 0.5048 | test acc: 0.9215\n",
      "EPOCH:   164 | BP | train loss: 0.5012 | test acc: 0.9215\n",
      "EPOCH:   165 | BP | train loss: 0.4976 | test acc: 0.9221\n",
      "EPOCH:   166 | BP | train loss: 0.4941 | test acc: 0.9226\n",
      "EPOCH:   167 | BP | train loss: 0.4906 | test acc: 0.9226\n",
      "EPOCH:   168 | BP | train loss: 0.4872 | test acc: 0.9226\n",
      "EPOCH:   169 | BP | train loss: 0.4838 | test acc: 0.9238\n",
      "EPOCH:   170 | BP | train loss: 0.4805 | test acc: 0.9238\n",
      "EPOCH:   171 | BP | train loss: 0.4772 | test acc: 0.9243\n",
      "EPOCH:   172 | BP | train loss: 0.4740 | test acc: 0.9243\n",
      "EPOCH:   173 | BP | train loss: 0.4708 | test acc: 0.9249\n",
      "EPOCH:   174 | BP | train loss: 0.4676 | test acc: 0.9249\n",
      "EPOCH:   175 | BP | train loss: 0.4645 | test acc: 0.9254\n",
      "EPOCH:   176 | BP | train loss: 0.4615 | test acc: 0.9254\n",
      "EPOCH:   177 | BP | train loss: 0.4585 | test acc: 0.9254\n",
      "EPOCH:   178 | BP | train loss: 0.4555 | test acc: 0.9260\n",
      "EPOCH:   179 | BP | train loss: 0.4525 | test acc: 0.9260\n",
      "EPOCH:   180 | BP | train loss: 0.4496 | test acc: 0.9260\n",
      "EPOCH:   181 | BP | train loss: 0.4468 | test acc: 0.9271\n",
      "EPOCH:   182 | BP | train loss: 0.4440 | test acc: 0.9277\n",
      "EPOCH:   183 | BP | train loss: 0.4412 | test acc: 0.9282\n",
      "EPOCH:   184 | BP | train loss: 0.4384 | test acc: 0.9277\n",
      "EPOCH:   185 | BP | train loss: 0.4357 | test acc: 0.9277\n",
      "EPOCH:   186 | BP | train loss: 0.4331 | test acc: 0.9288\n",
      "EPOCH:   187 | BP | train loss: 0.4304 | test acc: 0.9293\n",
      "EPOCH:   188 | BP | train loss: 0.4278 | test acc: 0.9293\n",
      "EPOCH:   189 | BP | train loss: 0.4253 | test acc: 0.9299\n",
      "EPOCH:   190 | BP | train loss: 0.4227 | test acc: 0.9299\n",
      "EPOCH:   191 | BP | train loss: 0.4202 | test acc: 0.9299\n",
      "EPOCH:   192 | BP | train loss: 0.4177 | test acc: 0.9299\n",
      "EPOCH:   193 | BP | train loss: 0.4153 | test acc: 0.9299\n",
      "EPOCH:   194 | BP | train loss: 0.4129 | test acc: 0.9299\n",
      "EPOCH:   195 | BP | train loss: 0.4105 | test acc: 0.9310\n",
      "EPOCH:   196 | BP | train loss: 0.4082 | test acc: 0.9310\n",
      "EPOCH:   197 | BP | train loss: 0.4058 | test acc: 0.9316\n",
      "EPOCH:   198 | BP | train loss: 0.4035 | test acc: 0.9316\n",
      "EPOCH:   199 | BP | train loss: 0.4013 | test acc: 0.9321\n",
      "EPOCH:   200 | BP | train loss: 0.3990 | test acc: 0.9316\n",
      "EPOCH:   201 | BP | train loss: 0.3968 | test acc: 0.9327\n",
      "EPOCH:   202 | BP | train loss: 0.3946 | test acc: 0.9332\n",
      "EPOCH:   203 | BP | train loss: 0.3925 | test acc: 0.9338\n",
      "EPOCH:   204 | BP | train loss: 0.3903 | test acc: 0.9338\n",
      "EPOCH:   205 | BP | train loss: 0.3882 | test acc: 0.9338\n",
      "EPOCH:   206 | BP | train loss: 0.3861 | test acc: 0.9338\n",
      "EPOCH:   207 | BP | train loss: 0.3841 | test acc: 0.9343\n",
      "EPOCH:   208 | BP | train loss: 0.3821 | test acc: 0.9343\n",
      "EPOCH:   209 | BP | train loss: 0.3800 | test acc: 0.9343\n",
      "EPOCH:   210 | BP | train loss: 0.3781 | test acc: 0.9343\n",
      "EPOCH:   211 | BP | train loss: 0.3761 | test acc: 0.9349\n",
      "EPOCH:   212 | BP | train loss: 0.3741 | test acc: 0.9349\n",
      "EPOCH:   213 | BP | train loss: 0.3722 | test acc: 0.9349\n",
      "EPOCH:   214 | BP | train loss: 0.3703 | test acc: 0.9349\n",
      "EPOCH:   215 | BP | train loss: 0.3684 | test acc: 0.9349\n",
      "EPOCH:   216 | BP | train loss: 0.3666 | test acc: 0.9360\n",
      "EPOCH:   217 | BP | train loss: 0.3648 | test acc: 0.9360\n",
      "EPOCH:   218 | BP | train loss: 0.3629 | test acc: 0.9360\n",
      "EPOCH:   219 | BP | train loss: 0.3611 | test acc: 0.9371\n",
      "EPOCH:   220 | BP | train loss: 0.3594 | test acc: 0.9371\n",
      "EPOCH:   221 | BP | train loss: 0.3576 | test acc: 0.9371\n",
      "EPOCH:   222 | BP | train loss: 0.3559 | test acc: 0.9366\n",
      "EPOCH:   223 | BP | train loss: 0.3542 | test acc: 0.9366\n",
      "EPOCH:   224 | BP | train loss: 0.3525 | test acc: 0.9382\n",
      "EPOCH:   225 | BP | train loss: 0.3508 | test acc: 0.9382\n",
      "EPOCH:   226 | BP | train loss: 0.3491 | test acc: 0.9382\n",
      "EPOCH:   227 | BP | train loss: 0.3475 | test acc: 0.9382\n",
      "EPOCH:   228 | BP | train loss: 0.3458 | test acc: 0.9382\n",
      "EPOCH:   229 | BP | train loss: 0.3442 | test acc: 0.9393\n",
      "EPOCH:   230 | BP | train loss: 0.3426 | test acc: 0.9399\n",
      "EPOCH:   231 | BP | train loss: 0.3410 | test acc: 0.9399\n",
      "EPOCH:   232 | BP | train loss: 0.3395 | test acc: 0.9399\n",
      "EPOCH:   233 | BP | train loss: 0.3379 | test acc: 0.9405\n",
      "EPOCH:   234 | BP | train loss: 0.3364 | test acc: 0.9405\n",
      "EPOCH:   235 | BP | train loss: 0.3349 | test acc: 0.9416\n",
      "EPOCH:   236 | BP | train loss: 0.3334 | test acc: 0.9416\n",
      "EPOCH:   237 | BP | train loss: 0.3319 | test acc: 0.9416\n",
      "EPOCH:   238 | BP | train loss: 0.3304 | test acc: 0.9416\n",
      "EPOCH:   239 | BP | train loss: 0.3290 | test acc: 0.9421\n",
      "EPOCH:   240 | BP | train loss: 0.3276 | test acc: 0.9421\n",
      "EPOCH:   241 | BP | train loss: 0.3261 | test acc: 0.9427\n",
      "EPOCH:   242 | BP | train loss: 0.3247 | test acc: 0.9432\n",
      "EPOCH:   243 | BP | train loss: 0.3233 | test acc: 0.9432\n",
      "EPOCH:   244 | BP | train loss: 0.3219 | test acc: 0.9438\n",
      "EPOCH:   245 | BP | train loss: 0.3206 | test acc: 0.9438\n",
      "EPOCH:   246 | BP | train loss: 0.3192 | test acc: 0.9438\n",
      "EPOCH:   247 | BP | train loss: 0.3179 | test acc: 0.9438\n",
      "EPOCH:   248 | BP | train loss: 0.3165 | test acc: 0.9438\n",
      "EPOCH:   249 | BP | train loss: 0.3152 | test acc: 0.9438\n",
      "EPOCH:   250 | BP | train loss: 0.3139 | test acc: 0.9438\n",
      "EPOCH:   251 | BP | train loss: 0.3126 | test acc: 0.9438\n",
      "EPOCH:   252 | BP | train loss: 0.3113 | test acc: 0.9438\n",
      "EPOCH:   253 | BP | train loss: 0.3101 | test acc: 0.9438\n",
      "EPOCH:   254 | BP | train loss: 0.3088 | test acc: 0.9438\n",
      "EPOCH:   255 | BP | train loss: 0.3076 | test acc: 0.9444\n",
      "EPOCH:   256 | BP | train loss: 0.3063 | test acc: 0.9444\n",
      "EPOCH:   257 | BP | train loss: 0.3051 | test acc: 0.9444\n",
      "EPOCH:   258 | BP | train loss: 0.3039 | test acc: 0.9444\n",
      "EPOCH:   259 | BP | train loss: 0.3027 | test acc: 0.9449\n",
      "EPOCH:   260 | BP | train loss: 0.3015 | test acc: 0.9455\n",
      "EPOCH:   261 | BP | train loss: 0.3003 | test acc: 0.9455\n",
      "EPOCH:   262 | BP | train loss: 0.2992 | test acc: 0.9455\n",
      "EPOCH:   263 | BP | train loss: 0.2980 | test acc: 0.9460\n",
      "EPOCH:   264 | BP | train loss: 0.2969 | test acc: 0.9466\n",
      "EPOCH:   265 | BP | train loss: 0.2957 | test acc: 0.9466\n",
      "EPOCH:   266 | BP | train loss: 0.2946 | test acc: 0.9466\n",
      "EPOCH:   267 | BP | train loss: 0.2935 | test acc: 0.9471\n",
      "EPOCH:   268 | BP | train loss: 0.2924 | test acc: 0.9471\n",
      "EPOCH:   269 | BP | train loss: 0.2913 | test acc: 0.9471\n",
      "EPOCH:   270 | BP | train loss: 0.2902 | test acc: 0.9477\n",
      "EPOCH:   271 | BP | train loss: 0.2891 | test acc: 0.9477\n",
      "EPOCH:   272 | BP | train loss: 0.2881 | test acc: 0.9477\n",
      "EPOCH:   273 | BP | train loss: 0.2870 | test acc: 0.9482\n",
      "EPOCH:   274 | BP | train loss: 0.2860 | test acc: 0.9482\n",
      "EPOCH:   275 | BP | train loss: 0.2849 | test acc: 0.9482\n",
      "EPOCH:   276 | BP | train loss: 0.2839 | test acc: 0.9488\n",
      "EPOCH:   277 | BP | train loss: 0.2829 | test acc: 0.9482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   278 | BP | train loss: 0.2819 | test acc: 0.9482\n",
      "EPOCH:   279 | BP | train loss: 0.2808 | test acc: 0.9482\n",
      "EPOCH:   280 | BP | train loss: 0.2799 | test acc: 0.9482\n",
      "EPOCH:   281 | BP | train loss: 0.2789 | test acc: 0.9482\n",
      "EPOCH:   282 | BP | train loss: 0.2779 | test acc: 0.9482\n",
      "EPOCH:   283 | BP | train loss: 0.2769 | test acc: 0.9482\n",
      "EPOCH:   284 | BP | train loss: 0.2760 | test acc: 0.9482\n",
      "EPOCH:   285 | BP | train loss: 0.2750 | test acc: 0.9482\n",
      "EPOCH:   286 | BP | train loss: 0.2741 | test acc: 0.9488\n",
      "EPOCH:   287 | BP | train loss: 0.2731 | test acc: 0.9488\n",
      "EPOCH:   288 | BP | train loss: 0.2722 | test acc: 0.9488\n",
      "EPOCH:   289 | BP | train loss: 0.2713 | test acc: 0.9488\n",
      "EPOCH:   290 | BP | train loss: 0.2703 | test acc: 0.9488\n",
      "EPOCH:   291 | BP | train loss: 0.2694 | test acc: 0.9488\n",
      "EPOCH:   292 | BP | train loss: 0.2685 | test acc: 0.9488\n",
      "EPOCH:   293 | BP | train loss: 0.2676 | test acc: 0.9488\n",
      "EPOCH:   294 | BP | train loss: 0.2667 | test acc: 0.9488\n",
      "EPOCH:   295 | BP | train loss: 0.2659 | test acc: 0.9488\n",
      "EPOCH:   296 | BP | train loss: 0.2650 | test acc: 0.9488\n",
      "EPOCH:   297 | BP | train loss: 0.2641 | test acc: 0.9488\n",
      "EPOCH:   298 | BP | train loss: 0.2633 | test acc: 0.9488\n",
      "EPOCH:   299 | BP | train loss: 0.2624 | test acc: 0.9494\n",
      "EPOCH:   300 | BP | train loss: 0.2616 | test acc: 0.9494\n",
      "EPOCH:   301 | BP | train loss: 0.2607 | test acc: 0.9494\n",
      "EPOCH:   302 | BP | train loss: 0.2599 | test acc: 0.9494\n",
      "EPOCH:   303 | BP | train loss: 0.2591 | test acc: 0.9494\n",
      "EPOCH:   304 | BP | train loss: 0.2582 | test acc: 0.9494\n",
      "EPOCH:   305 | BP | train loss: 0.2574 | test acc: 0.9494\n",
      "EPOCH:   306 | BP | train loss: 0.2566 | test acc: 0.9494\n",
      "EPOCH:   307 | BP | train loss: 0.2558 | test acc: 0.9494\n",
      "EPOCH:   308 | BP | train loss: 0.2550 | test acc: 0.9499\n",
      "EPOCH:   309 | BP | train loss: 0.2542 | test acc: 0.9499\n",
      "EPOCH:   310 | BP | train loss: 0.2534 | test acc: 0.9499\n",
      "EPOCH:   311 | BP | train loss: 0.2527 | test acc: 0.9499\n",
      "EPOCH:   312 | BP | train loss: 0.2519 | test acc: 0.9499\n",
      "EPOCH:   313 | BP | train loss: 0.2511 | test acc: 0.9499\n",
      "EPOCH:   314 | BP | train loss: 0.2504 | test acc: 0.9505\n",
      "EPOCH:   315 | BP | train loss: 0.2496 | test acc: 0.9505\n",
      "EPOCH:   316 | BP | train loss: 0.2489 | test acc: 0.9510\n",
      "EPOCH:   317 | BP | train loss: 0.2481 | test acc: 0.9510\n",
      "EPOCH:   318 | BP | train loss: 0.2474 | test acc: 0.9516\n",
      "EPOCH:   319 | BP | train loss: 0.2466 | test acc: 0.9516\n",
      "EPOCH:   320 | BP | train loss: 0.2459 | test acc: 0.9516\n",
      "EPOCH:   321 | BP | train loss: 0.2452 | test acc: 0.9516\n",
      "EPOCH:   322 | BP | train loss: 0.2445 | test acc: 0.9516\n",
      "EPOCH:   323 | BP | train loss: 0.2438 | test acc: 0.9521\n",
      "EPOCH:   324 | BP | train loss: 0.2430 | test acc: 0.9521\n",
      "EPOCH:   325 | BP | train loss: 0.2423 | test acc: 0.9521\n",
      "EPOCH:   326 | BP | train loss: 0.2416 | test acc: 0.9521\n",
      "EPOCH:   327 | BP | train loss: 0.2410 | test acc: 0.9527\n",
      "EPOCH:   328 | BP | train loss: 0.2403 | test acc: 0.9527\n",
      "EPOCH:   329 | BP | train loss: 0.2396 | test acc: 0.9527\n",
      "EPOCH:   330 | BP | train loss: 0.2389 | test acc: 0.9527\n",
      "EPOCH:   331 | BP | train loss: 0.2382 | test acc: 0.9527\n",
      "EPOCH:   332 | BP | train loss: 0.2376 | test acc: 0.9533\n",
      "EPOCH:   333 | BP | train loss: 0.2369 | test acc: 0.9533\n",
      "EPOCH:   334 | BP | train loss: 0.2362 | test acc: 0.9533\n",
      "EPOCH:   335 | BP | train loss: 0.2356 | test acc: 0.9533\n",
      "EPOCH:   336 | BP | train loss: 0.2349 | test acc: 0.9533\n",
      "EPOCH:   337 | BP | train loss: 0.2343 | test acc: 0.9533\n",
      "EPOCH:   338 | BP | train loss: 0.2336 | test acc: 0.9533\n",
      "EPOCH:   339 | BP | train loss: 0.2330 | test acc: 0.9533\n",
      "EPOCH:   340 | BP | train loss: 0.2324 | test acc: 0.9533\n",
      "EPOCH:   341 | BP | train loss: 0.2317 | test acc: 0.9533\n",
      "EPOCH:   342 | BP | train loss: 0.2311 | test acc: 0.9527\n",
      "EPOCH:   343 | BP | train loss: 0.2305 | test acc: 0.9533\n",
      "EPOCH:   344 | BP | train loss: 0.2299 | test acc: 0.9538\n",
      "EPOCH:   345 | BP | train loss: 0.2293 | test acc: 0.9538\n",
      "EPOCH:   346 | BP | train loss: 0.2287 | test acc: 0.9544\n",
      "EPOCH:   347 | BP | train loss: 0.2281 | test acc: 0.9555\n",
      "EPOCH:   348 | BP | train loss: 0.2275 | test acc: 0.9555\n",
      "EPOCH:   349 | BP | train loss: 0.2269 | test acc: 0.9560\n",
      "EPOCH:   350 | BP | train loss: 0.2263 | test acc: 0.9560\n",
      "EPOCH:   351 | BP | train loss: 0.2257 | test acc: 0.9566\n",
      "EPOCH:   352 | BP | train loss: 0.2251 | test acc: 0.9566\n",
      "EPOCH:   353 | BP | train loss: 0.2245 | test acc: 0.9572\n",
      "EPOCH:   354 | BP | train loss: 0.2239 | test acc: 0.9577\n",
      "EPOCH:   355 | BP | train loss: 0.2234 | test acc: 0.9577\n",
      "EPOCH:   356 | BP | train loss: 0.2228 | test acc: 0.9577\n",
      "EPOCH:   357 | BP | train loss: 0.2222 | test acc: 0.9577\n",
      "EPOCH:   358 | BP | train loss: 0.2217 | test acc: 0.9577\n",
      "EPOCH:   359 | BP | train loss: 0.2211 | test acc: 0.9577\n",
      "EPOCH:   360 | BP | train loss: 0.2206 | test acc: 0.9577\n",
      "EPOCH:   361 | BP | train loss: 0.2200 | test acc: 0.9577\n",
      "EPOCH:   362 | BP | train loss: 0.2195 | test acc: 0.9577\n",
      "EPOCH:   363 | BP | train loss: 0.2189 | test acc: 0.9577\n",
      "EPOCH:   364 | BP | train loss: 0.2184 | test acc: 0.9583\n",
      "EPOCH:   365 | BP | train loss: 0.2178 | test acc: 0.9583\n",
      "EPOCH:   366 | BP | train loss: 0.2173 | test acc: 0.9583\n",
      "EPOCH:   367 | BP | train loss: 0.2168 | test acc: 0.9583\n",
      "EPOCH:   368 | BP | train loss: 0.2163 | test acc: 0.9583\n",
      "EPOCH:   369 | BP | train loss: 0.2157 | test acc: 0.9583\n",
      "EPOCH:   370 | BP | train loss: 0.2152 | test acc: 0.9583\n",
      "EPOCH:   371 | BP | train loss: 0.2147 | test acc: 0.9583\n",
      "EPOCH:   372 | BP | train loss: 0.2142 | test acc: 0.9588\n",
      "EPOCH:   373 | BP | train loss: 0.2137 | test acc: 0.9588\n",
      "EPOCH:   374 | BP | train loss: 0.2132 | test acc: 0.9588\n",
      "EPOCH:   375 | BP | train loss: 0.2127 | test acc: 0.9588\n",
      "EPOCH:   376 | BP | train loss: 0.2122 | test acc: 0.9588\n",
      "EPOCH:   377 | BP | train loss: 0.2117 | test acc: 0.9588\n",
      "EPOCH:   378 | BP | train loss: 0.2112 | test acc: 0.9588\n",
      "EPOCH:   379 | BP | train loss: 0.2107 | test acc: 0.9588\n",
      "EPOCH:   380 | BP | train loss: 0.2102 | test acc: 0.9588\n",
      "EPOCH:   381 | BP | train loss: 0.2097 | test acc: 0.9588\n",
      "EPOCH:   382 | BP | train loss: 0.2092 | test acc: 0.9588\n",
      "EPOCH:   383 | BP | train loss: 0.2087 | test acc: 0.9588\n",
      "EPOCH:   384 | BP | train loss: 0.2082 | test acc: 0.9594\n",
      "EPOCH:   385 | BP | train loss: 0.2078 | test acc: 0.9594\n",
      "EPOCH:   386 | BP | train loss: 0.2073 | test acc: 0.9594\n",
      "EPOCH:   387 | BP | train loss: 0.2068 | test acc: 0.9594\n",
      "EPOCH:   388 | BP | train loss: 0.2064 | test acc: 0.9594\n",
      "EPOCH:   389 | BP | train loss: 0.2059 | test acc: 0.9594\n",
      "EPOCH:   390 | BP | train loss: 0.2054 | test acc: 0.9594\n",
      "EPOCH:   391 | BP | train loss: 0.2050 | test acc: 0.9594\n",
      "EPOCH:   392 | BP | train loss: 0.2045 | test acc: 0.9599\n",
      "EPOCH:   393 | BP | train loss: 0.2041 | test acc: 0.9599\n",
      "EPOCH:   394 | BP | train loss: 0.2036 | test acc: 0.9599\n",
      "EPOCH:   395 | BP | train loss: 0.2032 | test acc: 0.9605\n",
      "EPOCH:   396 | BP | train loss: 0.2027 | test acc: 0.9610\n",
      "EPOCH:   397 | BP | train loss: 0.2023 | test acc: 0.9610\n",
      "EPOCH:   398 | BP | train loss: 0.2018 | test acc: 0.9610\n",
      "EPOCH:   399 | BP | train loss: 0.2014 | test acc: 0.9616\n",
      "EPOCH:   400 | BP | train loss: 0.2010 | test acc: 0.9616\n",
      "EPOCH:   401 | BP | train loss: 0.2005 | test acc: 0.9616\n",
      "EPOCH:   402 | BP | train loss: 0.2001 | test acc: 0.9616\n",
      "EPOCH:   403 | BP | train loss: 0.1997 | test acc: 0.9616\n",
      "EPOCH:   404 | BP | train loss: 0.1992 | test acc: 0.9616\n",
      "EPOCH:   405 | BP | train loss: 0.1988 | test acc: 0.9616\n",
      "EPOCH:   406 | BP | train loss: 0.1984 | test acc: 0.9616\n",
      "EPOCH:   407 | BP | train loss: 0.1980 | test acc: 0.9616\n",
      "EPOCH:   408 | BP | train loss: 0.1976 | test acc: 0.9616\n",
      "EPOCH:   409 | BP | train loss: 0.1972 | test acc: 0.9622\n",
      "EPOCH:   410 | BP | train loss: 0.1967 | test acc: 0.9622\n",
      "EPOCH:   411 | BP | train loss: 0.1963 | test acc: 0.9622\n",
      "EPOCH:   412 | BP | train loss: 0.1959 | test acc: 0.9622\n",
      "EPOCH:   413 | BP | train loss: 0.1955 | test acc: 0.9622\n",
      "EPOCH:   414 | BP | train loss: 0.1951 | test acc: 0.9622\n",
      "EPOCH:   415 | BP | train loss: 0.1947 | test acc: 0.9622\n",
      "EPOCH:   416 | BP | train loss: 0.1943 | test acc: 0.9627\n",
      "EPOCH:   417 | BP | train loss: 0.1939 | test acc: 0.9633\n",
      "EPOCH:   418 | BP | train loss: 0.1935 | test acc: 0.9633\n",
      "EPOCH:   419 | BP | train loss: 0.1931 | test acc: 0.9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   420 | BP | train loss: 0.1927 | test acc: 0.9633\n",
      "EPOCH:   421 | BP | train loss: 0.1923 | test acc: 0.9633\n",
      "EPOCH:   422 | BP | train loss: 0.1920 | test acc: 0.9633\n",
      "EPOCH:   423 | BP | train loss: 0.1916 | test acc: 0.9633\n",
      "EPOCH:   424 | BP | train loss: 0.1912 | test acc: 0.9633\n",
      "EPOCH:   425 | BP | train loss: 0.1908 | test acc: 0.9633\n",
      "EPOCH:   426 | BP | train loss: 0.1904 | test acc: 0.9633\n",
      "EPOCH:   427 | BP | train loss: 0.1901 | test acc: 0.9633\n",
      "EPOCH:   428 | BP | train loss: 0.1897 | test acc: 0.9633\n",
      "EPOCH:   429 | BP | train loss: 0.1893 | test acc: 0.9633\n",
      "EPOCH:   430 | BP | train loss: 0.1889 | test acc: 0.9633\n",
      "EPOCH:   431 | BP | train loss: 0.1886 | test acc: 0.9633\n",
      "EPOCH:   432 | BP | train loss: 0.1882 | test acc: 0.9644\n",
      "EPOCH:   433 | BP | train loss: 0.1878 | test acc: 0.9644\n",
      "EPOCH:   434 | BP | train loss: 0.1875 | test acc: 0.9644\n",
      "EPOCH:   435 | BP | train loss: 0.1871 | test acc: 0.9649\n",
      "EPOCH:   436 | BP | train loss: 0.1867 | test acc: 0.9649\n",
      "EPOCH:   437 | BP | train loss: 0.1864 | test acc: 0.9655\n",
      "EPOCH:   438 | BP | train loss: 0.1860 | test acc: 0.9655\n",
      "EPOCH:   439 | BP | train loss: 0.1857 | test acc: 0.9655\n",
      "EPOCH:   440 | BP | train loss: 0.1853 | test acc: 0.9655\n",
      "EPOCH:   441 | BP | train loss: 0.1850 | test acc: 0.9655\n",
      "EPOCH:   442 | BP | train loss: 0.1846 | test acc: 0.9655\n",
      "EPOCH:   443 | BP | train loss: 0.1843 | test acc: 0.9655\n",
      "EPOCH:   444 | BP | train loss: 0.1839 | test acc: 0.9655\n",
      "EPOCH:   445 | BP | train loss: 0.1836 | test acc: 0.9661\n",
      "EPOCH:   446 | BP | train loss: 0.1832 | test acc: 0.9661\n",
      "EPOCH:   447 | BP | train loss: 0.1829 | test acc: 0.9661\n",
      "EPOCH:   448 | BP | train loss: 0.1826 | test acc: 0.9661\n",
      "EPOCH:   449 | BP | train loss: 0.1822 | test acc: 0.9661\n",
      "EPOCH:   450 | BP | train loss: 0.1819 | test acc: 0.9661\n",
      "EPOCH:   451 | BP | train loss: 0.1816 | test acc: 0.9661\n",
      "EPOCH:   452 | BP | train loss: 0.1812 | test acc: 0.9661\n",
      "EPOCH:   453 | BP | train loss: 0.1809 | test acc: 0.9661\n",
      "EPOCH:   454 | BP | train loss: 0.1806 | test acc: 0.9661\n",
      "EPOCH:   455 | BP | train loss: 0.1802 | test acc: 0.9661\n",
      "EPOCH:   456 | BP | train loss: 0.1799 | test acc: 0.9666\n",
      "EPOCH:   457 | BP | train loss: 0.1796 | test acc: 0.9666\n",
      "EPOCH:   458 | BP | train loss: 0.1793 | test acc: 0.9666\n",
      "EPOCH:   459 | BP | train loss: 0.1789 | test acc: 0.9672\n",
      "EPOCH:   460 | BP | train loss: 0.1786 | test acc: 0.9672\n",
      "EPOCH:   461 | BP | train loss: 0.1783 | test acc: 0.9672\n",
      "EPOCH:   462 | BP | train loss: 0.1780 | test acc: 0.9672\n",
      "EPOCH:   463 | BP | train loss: 0.1777 | test acc: 0.9672\n",
      "EPOCH:   464 | BP | train loss: 0.1774 | test acc: 0.9672\n",
      "EPOCH:   465 | BP | train loss: 0.1770 | test acc: 0.9672\n",
      "EPOCH:   466 | BP | train loss: 0.1767 | test acc: 0.9672\n",
      "EPOCH:   467 | BP | train loss: 0.1764 | test acc: 0.9672\n",
      "EPOCH:   468 | BP | train loss: 0.1761 | test acc: 0.9672\n",
      "EPOCH:   469 | BP | train loss: 0.1758 | test acc: 0.9672\n",
      "EPOCH:   470 | BP | train loss: 0.1755 | test acc: 0.9672\n",
      "EPOCH:   471 | BP | train loss: 0.1752 | test acc: 0.9672\n",
      "EPOCH:   472 | BP | train loss: 0.1749 | test acc: 0.9672\n",
      "EPOCH:   473 | BP | train loss: 0.1746 | test acc: 0.9677\n",
      "EPOCH:   474 | BP | train loss: 0.1743 | test acc: 0.9677\n",
      "EPOCH:   475 | BP | train loss: 0.1740 | test acc: 0.9677\n",
      "EPOCH:   476 | BP | train loss: 0.1737 | test acc: 0.9677\n",
      "EPOCH:   477 | BP | train loss: 0.1734 | test acc: 0.9677\n",
      "EPOCH:   478 | BP | train loss: 0.1731 | test acc: 0.9677\n",
      "EPOCH:   479 | BP | train loss: 0.1728 | test acc: 0.9677\n",
      "EPOCH:   480 | BP | train loss: 0.1725 | test acc: 0.9677\n",
      "EPOCH:   481 | BP | train loss: 0.1722 | test acc: 0.9677\n",
      "EPOCH:   482 | BP | train loss: 0.1719 | test acc: 0.9677\n",
      "EPOCH:   483 | BP | train loss: 0.1716 | test acc: 0.9677\n",
      "EPOCH:   484 | BP | train loss: 0.1714 | test acc: 0.9677\n",
      "EPOCH:   485 | BP | train loss: 0.1711 | test acc: 0.9677\n",
      "EPOCH:   486 | BP | train loss: 0.1708 | test acc: 0.9677\n",
      "EPOCH:   487 | BP | train loss: 0.1705 | test acc: 0.9677\n",
      "EPOCH:   488 | BP | train loss: 0.1702 | test acc: 0.9677\n",
      "EPOCH:   489 | BP | train loss: 0.1699 | test acc: 0.9683\n",
      "EPOCH:   490 | BP | train loss: 0.1697 | test acc: 0.9683\n",
      "EPOCH:   491 | BP | train loss: 0.1694 | test acc: 0.9683\n",
      "EPOCH:   492 | BP | train loss: 0.1691 | test acc: 0.9683\n",
      "EPOCH:   493 | BP | train loss: 0.1688 | test acc: 0.9683\n",
      "EPOCH:   494 | BP | train loss: 0.1686 | test acc: 0.9683\n",
      "EPOCH:   495 | BP | train loss: 0.1683 | test acc: 0.9683\n",
      "EPOCH:   496 | BP | train loss: 0.1680 | test acc: 0.9683\n",
      "EPOCH:   497 | BP | train loss: 0.1677 | test acc: 0.9683\n",
      "EPOCH:   498 | BP | train loss: 0.1675 | test acc: 0.9683\n",
      "EPOCH:   499 | BP | train loss: 0.1672 | test acc: 0.9683\n",
      "EPOCH:   500 | BP | train loss: 0.1669 | test acc: 0.9683\n",
      "EPOCH:   501 | BP | train loss: 0.1667 | test acc: 0.9683\n",
      "EPOCH:   502 | BP | train loss: 0.1664 | test acc: 0.9683\n",
      "EPOCH:   503 | BP | train loss: 0.1661 | test acc: 0.9683\n",
      "EPOCH:   504 | BP | train loss: 0.1659 | test acc: 0.9683\n",
      "EPOCH:   505 | BP | train loss: 0.1656 | test acc: 0.9683\n",
      "EPOCH:   506 | BP | train loss: 0.1653 | test acc: 0.9683\n",
      "EPOCH:   507 | BP | train loss: 0.1651 | test acc: 0.9683\n",
      "EPOCH:   508 | BP | train loss: 0.1648 | test acc: 0.9683\n",
      "EPOCH:   509 | BP | train loss: 0.1646 | test acc: 0.9683\n",
      "EPOCH:   510 | BP | train loss: 0.1643 | test acc: 0.9683\n",
      "EPOCH:   511 | BP | train loss: 0.1641 | test acc: 0.9683\n",
      "EPOCH:   512 | BP | train loss: 0.1638 | test acc: 0.9683\n",
      "EPOCH:   513 | BP | train loss: 0.1636 | test acc: 0.9683\n",
      "EPOCH:   514 | BP | train loss: 0.1633 | test acc: 0.9683\n",
      "EPOCH:   515 | BP | train loss: 0.1630 | test acc: 0.9683\n",
      "EPOCH:   516 | BP | train loss: 0.1628 | test acc: 0.9683\n",
      "EPOCH:   517 | BP | train loss: 0.1625 | test acc: 0.9683\n",
      "EPOCH:   518 | BP | train loss: 0.1623 | test acc: 0.9683\n",
      "EPOCH:   519 | BP | train loss: 0.1620 | test acc: 0.9688\n",
      "EPOCH:   520 | BP | train loss: 0.1618 | test acc: 0.9694\n",
      "EPOCH:   521 | BP | train loss: 0.1616 | test acc: 0.9694\n",
      "EPOCH:   522 | BP | train loss: 0.1613 | test acc: 0.9694\n",
      "EPOCH:   523 | BP | train loss: 0.1611 | test acc: 0.9694\n",
      "EPOCH:   524 | BP | train loss: 0.1608 | test acc: 0.9694\n",
      "EPOCH:   525 | BP | train loss: 0.1606 | test acc: 0.9694\n",
      "EPOCH:   526 | BP | train loss: 0.1603 | test acc: 0.9694\n",
      "EPOCH:   527 | BP | train loss: 0.1601 | test acc: 0.9694\n",
      "EPOCH:   528 | BP | train loss: 0.1599 | test acc: 0.9694\n",
      "EPOCH:   529 | BP | train loss: 0.1596 | test acc: 0.9694\n",
      "EPOCH:   530 | BP | train loss: 0.1594 | test acc: 0.9694\n",
      "EPOCH:   531 | BP | train loss: 0.1591 | test acc: 0.9694\n",
      "EPOCH:   532 | BP | train loss: 0.1589 | test acc: 0.9694\n",
      "EPOCH:   533 | BP | train loss: 0.1587 | test acc: 0.9694\n",
      "EPOCH:   534 | BP | train loss: 0.1584 | test acc: 0.9699\n",
      "EPOCH:   535 | BP | train loss: 0.1582 | test acc: 0.9699\n",
      "EPOCH:   536 | BP | train loss: 0.1580 | test acc: 0.9699\n",
      "EPOCH:   537 | BP | train loss: 0.1577 | test acc: 0.9699\n",
      "EPOCH:   538 | BP | train loss: 0.1575 | test acc: 0.9699\n",
      "EPOCH:   539 | BP | train loss: 0.1573 | test acc: 0.9705\n",
      "EPOCH:   540 | BP | train loss: 0.1571 | test acc: 0.9705\n",
      "EPOCH:   541 | BP | train loss: 0.1568 | test acc: 0.9705\n",
      "EPOCH:   542 | BP | train loss: 0.1566 | test acc: 0.9705\n",
      "EPOCH:   543 | BP | train loss: 0.1564 | test acc: 0.9705\n",
      "EPOCH:   544 | BP | train loss: 0.1562 | test acc: 0.9705\n",
      "EPOCH:   545 | BP | train loss: 0.1559 | test acc: 0.9705\n",
      "EPOCH:   546 | BP | train loss: 0.1557 | test acc: 0.9705\n",
      "EPOCH:   547 | BP | train loss: 0.1555 | test acc: 0.9705\n",
      "EPOCH:   548 | BP | train loss: 0.1553 | test acc: 0.9705\n",
      "EPOCH:   549 | BP | train loss: 0.1550 | test acc: 0.9705\n",
      "EPOCH:   550 | BP | train loss: 0.1548 | test acc: 0.9705\n",
      "EPOCH:   551 | BP | train loss: 0.1546 | test acc: 0.9705\n",
      "EPOCH:   552 | BP | train loss: 0.1544 | test acc: 0.9705\n",
      "EPOCH:   553 | BP | train loss: 0.1542 | test acc: 0.9705\n",
      "EPOCH:   554 | BP | train loss: 0.1540 | test acc: 0.9705\n",
      "EPOCH:   555 | BP | train loss: 0.1537 | test acc: 0.9711\n",
      "EPOCH:   556 | BP | train loss: 0.1535 | test acc: 0.9716\n",
      "EPOCH:   557 | BP | train loss: 0.1533 | test acc: 0.9716\n",
      "EPOCH:   558 | BP | train loss: 0.1531 | test acc: 0.9716\n",
      "EPOCH:   559 | BP | train loss: 0.1529 | test acc: 0.9722\n",
      "EPOCH:   560 | BP | train loss: 0.1527 | test acc: 0.9722\n",
      "EPOCH:   561 | BP | train loss: 0.1525 | test acc: 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   562 | BP | train loss: 0.1522 | test acc: 0.9722\n",
      "EPOCH:   563 | BP | train loss: 0.1520 | test acc: 0.9722\n",
      "EPOCH:   564 | BP | train loss: 0.1518 | test acc: 0.9722\n",
      "EPOCH:   565 | BP | train loss: 0.1516 | test acc: 0.9722\n",
      "EPOCH:   566 | BP | train loss: 0.1514 | test acc: 0.9722\n",
      "EPOCH:   567 | BP | train loss: 0.1512 | test acc: 0.9722\n",
      "EPOCH:   568 | BP | train loss: 0.1510 | test acc: 0.9722\n",
      "EPOCH:   569 | BP | train loss: 0.1508 | test acc: 0.9722\n",
      "EPOCH:   570 | BP | train loss: 0.1506 | test acc: 0.9722\n",
      "EPOCH:   571 | BP | train loss: 0.1504 | test acc: 0.9722\n",
      "EPOCH:   572 | BP | train loss: 0.1502 | test acc: 0.9722\n",
      "EPOCH:   573 | BP | train loss: 0.1500 | test acc: 0.9722\n",
      "EPOCH:   574 | BP | train loss: 0.1498 | test acc: 0.9722\n",
      "EPOCH:   575 | BP | train loss: 0.1496 | test acc: 0.9722\n",
      "EPOCH:   576 | BP | train loss: 0.1494 | test acc: 0.9722\n",
      "EPOCH:   577 | BP | train loss: 0.1492 | test acc: 0.9722\n",
      "EPOCH:   578 | BP | train loss: 0.1490 | test acc: 0.9722\n",
      "EPOCH:   579 | BP | train loss: 0.1488 | test acc: 0.9722\n",
      "EPOCH:   580 | BP | train loss: 0.1486 | test acc: 0.9722\n",
      "EPOCH:   581 | BP | train loss: 0.1484 | test acc: 0.9722\n",
      "EPOCH:   582 | BP | train loss: 0.1482 | test acc: 0.9722\n",
      "EPOCH:   583 | BP | train loss: 0.1480 | test acc: 0.9722\n",
      "EPOCH:   584 | BP | train loss: 0.1478 | test acc: 0.9727\n",
      "EPOCH:   585 | BP | train loss: 0.1476 | test acc: 0.9727\n",
      "EPOCH:   586 | BP | train loss: 0.1474 | test acc: 0.9727\n",
      "EPOCH:   587 | BP | train loss: 0.1472 | test acc: 0.9727\n",
      "EPOCH:   588 | BP | train loss: 0.1470 | test acc: 0.9727\n",
      "EPOCH:   589 | BP | train loss: 0.1468 | test acc: 0.9727\n",
      "EPOCH:   590 | BP | train loss: 0.1466 | test acc: 0.9727\n",
      "EPOCH:   591 | BP | train loss: 0.1465 | test acc: 0.9727\n",
      "EPOCH:   592 | BP | train loss: 0.1463 | test acc: 0.9727\n",
      "EPOCH:   593 | BP | train loss: 0.1461 | test acc: 0.9727\n",
      "EPOCH:   594 | BP | train loss: 0.1459 | test acc: 0.9727\n",
      "EPOCH:   595 | BP | train loss: 0.1457 | test acc: 0.9727\n",
      "EPOCH:   596 | BP | train loss: 0.1455 | test acc: 0.9727\n",
      "EPOCH:   597 | BP | train loss: 0.1453 | test acc: 0.9727\n",
      "EPOCH:   598 | BP | train loss: 0.1451 | test acc: 0.9727\n",
      "EPOCH:   599 | BP | train loss: 0.1450 | test acc: 0.9727\n",
      "EPOCH:   600 | BP | train loss: 0.1448 | test acc: 0.9727\n",
      "EPOCH:   601 | BP | train loss: 0.1446 | test acc: 0.9727\n",
      "EPOCH:   602 | BP | train loss: 0.1444 | test acc: 0.9727\n",
      "EPOCH:   603 | BP | train loss: 0.1442 | test acc: 0.9727\n",
      "EPOCH:   604 | BP | train loss: 0.1440 | test acc: 0.9727\n",
      "EPOCH:   605 | BP | train loss: 0.1439 | test acc: 0.9727\n",
      "EPOCH:   606 | BP | train loss: 0.1437 | test acc: 0.9727\n",
      "EPOCH:   607 | BP | train loss: 0.1435 | test acc: 0.9727\n",
      "EPOCH:   608 | BP | train loss: 0.1433 | test acc: 0.9727\n",
      "EPOCH:   609 | BP | train loss: 0.1431 | test acc: 0.9727\n",
      "EPOCH:   610 | BP | train loss: 0.1430 | test acc: 0.9727\n",
      "EPOCH:   611 | BP | train loss: 0.1428 | test acc: 0.9727\n",
      "EPOCH:   612 | BP | train loss: 0.1426 | test acc: 0.9727\n",
      "EPOCH:   613 | BP | train loss: 0.1424 | test acc: 0.9727\n",
      "EPOCH:   614 | BP | train loss: 0.1423 | test acc: 0.9727\n",
      "EPOCH:   615 | BP | train loss: 0.1421 | test acc: 0.9727\n",
      "EPOCH:   616 | BP | train loss: 0.1419 | test acc: 0.9727\n",
      "EPOCH:   617 | BP | train loss: 0.1417 | test acc: 0.9727\n",
      "EPOCH:   618 | BP | train loss: 0.1416 | test acc: 0.9727\n",
      "EPOCH:   619 | BP | train loss: 0.1414 | test acc: 0.9727\n",
      "EPOCH:   620 | BP | train loss: 0.1412 | test acc: 0.9733\n",
      "EPOCH:   621 | BP | train loss: 0.1410 | test acc: 0.9733\n",
      "EPOCH:   622 | BP | train loss: 0.1409 | test acc: 0.9733\n",
      "EPOCH:   623 | BP | train loss: 0.1407 | test acc: 0.9733\n",
      "EPOCH:   624 | BP | train loss: 0.1405 | test acc: 0.9738\n",
      "EPOCH:   625 | BP | train loss: 0.1403 | test acc: 0.9738\n",
      "EPOCH:   626 | BP | train loss: 0.1402 | test acc: 0.9738\n",
      "EPOCH:   627 | BP | train loss: 0.1400 | test acc: 0.9738\n",
      "EPOCH:   628 | BP | train loss: 0.1398 | test acc: 0.9738\n",
      "EPOCH:   629 | BP | train loss: 0.1397 | test acc: 0.9738\n",
      "EPOCH:   630 | BP | train loss: 0.1395 | test acc: 0.9738\n",
      "EPOCH:   631 | BP | train loss: 0.1393 | test acc: 0.9744\n",
      "EPOCH:   632 | BP | train loss: 0.1392 | test acc: 0.9744\n",
      "EPOCH:   633 | BP | train loss: 0.1390 | test acc: 0.9744\n",
      "EPOCH:   634 | BP | train loss: 0.1388 | test acc: 0.9744\n",
      "EPOCH:   635 | BP | train loss: 0.1387 | test acc: 0.9744\n",
      "EPOCH:   636 | BP | train loss: 0.1385 | test acc: 0.9744\n",
      "EPOCH:   637 | BP | train loss: 0.1383 | test acc: 0.9744\n",
      "EPOCH:   638 | BP | train loss: 0.1382 | test acc: 0.9744\n",
      "EPOCH:   639 | BP | train loss: 0.1380 | test acc: 0.9744\n",
      "EPOCH:   640 | BP | train loss: 0.1379 | test acc: 0.9744\n",
      "EPOCH:   641 | BP | train loss: 0.1377 | test acc: 0.9744\n",
      "EPOCH:   642 | BP | train loss: 0.1375 | test acc: 0.9744\n",
      "EPOCH:   643 | BP | train loss: 0.1374 | test acc: 0.9744\n",
      "EPOCH:   644 | BP | train loss: 0.1372 | test acc: 0.9744\n",
      "EPOCH:   645 | BP | train loss: 0.1371 | test acc: 0.9744\n",
      "EPOCH:   646 | BP | train loss: 0.1369 | test acc: 0.9744\n",
      "EPOCH:   647 | BP | train loss: 0.1367 | test acc: 0.9744\n",
      "EPOCH:   648 | BP | train loss: 0.1366 | test acc: 0.9744\n",
      "EPOCH:   649 | BP | train loss: 0.1364 | test acc: 0.9744\n",
      "EPOCH:   650 | BP | train loss: 0.1363 | test acc: 0.9744\n",
      "EPOCH:   651 | BP | train loss: 0.1361 | test acc: 0.9744\n",
      "EPOCH:   652 | BP | train loss: 0.1359 | test acc: 0.9744\n",
      "EPOCH:   653 | BP | train loss: 0.1358 | test acc: 0.9750\n",
      "EPOCH:   654 | BP | train loss: 0.1356 | test acc: 0.9750\n",
      "EPOCH:   655 | BP | train loss: 0.1355 | test acc: 0.9750\n",
      "EPOCH:   656 | BP | train loss: 0.1353 | test acc: 0.9750\n",
      "EPOCH:   657 | BP | train loss: 0.1352 | test acc: 0.9750\n",
      "EPOCH:   658 | BP | train loss: 0.1350 | test acc: 0.9750\n",
      "EPOCH:   659 | BP | train loss: 0.1349 | test acc: 0.9750\n",
      "EPOCH:   660 | BP | train loss: 0.1347 | test acc: 0.9750\n",
      "EPOCH:   661 | BP | train loss: 0.1346 | test acc: 0.9750\n",
      "EPOCH:   662 | BP | train loss: 0.1344 | test acc: 0.9750\n",
      "EPOCH:   663 | BP | train loss: 0.1342 | test acc: 0.9750\n",
      "EPOCH:   664 | BP | train loss: 0.1341 | test acc: 0.9750\n",
      "EPOCH:   665 | BP | train loss: 0.1339 | test acc: 0.9750\n",
      "EPOCH:   666 | BP | train loss: 0.1338 | test acc: 0.9750\n",
      "EPOCH:   667 | BP | train loss: 0.1336 | test acc: 0.9750\n",
      "EPOCH:   668 | BP | train loss: 0.1335 | test acc: 0.9750\n",
      "EPOCH:   669 | BP | train loss: 0.1333 | test acc: 0.9750\n",
      "EPOCH:   670 | BP | train loss: 0.1332 | test acc: 0.9744\n",
      "EPOCH:   671 | BP | train loss: 0.1331 | test acc: 0.9744\n",
      "EPOCH:   672 | BP | train loss: 0.1329 | test acc: 0.9744\n",
      "EPOCH:   673 | BP | train loss: 0.1328 | test acc: 0.9744\n",
      "EPOCH:   674 | BP | train loss: 0.1326 | test acc: 0.9744\n",
      "EPOCH:   675 | BP | train loss: 0.1325 | test acc: 0.9744\n",
      "EPOCH:   676 | BP | train loss: 0.1323 | test acc: 0.9744\n",
      "EPOCH:   677 | BP | train loss: 0.1322 | test acc: 0.9744\n",
      "EPOCH:   678 | BP | train loss: 0.1320 | test acc: 0.9744\n",
      "EPOCH:   679 | BP | train loss: 0.1319 | test acc: 0.9744\n",
      "EPOCH:   680 | BP | train loss: 0.1317 | test acc: 0.9744\n",
      "EPOCH:   681 | BP | train loss: 0.1316 | test acc: 0.9744\n",
      "EPOCH:   682 | BP | train loss: 0.1314 | test acc: 0.9744\n",
      "EPOCH:   683 | BP | train loss: 0.1313 | test acc: 0.9750\n",
      "EPOCH:   684 | BP | train loss: 0.1312 | test acc: 0.9750\n",
      "EPOCH:   685 | BP | train loss: 0.1310 | test acc: 0.9750\n",
      "EPOCH:   686 | BP | train loss: 0.1309 | test acc: 0.9750\n",
      "EPOCH:   687 | BP | train loss: 0.1307 | test acc: 0.9755\n",
      "EPOCH:   688 | BP | train loss: 0.1306 | test acc: 0.9755\n",
      "EPOCH:   689 | BP | train loss: 0.1304 | test acc: 0.9755\n",
      "EPOCH:   690 | BP | train loss: 0.1303 | test acc: 0.9755\n",
      "EPOCH:   691 | BP | train loss: 0.1302 | test acc: 0.9755\n",
      "EPOCH:   692 | BP | train loss: 0.1300 | test acc: 0.9755\n",
      "EPOCH:   693 | BP | train loss: 0.1299 | test acc: 0.9750\n",
      "EPOCH:   694 | BP | train loss: 0.1297 | test acc: 0.9750\n",
      "EPOCH:   695 | BP | train loss: 0.1296 | test acc: 0.9750\n",
      "EPOCH:   696 | BP | train loss: 0.1295 | test acc: 0.9750\n",
      "EPOCH:   697 | BP | train loss: 0.1293 | test acc: 0.9750\n",
      "EPOCH:   698 | BP | train loss: 0.1292 | test acc: 0.9750\n",
      "EPOCH:   699 | BP | train loss: 0.1291 | test acc: 0.9750\n",
      "EPOCH:   700 | BP | train loss: 0.1289 | test acc: 0.9750\n",
      "EPOCH:   701 | BP | train loss: 0.1288 | test acc: 0.9750\n",
      "EPOCH:   702 | BP | train loss: 0.1286 | test acc: 0.9750\n",
      "EPOCH:   703 | BP | train loss: 0.1285 | test acc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   704 | BP | train loss: 0.1284 | test acc: 0.9750\n",
      "EPOCH:   705 | BP | train loss: 0.1282 | test acc: 0.9750\n",
      "EPOCH:   706 | BP | train loss: 0.1281 | test acc: 0.9750\n",
      "EPOCH:   707 | BP | train loss: 0.1280 | test acc: 0.9750\n",
      "EPOCH:   708 | BP | train loss: 0.1278 | test acc: 0.9750\n",
      "EPOCH:   709 | BP | train loss: 0.1277 | test acc: 0.9750\n",
      "EPOCH:   710 | BP | train loss: 0.1276 | test acc: 0.9750\n",
      "EPOCH:   711 | BP | train loss: 0.1274 | test acc: 0.9750\n",
      "EPOCH:   712 | BP | train loss: 0.1273 | test acc: 0.9750\n",
      "EPOCH:   713 | BP | train loss: 0.1272 | test acc: 0.9750\n",
      "EPOCH:   714 | BP | train loss: 0.1270 | test acc: 0.9750\n",
      "EPOCH:   715 | BP | train loss: 0.1269 | test acc: 0.9755\n",
      "EPOCH:   716 | BP | train loss: 0.1268 | test acc: 0.9755\n",
      "EPOCH:   717 | BP | train loss: 0.1266 | test acc: 0.9755\n",
      "EPOCH:   718 | BP | train loss: 0.1265 | test acc: 0.9755\n",
      "EPOCH:   719 | BP | train loss: 0.1264 | test acc: 0.9755\n",
      "EPOCH:   720 | BP | train loss: 0.1263 | test acc: 0.9755\n",
      "EPOCH:   721 | BP | train loss: 0.1261 | test acc: 0.9755\n",
      "EPOCH:   722 | BP | train loss: 0.1260 | test acc: 0.9761\n",
      "EPOCH:   723 | BP | train loss: 0.1259 | test acc: 0.9761\n",
      "EPOCH:   724 | BP | train loss: 0.1257 | test acc: 0.9761\n",
      "EPOCH:   725 | BP | train loss: 0.1256 | test acc: 0.9766\n",
      "EPOCH:   726 | BP | train loss: 0.1255 | test acc: 0.9766\n",
      "EPOCH:   727 | BP | train loss: 0.1254 | test acc: 0.9766\n",
      "EPOCH:   728 | BP | train loss: 0.1252 | test acc: 0.9766\n",
      "EPOCH:   729 | BP | train loss: 0.1251 | test acc: 0.9766\n",
      "EPOCH:   730 | BP | train loss: 0.1250 | test acc: 0.9766\n",
      "EPOCH:   731 | BP | train loss: 0.1248 | test acc: 0.9766\n",
      "EPOCH:   732 | BP | train loss: 0.1247 | test acc: 0.9766\n",
      "EPOCH:   733 | BP | train loss: 0.1246 | test acc: 0.9766\n",
      "EPOCH:   734 | BP | train loss: 0.1245 | test acc: 0.9766\n",
      "EPOCH:   735 | BP | train loss: 0.1243 | test acc: 0.9766\n",
      "EPOCH:   736 | BP | train loss: 0.1242 | test acc: 0.9766\n",
      "EPOCH:   737 | BP | train loss: 0.1241 | test acc: 0.9766\n",
      "EPOCH:   738 | BP | train loss: 0.1240 | test acc: 0.9766\n",
      "EPOCH:   739 | BP | train loss: 0.1238 | test acc: 0.9766\n",
      "EPOCH:   740 | BP | train loss: 0.1237 | test acc: 0.9766\n",
      "EPOCH:   741 | BP | train loss: 0.1236 | test acc: 0.9766\n",
      "EPOCH:   742 | BP | train loss: 0.1235 | test acc: 0.9766\n",
      "EPOCH:   743 | BP | train loss: 0.1234 | test acc: 0.9766\n",
      "EPOCH:   744 | BP | train loss: 0.1232 | test acc: 0.9766\n",
      "EPOCH:   745 | BP | train loss: 0.1231 | test acc: 0.9766\n",
      "EPOCH:   746 | BP | train loss: 0.1230 | test acc: 0.9766\n",
      "EPOCH:   747 | BP | train loss: 0.1229 | test acc: 0.9766\n",
      "EPOCH:   748 | BP | train loss: 0.1227 | test acc: 0.9766\n",
      "EPOCH:   749 | BP | train loss: 0.1226 | test acc: 0.9766\n",
      "EPOCH:   750 | BP | train loss: 0.1225 | test acc: 0.9766\n",
      "EPOCH:   751 | BP | train loss: 0.1224 | test acc: 0.9766\n",
      "EPOCH:   752 | BP | train loss: 0.1223 | test acc: 0.9766\n",
      "EPOCH:   753 | BP | train loss: 0.1221 | test acc: 0.9766\n",
      "EPOCH:   754 | BP | train loss: 0.1220 | test acc: 0.9766\n",
      "EPOCH:   755 | BP | train loss: 0.1219 | test acc: 0.9766\n",
      "EPOCH:   756 | BP | train loss: 0.1218 | test acc: 0.9766\n",
      "EPOCH:   757 | BP | train loss: 0.1217 | test acc: 0.9766\n",
      "EPOCH:   758 | BP | train loss: 0.1216 | test acc: 0.9766\n",
      "EPOCH:   759 | BP | train loss: 0.1214 | test acc: 0.9766\n",
      "EPOCH:   760 | BP | train loss: 0.1213 | test acc: 0.9766\n",
      "EPOCH:   761 | BP | train loss: 0.1212 | test acc: 0.9766\n",
      "EPOCH:   762 | BP | train loss: 0.1211 | test acc: 0.9772\n",
      "EPOCH:   763 | BP | train loss: 0.1210 | test acc: 0.9777\n",
      "EPOCH:   764 | BP | train loss: 0.1209 | test acc: 0.9777\n",
      "EPOCH:   765 | BP | train loss: 0.1207 | test acc: 0.9777\n",
      "EPOCH:   766 | BP | train loss: 0.1206 | test acc: 0.9777\n",
      "EPOCH:   767 | BP | train loss: 0.1205 | test acc: 0.9777\n",
      "EPOCH:   768 | BP | train loss: 0.1204 | test acc: 0.9777\n",
      "EPOCH:   769 | BP | train loss: 0.1203 | test acc: 0.9777\n",
      "EPOCH:   770 | BP | train loss: 0.1202 | test acc: 0.9777\n",
      "EPOCH:   771 | BP | train loss: 0.1200 | test acc: 0.9777\n",
      "EPOCH:   772 | BP | train loss: 0.1199 | test acc: 0.9777\n",
      "EPOCH:   773 | BP | train loss: 0.1198 | test acc: 0.9777\n",
      "EPOCH:   774 | BP | train loss: 0.1197 | test acc: 0.9777\n",
      "EPOCH:   775 | BP | train loss: 0.1196 | test acc: 0.9783\n",
      "EPOCH:   776 | BP | train loss: 0.1195 | test acc: 0.9783\n",
      "EPOCH:   777 | BP | train loss: 0.1194 | test acc: 0.9783\n",
      "EPOCH:   778 | BP | train loss: 0.1192 | test acc: 0.9783\n",
      "EPOCH:   779 | BP | train loss: 0.1191 | test acc: 0.9783\n",
      "EPOCH:   780 | BP | train loss: 0.1190 | test acc: 0.9783\n",
      "EPOCH:   781 | BP | train loss: 0.1189 | test acc: 0.9783\n",
      "EPOCH:   782 | BP | train loss: 0.1188 | test acc: 0.9783\n",
      "EPOCH:   783 | BP | train loss: 0.1187 | test acc: 0.9783\n",
      "EPOCH:   784 | BP | train loss: 0.1186 | test acc: 0.9783\n",
      "EPOCH:   785 | BP | train loss: 0.1185 | test acc: 0.9783\n",
      "EPOCH:   786 | BP | train loss: 0.1184 | test acc: 0.9783\n",
      "EPOCH:   787 | BP | train loss: 0.1182 | test acc: 0.9783\n",
      "EPOCH:   788 | BP | train loss: 0.1181 | test acc: 0.9783\n",
      "EPOCH:   789 | BP | train loss: 0.1180 | test acc: 0.9783\n",
      "EPOCH:   790 | BP | train loss: 0.1179 | test acc: 0.9783\n",
      "EPOCH:   791 | BP | train loss: 0.1178 | test acc: 0.9783\n",
      "EPOCH:   792 | BP | train loss: 0.1177 | test acc: 0.9783\n",
      "EPOCH:   793 | BP | train loss: 0.1176 | test acc: 0.9783\n",
      "EPOCH:   794 | BP | train loss: 0.1175 | test acc: 0.9783\n",
      "EPOCH:   795 | BP | train loss: 0.1174 | test acc: 0.9783\n",
      "EPOCH:   796 | BP | train loss: 0.1173 | test acc: 0.9783\n",
      "EPOCH:   797 | BP | train loss: 0.1172 | test acc: 0.9783\n",
      "EPOCH:   798 | BP | train loss: 0.1171 | test acc: 0.9783\n",
      "EPOCH:   799 | BP | train loss: 0.1169 | test acc: 0.9783\n",
      "EPOCH:   800 | BP | train loss: 0.1168 | test acc: 0.9783\n",
      "EPOCH:   801 | BP | train loss: 0.1167 | test acc: 0.9783\n",
      "EPOCH:   802 | BP | train loss: 0.1166 | test acc: 0.9783\n",
      "EPOCH:   803 | BP | train loss: 0.1165 | test acc: 0.9783\n",
      "EPOCH:   804 | BP | train loss: 0.1164 | test acc: 0.9783\n",
      "EPOCH:   805 | BP | train loss: 0.1163 | test acc: 0.9783\n",
      "EPOCH:   806 | BP | train loss: 0.1162 | test acc: 0.9783\n",
      "EPOCH:   807 | BP | train loss: 0.1161 | test acc: 0.9783\n",
      "EPOCH:   808 | BP | train loss: 0.1160 | test acc: 0.9783\n",
      "EPOCH:   809 | BP | train loss: 0.1159 | test acc: 0.9783\n",
      "EPOCH:   810 | BP | train loss: 0.1158 | test acc: 0.9783\n",
      "EPOCH:   811 | BP | train loss: 0.1157 | test acc: 0.9783\n",
      "EPOCH:   812 | BP | train loss: 0.1156 | test acc: 0.9783\n",
      "EPOCH:   813 | BP | train loss: 0.1155 | test acc: 0.9783\n",
      "EPOCH:   814 | BP | train loss: 0.1154 | test acc: 0.9783\n",
      "EPOCH:   815 | BP | train loss: 0.1153 | test acc: 0.9789\n",
      "EPOCH:   816 | BP | train loss: 0.1152 | test acc: 0.9789\n",
      "EPOCH:   817 | BP | train loss: 0.1151 | test acc: 0.9789\n",
      "EPOCH:   818 | BP | train loss: 0.1150 | test acc: 0.9789\n",
      "EPOCH:   819 | BP | train loss: 0.1148 | test acc: 0.9789\n",
      "EPOCH:   820 | BP | train loss: 0.1147 | test acc: 0.9789\n",
      "EPOCH:   821 | BP | train loss: 0.1146 | test acc: 0.9789\n",
      "EPOCH:   822 | BP | train loss: 0.1145 | test acc: 0.9789\n",
      "EPOCH:   823 | BP | train loss: 0.1144 | test acc: 0.9789\n",
      "EPOCH:   824 | BP | train loss: 0.1143 | test acc: 0.9789\n",
      "EPOCH:   825 | BP | train loss: 0.1142 | test acc: 0.9789\n",
      "EPOCH:   826 | BP | train loss: 0.1141 | test acc: 0.9789\n",
      "EPOCH:   827 | BP | train loss: 0.1140 | test acc: 0.9789\n",
      "EPOCH:   828 | BP | train loss: 0.1139 | test acc: 0.9789\n",
      "EPOCH:   829 | BP | train loss: 0.1138 | test acc: 0.9789\n",
      "EPOCH:   830 | BP | train loss: 0.1137 | test acc: 0.9789\n",
      "EPOCH:   831 | BP | train loss: 0.1136 | test acc: 0.9789\n",
      "EPOCH:   832 | BP | train loss: 0.1135 | test acc: 0.9789\n",
      "EPOCH:   833 | BP | train loss: 0.1134 | test acc: 0.9789\n",
      "EPOCH:   834 | BP | train loss: 0.1133 | test acc: 0.9789\n",
      "EPOCH:   835 | BP | train loss: 0.1132 | test acc: 0.9789\n",
      "EPOCH:   836 | BP | train loss: 0.1131 | test acc: 0.9789\n",
      "EPOCH:   837 | BP | train loss: 0.1130 | test acc: 0.9789\n",
      "EPOCH:   838 | BP | train loss: 0.1129 | test acc: 0.9789\n",
      "EPOCH:   839 | BP | train loss: 0.1128 | test acc: 0.9789\n",
      "EPOCH:   840 | BP | train loss: 0.1127 | test acc: 0.9789\n",
      "EPOCH:   841 | BP | train loss: 0.1126 | test acc: 0.9789\n",
      "EPOCH:   842 | BP | train loss: 0.1125 | test acc: 0.9789\n",
      "EPOCH:   843 | BP | train loss: 0.1125 | test acc: 0.9789\n",
      "EPOCH:   844 | BP | train loss: 0.1124 | test acc: 0.9789\n",
      "EPOCH:   845 | BP | train loss: 0.1123 | test acc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   846 | BP | train loss: 0.1122 | test acc: 0.9789\n",
      "EPOCH:   847 | BP | train loss: 0.1121 | test acc: 0.9789\n",
      "EPOCH:   848 | BP | train loss: 0.1120 | test acc: 0.9789\n",
      "EPOCH:   849 | BP | train loss: 0.1119 | test acc: 0.9789\n",
      "EPOCH:   850 | BP | train loss: 0.1118 | test acc: 0.9789\n",
      "EPOCH:   851 | BP | train loss: 0.1117 | test acc: 0.9789\n",
      "EPOCH:   852 | BP | train loss: 0.1116 | test acc: 0.9789\n",
      "EPOCH:   853 | BP | train loss: 0.1115 | test acc: 0.9789\n",
      "EPOCH:   854 | BP | train loss: 0.1114 | test acc: 0.9794\n",
      "EPOCH:   855 | BP | train loss: 0.1113 | test acc: 0.9794\n",
      "EPOCH:   856 | BP | train loss: 0.1112 | test acc: 0.9794\n",
      "EPOCH:   857 | BP | train loss: 0.1111 | test acc: 0.9794\n",
      "EPOCH:   858 | BP | train loss: 0.1110 | test acc: 0.9794\n",
      "EPOCH:   859 | BP | train loss: 0.1109 | test acc: 0.9794\n",
      "EPOCH:   860 | BP | train loss: 0.1108 | test acc: 0.9800\n",
      "EPOCH:   861 | BP | train loss: 0.1107 | test acc: 0.9800\n",
      "EPOCH:   862 | BP | train loss: 0.1106 | test acc: 0.9800\n",
      "EPOCH:   863 | BP | train loss: 0.1105 | test acc: 0.9800\n",
      "EPOCH:   864 | BP | train loss: 0.1104 | test acc: 0.9800\n",
      "EPOCH:   865 | BP | train loss: 0.1104 | test acc: 0.9800\n",
      "EPOCH:   866 | BP | train loss: 0.1103 | test acc: 0.9800\n",
      "EPOCH:   867 | BP | train loss: 0.1102 | test acc: 0.9800\n",
      "EPOCH:   868 | BP | train loss: 0.1101 | test acc: 0.9800\n",
      "EPOCH:   869 | BP | train loss: 0.1100 | test acc: 0.9800\n",
      "EPOCH:   870 | BP | train loss: 0.1099 | test acc: 0.9800\n",
      "EPOCH:   871 | BP | train loss: 0.1098 | test acc: 0.9800\n",
      "EPOCH:   872 | BP | train loss: 0.1097 | test acc: 0.9800\n",
      "EPOCH:   873 | BP | train loss: 0.1096 | test acc: 0.9800\n",
      "EPOCH:   874 | BP | train loss: 0.1095 | test acc: 0.9805\n",
      "EPOCH:   875 | BP | train loss: 0.1094 | test acc: 0.9805\n",
      "EPOCH:   876 | BP | train loss: 0.1093 | test acc: 0.9805\n",
      "EPOCH:   877 | BP | train loss: 0.1092 | test acc: 0.9805\n",
      "EPOCH:   878 | BP | train loss: 0.1092 | test acc: 0.9805\n",
      "EPOCH:   879 | BP | train loss: 0.1091 | test acc: 0.9805\n",
      "EPOCH:   880 | BP | train loss: 0.1090 | test acc: 0.9805\n",
      "EPOCH:   881 | BP | train loss: 0.1089 | test acc: 0.9811\n",
      "EPOCH:   882 | BP | train loss: 0.1088 | test acc: 0.9811\n",
      "EPOCH:   883 | BP | train loss: 0.1087 | test acc: 0.9811\n",
      "EPOCH:   884 | BP | train loss: 0.1086 | test acc: 0.9811\n",
      "EPOCH:   885 | BP | train loss: 0.1085 | test acc: 0.9811\n",
      "EPOCH:   886 | BP | train loss: 0.1084 | test acc: 0.9811\n",
      "EPOCH:   887 | BP | train loss: 0.1083 | test acc: 0.9811\n",
      "EPOCH:   888 | BP | train loss: 0.1083 | test acc: 0.9811\n",
      "EPOCH:   889 | BP | train loss: 0.1082 | test acc: 0.9811\n",
      "EPOCH:   890 | BP | train loss: 0.1081 | test acc: 0.9811\n",
      "EPOCH:   891 | BP | train loss: 0.1080 | test acc: 0.9811\n",
      "EPOCH:   892 | BP | train loss: 0.1079 | test acc: 0.9811\n",
      "EPOCH:   893 | BP | train loss: 0.1078 | test acc: 0.9811\n",
      "EPOCH:   894 | BP | train loss: 0.1077 | test acc: 0.9811\n",
      "EPOCH:   895 | BP | train loss: 0.1076 | test acc: 0.9811\n",
      "EPOCH:   896 | BP | train loss: 0.1075 | test acc: 0.9811\n",
      "EPOCH:   897 | BP | train loss: 0.1075 | test acc: 0.9811\n",
      "EPOCH:   898 | BP | train loss: 0.1074 | test acc: 0.9811\n",
      "EPOCH:   899 | BP | train loss: 0.1073 | test acc: 0.9811\n",
      "EPOCH:   900 | BP | train loss: 0.1072 | test acc: 0.9811\n",
      "EPOCH:   901 | BP | train loss: 0.1071 | test acc: 0.9811\n",
      "EPOCH:   902 | BP | train loss: 0.1070 | test acc: 0.9811\n",
      "EPOCH:   903 | BP | train loss: 0.1069 | test acc: 0.9811\n",
      "EPOCH:   904 | BP | train loss: 0.1069 | test acc: 0.9811\n",
      "EPOCH:   905 | BP | train loss: 0.1068 | test acc: 0.9811\n",
      "EPOCH:   906 | BP | train loss: 0.1067 | test acc: 0.9811\n",
      "EPOCH:   907 | BP | train loss: 0.1066 | test acc: 0.9811\n",
      "EPOCH:   908 | BP | train loss: 0.1065 | test acc: 0.9811\n",
      "EPOCH:   909 | BP | train loss: 0.1064 | test acc: 0.9811\n",
      "EPOCH:   910 | BP | train loss: 0.1063 | test acc: 0.9811\n",
      "EPOCH:   911 | BP | train loss: 0.1063 | test acc: 0.9811\n",
      "EPOCH:   912 | BP | train loss: 0.1062 | test acc: 0.9811\n",
      "EPOCH:   913 | BP | train loss: 0.1061 | test acc: 0.9811\n",
      "EPOCH:   914 | BP | train loss: 0.1060 | test acc: 0.9811\n",
      "EPOCH:   915 | BP | train loss: 0.1059 | test acc: 0.9811\n",
      "EPOCH:   916 | BP | train loss: 0.1058 | test acc: 0.9811\n",
      "EPOCH:   917 | BP | train loss: 0.1057 | test acc: 0.9811\n",
      "EPOCH:   918 | BP | train loss: 0.1057 | test acc: 0.9811\n",
      "EPOCH:   919 | BP | train loss: 0.1056 | test acc: 0.9811\n",
      "EPOCH:   920 | BP | train loss: 0.1055 | test acc: 0.9811\n",
      "EPOCH:   921 | BP | train loss: 0.1054 | test acc: 0.9811\n",
      "EPOCH:   922 | BP | train loss: 0.1053 | test acc: 0.9811\n",
      "EPOCH:   923 | BP | train loss: 0.1052 | test acc: 0.9811\n",
      "EPOCH:   924 | BP | train loss: 0.1052 | test acc: 0.9811\n",
      "EPOCH:   925 | BP | train loss: 0.1051 | test acc: 0.9811\n",
      "EPOCH:   926 | BP | train loss: 0.1050 | test acc: 0.9811\n",
      "EPOCH:   927 | BP | train loss: 0.1049 | test acc: 0.9811\n",
      "EPOCH:   928 | BP | train loss: 0.1048 | test acc: 0.9816\n",
      "EPOCH:   929 | BP | train loss: 0.1047 | test acc: 0.9816\n",
      "EPOCH:   930 | BP | train loss: 0.1047 | test acc: 0.9816\n",
      "EPOCH:   931 | BP | train loss: 0.1046 | test acc: 0.9816\n",
      "EPOCH:   932 | BP | train loss: 0.1045 | test acc: 0.9816\n",
      "EPOCH:   933 | BP | train loss: 0.1044 | test acc: 0.9816\n",
      "EPOCH:   934 | BP | train loss: 0.1043 | test acc: 0.9816\n",
      "EPOCH:   935 | BP | train loss: 0.1043 | test acc: 0.9816\n",
      "EPOCH:   936 | BP | train loss: 0.1042 | test acc: 0.9816\n",
      "EPOCH:   937 | BP | train loss: 0.1041 | test acc: 0.9816\n",
      "EPOCH:   938 | BP | train loss: 0.1040 | test acc: 0.9816\n",
      "EPOCH:   939 | BP | train loss: 0.1039 | test acc: 0.9816\n",
      "EPOCH:   940 | BP | train loss: 0.1038 | test acc: 0.9816\n",
      "EPOCH:   941 | BP | train loss: 0.1038 | test acc: 0.9816\n",
      "EPOCH:   942 | BP | train loss: 0.1037 | test acc: 0.9816\n",
      "EPOCH:   943 | BP | train loss: 0.1036 | test acc: 0.9816\n",
      "EPOCH:   944 | BP | train loss: 0.1035 | test acc: 0.9816\n",
      "EPOCH:   945 | BP | train loss: 0.1034 | test acc: 0.9816\n",
      "EPOCH:   946 | BP | train loss: 0.1034 | test acc: 0.9816\n",
      "EPOCH:   947 | BP | train loss: 0.1033 | test acc: 0.9816\n",
      "EPOCH:   948 | BP | train loss: 0.1032 | test acc: 0.9816\n",
      "EPOCH:   949 | BP | train loss: 0.1031 | test acc: 0.9816\n",
      "EPOCH:   950 | BP | train loss: 0.1030 | test acc: 0.9816\n",
      "EPOCH:   951 | BP | train loss: 0.1030 | test acc: 0.9816\n",
      "EPOCH:   952 | BP | train loss: 0.1029 | test acc: 0.9816\n",
      "EPOCH:   953 | BP | train loss: 0.1028 | test acc: 0.9816\n",
      "EPOCH:   954 | BP | train loss: 0.1027 | test acc: 0.9816\n",
      "EPOCH:   955 | BP | train loss: 0.1027 | test acc: 0.9816\n",
      "EPOCH:   956 | BP | train loss: 0.1026 | test acc: 0.9816\n",
      "EPOCH:   957 | BP | train loss: 0.1025 | test acc: 0.9816\n",
      "EPOCH:   958 | BP | train loss: 0.1024 | test acc: 0.9816\n",
      "EPOCH:   959 | BP | train loss: 0.1023 | test acc: 0.9816\n",
      "EPOCH:   960 | BP | train loss: 0.1023 | test acc: 0.9816\n",
      "EPOCH:   961 | BP | train loss: 0.1022 | test acc: 0.9816\n",
      "EPOCH:   962 | BP | train loss: 0.1021 | test acc: 0.9816\n",
      "EPOCH:   963 | BP | train loss: 0.1020 | test acc: 0.9816\n",
      "EPOCH:   964 | BP | train loss: 0.1020 | test acc: 0.9816\n",
      "EPOCH:   965 | BP | train loss: 0.1019 | test acc: 0.9816\n",
      "EPOCH:   966 | BP | train loss: 0.1018 | test acc: 0.9816\n",
      "EPOCH:   967 | BP | train loss: 0.1017 | test acc: 0.9816\n",
      "EPOCH:   968 | BP | train loss: 0.1016 | test acc: 0.9816\n",
      "EPOCH:   969 | BP | train loss: 0.1016 | test acc: 0.9816\n",
      "EPOCH:   970 | BP | train loss: 0.1015 | test acc: 0.9816\n",
      "EPOCH:   971 | BP | train loss: 0.1014 | test acc: 0.9816\n",
      "EPOCH:   972 | BP | train loss: 0.1013 | test acc: 0.9816\n",
      "EPOCH:   973 | BP | train loss: 0.1013 | test acc: 0.9816\n",
      "EPOCH:   974 | BP | train loss: 0.1012 | test acc: 0.9816\n",
      "EPOCH:   975 | BP | train loss: 0.1011 | test acc: 0.9816\n",
      "EPOCH:   976 | BP | train loss: 0.1010 | test acc: 0.9816\n",
      "EPOCH:   977 | BP | train loss: 0.1010 | test acc: 0.9816\n",
      "EPOCH:   978 | BP | train loss: 0.1009 | test acc: 0.9816\n",
      "EPOCH:   979 | BP | train loss: 0.1008 | test acc: 0.9816\n",
      "EPOCH:   980 | BP | train loss: 0.1007 | test acc: 0.9816\n",
      "EPOCH:   981 | BP | train loss: 0.1007 | test acc: 0.9816\n",
      "EPOCH:   982 | BP | train loss: 0.1006 | test acc: 0.9816\n",
      "EPOCH:   983 | BP | train loss: 0.1005 | test acc: 0.9816\n",
      "EPOCH:   984 | BP | train loss: 0.1004 | test acc: 0.9816\n",
      "EPOCH:   985 | BP | train loss: 0.1004 | test acc: 0.9816\n",
      "EPOCH:   986 | BP | train loss: 0.1003 | test acc: 0.9816\n",
      "EPOCH:   987 | BP | train loss: 0.1002 | test acc: 0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   988 | BP | train loss: 0.1001 | test acc: 0.9816\n",
      "EPOCH:   989 | BP | train loss: 0.1001 | test acc: 0.9816\n",
      "EPOCH:   990 | BP | train loss: 0.1000 | test acc: 0.9816\n",
      "EPOCH:   991 | BP | train loss: 0.0999 | test acc: 0.9816\n",
      "EPOCH:   992 | BP | train loss: 0.0998 | test acc: 0.9816\n",
      "EPOCH:   993 | BP | train loss: 0.0998 | test acc: 0.9816\n",
      "EPOCH:   994 | BP | train loss: 0.0997 | test acc: 0.9816\n",
      "EPOCH:   995 | BP | train loss: 0.0996 | test acc: 0.9816\n",
      "EPOCH:   996 | BP | train loss: 0.0995 | test acc: 0.9816\n",
      "EPOCH:   997 | BP | train loss: 0.0995 | test acc: 0.9816\n",
      "EPOCH:   998 | BP | train loss: 0.0994 | test acc: 0.9816\n",
      "EPOCH:   999 | BP | train loss: 0.0993 | test acc: 0.9816\n",
      "EPOCH:  1000 | BP | train loss: 0.0992 | test acc: 0.9816\n",
      "==================== finish training ====================\n",
      "  training time: 26.35 s\n",
      "  reach best train loss 0.0992 at epoch 1000\n",
      "  reach best test acc 0.9816 at epoch 928\n",
      "  reach 0.96 acc in 10.45 s\n",
      "  reach 0.98 acc in 23.02 s\n",
      "--------------------------------------------------\n",
      "Train Params:\n",
      "  zs: [3. 3. 1. 1.]\n",
      "  beta: 0.99\n",
      "  cbp_epoch: 150\n",
      "  max_epoch: 1000\n",
      "  cbp_lr: 0.1\n",
      "  bp_lr: 0.1\n",
      "  bp_momentum: 0\n",
      "  bp_adam: False\n",
      "  logfile: results/toy/digits/64-129-10/CBP_CE_relu_initNone_seed7/train.log\n",
      "--------------------------------------------------\n",
      "==================== start training ====================\n",
      "EPOCH:     1 | CBP | train loss: 2.2897 | test acc: 0.0985\n",
      "EPOCH:     2 | CBP | train loss: 56.8014 | test acc: 0.1013\n",
      "EPOCH:     3 | CBP | train loss: 2.5828 | test acc: 0.1013\n",
      "EPOCH:     4 | CBP | train loss: 488.9368 | test acc: 0.0985\n",
      "EPOCH:     5 | CBP | train loss: 318.6018 | test acc: 0.1013\n",
      "EPOCH:     6 | CBP | train loss: 14.8369 | test acc: 0.1013\n",
      "EPOCH:     7 | CBP | train loss: 2025.3402 | test acc: 0.1007\n",
      "EPOCH:     8 | CBP | train loss: 315.3334 | test acc: 0.1013\n",
      "EPOCH:     9 | CBP | train loss: 9.1499 | test acc: 0.0985\n",
      "EPOCH:    10 | CBP | train loss: 3590.9209 | test acc: 0.1018\n",
      "EPOCH:    11 | CBP | train loss: 176.7609 | test acc: 0.0985\n",
      "EPOCH:    12 | CBP | train loss: 64.5388 | test acc: 0.1007\n",
      "EPOCH:    13 | CBP | train loss: 708.6569 | test acc: 0.1002\n",
      "EPOCH:    14 | CBP | train loss: 284.9856 | test acc: 0.1007\n",
      "EPOCH:    15 | CBP | train loss: 300.6297 | test acc: 0.1013\n",
      "EPOCH:    16 | CBP | train loss: 1516.9640 | test acc: 0.0985\n",
      "EPOCH:    17 | CBP | train loss: 570.0437 | test acc: 0.1013\n",
      "EPOCH:    18 | CBP | train loss: 212.7542 | test acc: 0.0985\n",
      "EPOCH:    19 | CBP | train loss: 1617.8320 | test acc: 0.1007\n",
      "EPOCH:    20 | CBP | train loss: 1069.5754 | test acc: 0.1514\n",
      "EPOCH:    21 | CBP | train loss: 164.7950 | test acc: 0.1002\n",
      "EPOCH:    22 | CBP | train loss: 1088.5192 | test acc: 0.1013\n",
      "EPOCH:    23 | CBP | train loss: 917.4049 | test acc: 0.0996\n",
      "EPOCH:    24 | CBP | train loss: 434.0860 | test acc: 0.1007\n",
      "EPOCH:    25 | CBP | train loss: 795.6838 | test acc: 0.1002\n",
      "EPOCH:    26 | CBP | train loss: 409.6578 | test acc: 0.0985\n",
      "EPOCH:    27 | CBP | train loss: 353.1655 | test acc: 0.1013\n",
      "EPOCH:    28 | CBP | train loss: 2329.1677 | test acc: 0.1252\n",
      "EPOCH:    29 | CBP | train loss: 286.4524 | test acc: 0.1013\n",
      "EPOCH:    30 | CBP | train loss: 288.0910 | test acc: 0.0985\n",
      "EPOCH:    31 | CBP | train loss: 1327.5341 | test acc: 0.2098\n",
      "EPOCH:    32 | CBP | train loss: 324.4617 | test acc: 0.1007\n",
      "EPOCH:    33 | CBP | train loss: 425.9749 | test acc: 0.0996\n",
      "EPOCH:    34 | CBP | train loss: 868.1388 | test acc: 0.0985\n",
      "EPOCH:    35 | CBP | train loss: 1199.0688 | test acc: 0.1002\n",
      "EPOCH:    36 | CBP | train loss: 406.4418 | test acc: 0.1002\n",
      "EPOCH:    37 | CBP | train loss: 864.4268 | test acc: 0.1007\n",
      "EPOCH:    38 | CBP | train loss: 363.0014 | test acc: 0.1024\n",
      "EPOCH:    39 | CBP | train loss: 236.7589 | test acc: 0.0968\n",
      "EPOCH:    40 | CBP | train loss: 811.3061 | test acc: 0.1002\n",
      "EPOCH:    41 | CBP | train loss: 426.2482 | test acc: 0.1541\n",
      "EPOCH:    42 | CBP | train loss: 233.4841 | test acc: 0.0991\n",
      "EPOCH:    43 | CBP | train loss: 861.3433 | test acc: 0.1018\n",
      "EPOCH:    44 | CBP | train loss: 257.2378 | test acc: 0.1002\n",
      "EPOCH:    45 | CBP | train loss: 351.4203 | test acc: 0.1007\n",
      "EPOCH:    46 | CBP | train loss: 1038.9839 | test acc: 0.1263\n",
      "EPOCH:    47 | CBP | train loss: 190.4919 | test acc: 0.1018\n",
      "EPOCH:    48 | CBP | train loss: 330.8565 | test acc: 0.1002\n",
      "EPOCH:    49 | CBP | train loss: 1734.7164 | test acc: 0.1503\n",
      "EPOCH:    50 | CBP | train loss: 260.5054 | test acc: 0.0991\n",
      "EPOCH:    51 | CBP | train loss: 305.1447 | test acc: 0.1018\n",
      "EPOCH:    52 | CBP | train loss: 1649.9355 | test acc: 0.1213\n",
      "EPOCH:    53 | CBP | train loss: 267.6591 | test acc: 0.1002\n",
      "EPOCH:    54 | CBP | train loss: 188.3772 | test acc: 0.0985\n",
      "EPOCH:    55 | CBP | train loss: 1263.0446 | test acc: 0.1002\n",
      "EPOCH:    56 | CBP | train loss: 293.7112 | test acc: 0.0996\n",
      "EPOCH:    57 | CBP | train loss: 317.1357 | test acc: 0.1013\n",
      "EPOCH:    58 | CBP | train loss: 1220.3768 | test acc: 0.1937\n",
      "EPOCH:    59 | CBP | train loss: 210.8181 | test acc: 0.1007\n",
      "EPOCH:    60 | CBP | train loss: 281.1658 | test acc: 0.0996\n",
      "EPOCH:    61 | CBP | train loss: 1297.4889 | test acc: 0.1024\n",
      "EPOCH:    62 | CBP | train loss: 239.6935 | test acc: 0.0968\n",
      "EPOCH:    63 | CBP | train loss: 216.2868 | test acc: 0.1452\n",
      "EPOCH:    64 | CBP | train loss: 649.2072 | test acc: 0.1013\n",
      "EPOCH:    65 | CBP | train loss: 254.5104 | test acc: 0.2226\n",
      "EPOCH:    66 | CBP | train loss: 113.4654 | test acc: 0.1007\n",
      "EPOCH:    67 | CBP | train loss: 802.2254 | test acc: 0.1931\n",
      "EPOCH:    68 | CBP | train loss: 243.8516 | test acc: 0.1731\n",
      "EPOCH:    69 | CBP | train loss: 162.2976 | test acc: 0.1447\n",
      "EPOCH:    70 | CBP | train loss: 378.6757 | test acc: 0.1063\n",
      "EPOCH:    71 | CBP | train loss: 185.4909 | test acc: 0.1920\n",
      "EPOCH:    72 | CBP | train loss: 107.7266 | test acc: 0.1013\n",
      "EPOCH:    73 | CBP | train loss: 865.1889 | test acc: 0.2326\n",
      "EPOCH:    74 | CBP | train loss: 139.5865 | test acc: 0.1024\n",
      "EPOCH:    75 | CBP | train loss: 144.3112 | test acc: 0.2009\n",
      "EPOCH:    76 | CBP | train loss: 279.0043 | test acc: 0.2109\n",
      "EPOCH:    77 | CBP | train loss: 132.1692 | test acc: 0.1202\n",
      "EPOCH:    78 | CBP | train loss: 130.5033 | test acc: 0.1959\n",
      "EPOCH:    79 | CBP | train loss: 399.6064 | test acc: 0.1107\n",
      "EPOCH:    80 | CBP | train loss: 154.4718 | test acc: 0.1130\n",
      "EPOCH:    81 | CBP | train loss: 128.6764 | test acc: 0.1013\n",
      "EPOCH:    82 | CBP | train loss: 761.3691 | test acc: 0.2009\n",
      "EPOCH:    83 | CBP | train loss: 80.2124 | test acc: 0.2615\n",
      "EPOCH:    84 | CBP | train loss: 87.2715 | test acc: 0.1002\n",
      "EPOCH:    85 | CBP | train loss: 471.3026 | test acc: 0.1263\n",
      "EPOCH:    86 | CBP | train loss: 164.3780 | test acc: 0.2065\n",
      "EPOCH:    87 | CBP | train loss: 62.4515 | test acc: 0.1007\n",
      "EPOCH:    88 | CBP | train loss: 181.2771 | test acc: 0.3728\n",
      "EPOCH:    89 | CBP | train loss: 32.5069 | test acc: 0.1074\n",
      "EPOCH:    90 | CBP | train loss: 146.0528 | test acc: 0.1107\n",
      "EPOCH:    91 | CBP | train loss: 185.1163 | test acc: 0.1007\n",
      "EPOCH:    92 | CBP | train loss: 159.5371 | test acc: 0.3356\n",
      "EPOCH:    93 | CBP | train loss: 55.9403 | test acc: 0.2059\n",
      "EPOCH:    94 | CBP | train loss: 120.5411 | test acc: 0.1369\n",
      "EPOCH:    95 | CBP | train loss: 70.0811 | test acc: 0.1981\n",
      "EPOCH:    96 | CBP | train loss: 90.0915 | test acc: 0.2393\n",
      "EPOCH:    97 | CBP | train loss: 106.1757 | test acc: 0.2615\n",
      "EPOCH:    98 | CBP | train loss: 87.8629 | test acc: 0.2332\n",
      "EPOCH:    99 | CBP | train loss: 84.9288 | test acc: 0.2627\n",
      "EPOCH:   100 | CBP | train loss: 46.8752 | test acc: 0.1886\n",
      "EPOCH:   101 | CBP | train loss: 72.8262 | test acc: 0.2944\n",
      "EPOCH:   102 | CBP | train loss: 54.5587 | test acc: 0.1018\n",
      "EPOCH:   103 | CBP | train loss: 101.2032 | test acc: 0.2582\n",
      "EPOCH:   104 | CBP | train loss: 51.7027 | test acc: 0.2181\n",
      "EPOCH:   105 | CBP | train loss: 40.9396 | test acc: 0.1825\n",
      "EPOCH:   106 | CBP | train loss: 53.2910 | test acc: 0.2293\n",
      "EPOCH:   107 | CBP | train loss: 47.2487 | test acc: 0.2037\n",
      "EPOCH:   108 | CBP | train loss: 77.7424 | test acc: 0.2059\n",
      "EPOCH:   109 | CBP | train loss: 53.6844 | test acc: 0.4318\n",
      "EPOCH:   110 | CBP | train loss: 22.3414 | test acc: 0.2643\n",
      "EPOCH:   111 | CBP | train loss: 31.6276 | test acc: 0.2743\n",
      "EPOCH:   112 | CBP | train loss: 41.0865 | test acc: 0.3200\n",
      "EPOCH:   113 | CBP | train loss: 23.6576 | test acc: 0.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   114 | CBP | train loss: 32.7886 | test acc: 0.4240\n",
      "EPOCH:   115 | CBP | train loss: 23.2754 | test acc: 0.3239\n",
      "EPOCH:   116 | CBP | train loss: 32.6965 | test acc: 0.2538\n",
      "EPOCH:   117 | CBP | train loss: 46.5722 | test acc: 0.2782\n",
      "EPOCH:   118 | CBP | train loss: 46.1337 | test acc: 0.3612\n",
      "EPOCH:   119 | CBP | train loss: 30.7429 | test acc: 0.3322\n",
      "EPOCH:   120 | CBP | train loss: 33.0068 | test acc: 0.4441\n",
      "EPOCH:   121 | CBP | train loss: 17.3806 | test acc: 0.3495\n",
      "EPOCH:   122 | CBP | train loss: 28.1170 | test acc: 0.3439\n",
      "EPOCH:   123 | CBP | train loss: 18.8208 | test acc: 0.5298\n",
      "EPOCH:   124 | CBP | train loss: 22.6482 | test acc: 0.3984\n",
      "EPOCH:   125 | CBP | train loss: 20.8653 | test acc: 0.5743\n",
      "EPOCH:   126 | CBP | train loss: 13.5063 | test acc: 0.4424\n",
      "EPOCH:   127 | CBP | train loss: 15.4743 | test acc: 0.4446\n",
      "EPOCH:   128 | CBP | train loss: 19.4557 | test acc: 0.6427\n",
      "EPOCH:   129 | CBP | train loss: 8.5149 | test acc: 0.4958\n",
      "EPOCH:   130 | CBP | train loss: 16.9734 | test acc: 0.6372\n",
      "EPOCH:   131 | CBP | train loss: 10.4068 | test acc: 0.7001\n",
      "EPOCH:   132 | CBP | train loss: 6.6458 | test acc: 0.7212\n",
      "EPOCH:   133 | CBP | train loss: 5.1712 | test acc: 0.6422\n",
      "EPOCH:   134 | CBP | train loss: 7.8465 | test acc: 0.7090\n",
      "EPOCH:   135 | CBP | train loss: 5.4133 | test acc: 0.7401\n",
      "EPOCH:   136 | CBP | train loss: 5.7351 | test acc: 0.7090\n",
      "EPOCH:   137 | CBP | train loss: 5.6727 | test acc: 0.8041\n",
      "EPOCH:   138 | CBP | train loss: 3.1662 | test acc: 0.8086\n",
      "EPOCH:   139 | CBP | train loss: 3.0801 | test acc: 0.8325\n",
      "EPOCH:   140 | CBP | train loss: 2.8867 | test acc: 0.8147\n",
      "EPOCH:   141 | CBP | train loss: 3.0697 | test acc: 0.8058\n",
      "EPOCH:   142 | CBP | train loss: 3.6966 | test acc: 0.8286\n",
      "EPOCH:   143 | CBP | train loss: 2.7210 | test acc: 0.8063\n",
      "EPOCH:   144 | CBP | train loss: 3.5775 | test acc: 0.8475\n",
      "EPOCH:   145 | CBP | train loss: 2.3234 | test acc: 0.8258\n",
      "EPOCH:   146 | CBP | train loss: 3.1053 | test acc: 0.8681\n",
      "EPOCH:   147 | CBP | train loss: 1.9825 | test acc: 0.8431\n",
      "EPOCH:   148 | CBP | train loss: 2.6556 | test acc: 0.8809\n",
      "EPOCH:   149 | CBP | train loss: 1.8962 | test acc: 0.8520\n",
      "EPOCH:   150 | CBP | train loss: 2.5236 | test acc: 0.8820\n",
      "EPOCH:   151 | BP | train loss: 1.9204 | test acc: 0.8904\n",
      "EPOCH:   152 | BP | train loss: 1.6583 | test acc: 0.8943\n",
      "EPOCH:   153 | BP | train loss: 1.4785 | test acc: 0.8982\n",
      "EPOCH:   154 | BP | train loss: 1.3488 | test acc: 0.9037\n",
      "EPOCH:   155 | BP | train loss: 1.2624 | test acc: 0.9043\n",
      "EPOCH:   156 | BP | train loss: 1.2006 | test acc: 0.9087\n",
      "EPOCH:   157 | BP | train loss: 1.1552 | test acc: 0.9076\n",
      "EPOCH:   158 | BP | train loss: 1.1191 | test acc: 0.9082\n",
      "EPOCH:   159 | BP | train loss: 1.0875 | test acc: 0.9093\n",
      "EPOCH:   160 | BP | train loss: 1.0584 | test acc: 0.9093\n",
      "EPOCH:   161 | BP | train loss: 1.0311 | test acc: 0.9104\n",
      "EPOCH:   162 | BP | train loss: 1.0053 | test acc: 0.9126\n",
      "EPOCH:   163 | BP | train loss: 0.9810 | test acc: 0.9154\n",
      "EPOCH:   164 | BP | train loss: 0.9579 | test acc: 0.9171\n",
      "EPOCH:   165 | BP | train loss: 0.9358 | test acc: 0.9193\n",
      "EPOCH:   166 | BP | train loss: 0.9147 | test acc: 0.9215\n",
      "EPOCH:   167 | BP | train loss: 0.8946 | test acc: 0.9226\n",
      "EPOCH:   168 | BP | train loss: 0.8756 | test acc: 0.9238\n",
      "EPOCH:   169 | BP | train loss: 0.8574 | test acc: 0.9243\n",
      "EPOCH:   170 | BP | train loss: 0.8400 | test acc: 0.9249\n",
      "EPOCH:   171 | BP | train loss: 0.8234 | test acc: 0.9265\n",
      "EPOCH:   172 | BP | train loss: 0.8076 | test acc: 0.9277\n",
      "EPOCH:   173 | BP | train loss: 0.7925 | test acc: 0.9282\n",
      "EPOCH:   174 | BP | train loss: 0.7779 | test acc: 0.9277\n",
      "EPOCH:   175 | BP | train loss: 0.7639 | test acc: 0.9293\n",
      "EPOCH:   176 | BP | train loss: 0.7502 | test acc: 0.9316\n",
      "EPOCH:   177 | BP | train loss: 0.7370 | test acc: 0.9321\n",
      "EPOCH:   178 | BP | train loss: 0.7241 | test acc: 0.9338\n",
      "EPOCH:   179 | BP | train loss: 0.7116 | test acc: 0.9343\n",
      "EPOCH:   180 | BP | train loss: 0.6995 | test acc: 0.9343\n",
      "EPOCH:   181 | BP | train loss: 0.6877 | test acc: 0.9349\n",
      "EPOCH:   182 | BP | train loss: 0.6762 | test acc: 0.9360\n",
      "EPOCH:   183 | BP | train loss: 0.6651 | test acc: 0.9360\n",
      "EPOCH:   184 | BP | train loss: 0.6543 | test acc: 0.9366\n",
      "EPOCH:   185 | BP | train loss: 0.6438 | test acc: 0.9366\n",
      "EPOCH:   186 | BP | train loss: 0.6338 | test acc: 0.9382\n",
      "EPOCH:   187 | BP | train loss: 0.6242 | test acc: 0.9382\n",
      "EPOCH:   188 | BP | train loss: 0.6149 | test acc: 0.9388\n",
      "EPOCH:   189 | BP | train loss: 0.6059 | test acc: 0.9393\n",
      "EPOCH:   190 | BP | train loss: 0.5973 | test acc: 0.9393\n",
      "EPOCH:   191 | BP | train loss: 0.5889 | test acc: 0.9393\n",
      "EPOCH:   192 | BP | train loss: 0.5808 | test acc: 0.9393\n",
      "EPOCH:   193 | BP | train loss: 0.5731 | test acc: 0.9399\n",
      "EPOCH:   194 | BP | train loss: 0.5655 | test acc: 0.9410\n",
      "EPOCH:   195 | BP | train loss: 0.5582 | test acc: 0.9416\n",
      "EPOCH:   196 | BP | train loss: 0.5512 | test acc: 0.9427\n",
      "EPOCH:   197 | BP | train loss: 0.5444 | test acc: 0.9438\n",
      "EPOCH:   198 | BP | train loss: 0.5379 | test acc: 0.9438\n",
      "EPOCH:   199 | BP | train loss: 0.5316 | test acc: 0.9444\n",
      "EPOCH:   200 | BP | train loss: 0.5255 | test acc: 0.9444\n",
      "EPOCH:   201 | BP | train loss: 0.5196 | test acc: 0.9449\n",
      "EPOCH:   202 | BP | train loss: 0.5139 | test acc: 0.9455\n",
      "EPOCH:   203 | BP | train loss: 0.5083 | test acc: 0.9455\n",
      "EPOCH:   204 | BP | train loss: 0.5028 | test acc: 0.9455\n",
      "EPOCH:   205 | BP | train loss: 0.4975 | test acc: 0.9455\n",
      "EPOCH:   206 | BP | train loss: 0.4924 | test acc: 0.9455\n",
      "EPOCH:   207 | BP | train loss: 0.4873 | test acc: 0.9460\n",
      "EPOCH:   208 | BP | train loss: 0.4824 | test acc: 0.9460\n",
      "EPOCH:   209 | BP | train loss: 0.4776 | test acc: 0.9460\n",
      "EPOCH:   210 | BP | train loss: 0.4728 | test acc: 0.9460\n",
      "EPOCH:   211 | BP | train loss: 0.4682 | test acc: 0.9471\n",
      "EPOCH:   212 | BP | train loss: 0.4636 | test acc: 0.9471\n",
      "EPOCH:   213 | BP | train loss: 0.4592 | test acc: 0.9477\n",
      "EPOCH:   214 | BP | train loss: 0.4547 | test acc: 0.9477\n",
      "EPOCH:   215 | BP | train loss: 0.4503 | test acc: 0.9482\n",
      "EPOCH:   216 | BP | train loss: 0.4460 | test acc: 0.9482\n",
      "EPOCH:   217 | BP | train loss: 0.4418 | test acc: 0.9482\n",
      "EPOCH:   218 | BP | train loss: 0.4376 | test acc: 0.9482\n",
      "EPOCH:   219 | BP | train loss: 0.4336 | test acc: 0.9482\n",
      "EPOCH:   220 | BP | train loss: 0.4297 | test acc: 0.9488\n",
      "EPOCH:   221 | BP | train loss: 0.4259 | test acc: 0.9499\n",
      "EPOCH:   222 | BP | train loss: 0.4222 | test acc: 0.9499\n",
      "EPOCH:   223 | BP | train loss: 0.4185 | test acc: 0.9505\n",
      "EPOCH:   224 | BP | train loss: 0.4149 | test acc: 0.9505\n",
      "EPOCH:   225 | BP | train loss: 0.4114 | test acc: 0.9510\n",
      "EPOCH:   226 | BP | train loss: 0.4080 | test acc: 0.9510\n",
      "EPOCH:   227 | BP | train loss: 0.4046 | test acc: 0.9516\n",
      "EPOCH:   228 | BP | train loss: 0.4012 | test acc: 0.9516\n",
      "EPOCH:   229 | BP | train loss: 0.3979 | test acc: 0.9527\n",
      "EPOCH:   230 | BP | train loss: 0.3947 | test acc: 0.9527\n",
      "EPOCH:   231 | BP | train loss: 0.3915 | test acc: 0.9527\n",
      "EPOCH:   232 | BP | train loss: 0.3884 | test acc: 0.9527\n",
      "EPOCH:   233 | BP | train loss: 0.3853 | test acc: 0.9527\n",
      "EPOCH:   234 | BP | train loss: 0.3823 | test acc: 0.9527\n",
      "EPOCH:   235 | BP | train loss: 0.3793 | test acc: 0.9527\n",
      "EPOCH:   236 | BP | train loss: 0.3763 | test acc: 0.9527\n",
      "EPOCH:   237 | BP | train loss: 0.3735 | test acc: 0.9527\n",
      "EPOCH:   238 | BP | train loss: 0.3706 | test acc: 0.9527\n",
      "EPOCH:   239 | BP | train loss: 0.3678 | test acc: 0.9527\n",
      "EPOCH:   240 | BP | train loss: 0.3651 | test acc: 0.9538\n",
      "EPOCH:   241 | BP | train loss: 0.3624 | test acc: 0.9533\n",
      "EPOCH:   242 | BP | train loss: 0.3597 | test acc: 0.9533\n",
      "EPOCH:   243 | BP | train loss: 0.3571 | test acc: 0.9533\n",
      "EPOCH:   244 | BP | train loss: 0.3545 | test acc: 0.9538\n",
      "EPOCH:   245 | BP | train loss: 0.3519 | test acc: 0.9538\n",
      "EPOCH:   246 | BP | train loss: 0.3494 | test acc: 0.9544\n",
      "EPOCH:   247 | BP | train loss: 0.3469 | test acc: 0.9544\n",
      "EPOCH:   248 | BP | train loss: 0.3445 | test acc: 0.9538\n",
      "EPOCH:   249 | BP | train loss: 0.3421 | test acc: 0.9538\n",
      "EPOCH:   250 | BP | train loss: 0.3397 | test acc: 0.9544\n",
      "EPOCH:   251 | BP | train loss: 0.3374 | test acc: 0.9549\n",
      "EPOCH:   252 | BP | train loss: 0.3351 | test acc: 0.9549\n",
      "EPOCH:   253 | BP | train loss: 0.3329 | test acc: 0.9549\n",
      "EPOCH:   254 | BP | train loss: 0.3306 | test acc: 0.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   255 | BP | train loss: 0.3285 | test acc: 0.9555\n",
      "EPOCH:   256 | BP | train loss: 0.3263 | test acc: 0.9555\n",
      "EPOCH:   257 | BP | train loss: 0.3242 | test acc: 0.9555\n",
      "EPOCH:   258 | BP | train loss: 0.3221 | test acc: 0.9566\n",
      "EPOCH:   259 | BP | train loss: 0.3200 | test acc: 0.9566\n",
      "EPOCH:   260 | BP | train loss: 0.3180 | test acc: 0.9572\n",
      "EPOCH:   261 | BP | train loss: 0.3160 | test acc: 0.9572\n",
      "EPOCH:   262 | BP | train loss: 0.3140 | test acc: 0.9572\n",
      "EPOCH:   263 | BP | train loss: 0.3121 | test acc: 0.9572\n",
      "EPOCH:   264 | BP | train loss: 0.3101 | test acc: 0.9572\n",
      "EPOCH:   265 | BP | train loss: 0.3081 | test acc: 0.9572\n",
      "EPOCH:   266 | BP | train loss: 0.3062 | test acc: 0.9566\n",
      "EPOCH:   267 | BP | train loss: 0.3042 | test acc: 0.9566\n",
      "EPOCH:   268 | BP | train loss: 0.3023 | test acc: 0.9566\n",
      "EPOCH:   269 | BP | train loss: 0.3004 | test acc: 0.9566\n",
      "EPOCH:   270 | BP | train loss: 0.2985 | test acc: 0.9572\n",
      "EPOCH:   271 | BP | train loss: 0.2967 | test acc: 0.9572\n",
      "EPOCH:   272 | BP | train loss: 0.2948 | test acc: 0.9572\n",
      "EPOCH:   273 | BP | train loss: 0.2930 | test acc: 0.9577\n",
      "EPOCH:   274 | BP | train loss: 0.2912 | test acc: 0.9577\n",
      "EPOCH:   275 | BP | train loss: 0.2894 | test acc: 0.9577\n",
      "EPOCH:   276 | BP | train loss: 0.2876 | test acc: 0.9577\n",
      "EPOCH:   277 | BP | train loss: 0.2859 | test acc: 0.9583\n",
      "EPOCH:   278 | BP | train loss: 0.2841 | test acc: 0.9583\n",
      "EPOCH:   279 | BP | train loss: 0.2824 | test acc: 0.9588\n",
      "EPOCH:   280 | BP | train loss: 0.2807 | test acc: 0.9588\n",
      "EPOCH:   281 | BP | train loss: 0.2791 | test acc: 0.9588\n",
      "EPOCH:   282 | BP | train loss: 0.2774 | test acc: 0.9588\n",
      "EPOCH:   283 | BP | train loss: 0.2758 | test acc: 0.9594\n",
      "EPOCH:   284 | BP | train loss: 0.2741 | test acc: 0.9594\n",
      "EPOCH:   285 | BP | train loss: 0.2725 | test acc: 0.9594\n",
      "EPOCH:   286 | BP | train loss: 0.2709 | test acc: 0.9594\n",
      "EPOCH:   287 | BP | train loss: 0.2693 | test acc: 0.9599\n",
      "EPOCH:   288 | BP | train loss: 0.2677 | test acc: 0.9599\n",
      "EPOCH:   289 | BP | train loss: 0.2661 | test acc: 0.9605\n",
      "EPOCH:   290 | BP | train loss: 0.2646 | test acc: 0.9605\n",
      "EPOCH:   291 | BP | train loss: 0.2631 | test acc: 0.9605\n",
      "EPOCH:   292 | BP | train loss: 0.2615 | test acc: 0.9605\n",
      "EPOCH:   293 | BP | train loss: 0.2600 | test acc: 0.9605\n",
      "EPOCH:   294 | BP | train loss: 0.2585 | test acc: 0.9605\n",
      "EPOCH:   295 | BP | train loss: 0.2570 | test acc: 0.9610\n",
      "EPOCH:   296 | BP | train loss: 0.2556 | test acc: 0.9610\n",
      "EPOCH:   297 | BP | train loss: 0.2541 | test acc: 0.9616\n",
      "EPOCH:   298 | BP | train loss: 0.2527 | test acc: 0.9616\n",
      "EPOCH:   299 | BP | train loss: 0.2513 | test acc: 0.9616\n",
      "EPOCH:   300 | BP | train loss: 0.2499 | test acc: 0.9616\n",
      "EPOCH:   301 | BP | train loss: 0.2485 | test acc: 0.9622\n",
      "EPOCH:   302 | BP | train loss: 0.2471 | test acc: 0.9622\n",
      "EPOCH:   303 | BP | train loss: 0.2457 | test acc: 0.9622\n",
      "EPOCH:   304 | BP | train loss: 0.2443 | test acc: 0.9622\n",
      "EPOCH:   305 | BP | train loss: 0.2430 | test acc: 0.9622\n",
      "EPOCH:   306 | BP | train loss: 0.2416 | test acc: 0.9622\n",
      "EPOCH:   307 | BP | train loss: 0.2403 | test acc: 0.9622\n",
      "EPOCH:   308 | BP | train loss: 0.2389 | test acc: 0.9622\n",
      "EPOCH:   309 | BP | train loss: 0.2376 | test acc: 0.9622\n",
      "EPOCH:   310 | BP | train loss: 0.2363 | test acc: 0.9622\n",
      "EPOCH:   311 | BP | train loss: 0.2350 | test acc: 0.9622\n",
      "EPOCH:   312 | BP | train loss: 0.2337 | test acc: 0.9622\n",
      "EPOCH:   313 | BP | train loss: 0.2324 | test acc: 0.9622\n",
      "EPOCH:   314 | BP | train loss: 0.2311 | test acc: 0.9627\n",
      "EPOCH:   315 | BP | train loss: 0.2298 | test acc: 0.9627\n",
      "EPOCH:   316 | BP | train loss: 0.2285 | test acc: 0.9633\n",
      "EPOCH:   317 | BP | train loss: 0.2273 | test acc: 0.9638\n",
      "EPOCH:   318 | BP | train loss: 0.2261 | test acc: 0.9644\n",
      "EPOCH:   319 | BP | train loss: 0.2249 | test acc: 0.9644\n",
      "EPOCH:   320 | BP | train loss: 0.2237 | test acc: 0.9644\n",
      "EPOCH:   321 | BP | train loss: 0.2225 | test acc: 0.9644\n",
      "EPOCH:   322 | BP | train loss: 0.2213 | test acc: 0.9638\n",
      "EPOCH:   323 | BP | train loss: 0.2202 | test acc: 0.9644\n",
      "EPOCH:   324 | BP | train loss: 0.2190 | test acc: 0.9644\n",
      "EPOCH:   325 | BP | train loss: 0.2179 | test acc: 0.9644\n",
      "EPOCH:   326 | BP | train loss: 0.2168 | test acc: 0.9644\n",
      "EPOCH:   327 | BP | train loss: 0.2157 | test acc: 0.9649\n",
      "EPOCH:   328 | BP | train loss: 0.2146 | test acc: 0.9649\n",
      "EPOCH:   329 | BP | train loss: 0.2136 | test acc: 0.9655\n",
      "EPOCH:   330 | BP | train loss: 0.2125 | test acc: 0.9666\n",
      "EPOCH:   331 | BP | train loss: 0.2114 | test acc: 0.9666\n",
      "EPOCH:   332 | BP | train loss: 0.2104 | test acc: 0.9672\n",
      "EPOCH:   333 | BP | train loss: 0.2094 | test acc: 0.9672\n",
      "EPOCH:   334 | BP | train loss: 0.2084 | test acc: 0.9677\n",
      "EPOCH:   335 | BP | train loss: 0.2073 | test acc: 0.9683\n",
      "EPOCH:   336 | BP | train loss: 0.2063 | test acc: 0.9683\n",
      "EPOCH:   337 | BP | train loss: 0.2054 | test acc: 0.9683\n",
      "EPOCH:   338 | BP | train loss: 0.2044 | test acc: 0.9683\n",
      "EPOCH:   339 | BP | train loss: 0.2034 | test acc: 0.9688\n",
      "EPOCH:   340 | BP | train loss: 0.2024 | test acc: 0.9688\n",
      "EPOCH:   341 | BP | train loss: 0.2015 | test acc: 0.9688\n",
      "EPOCH:   342 | BP | train loss: 0.2005 | test acc: 0.9688\n",
      "EPOCH:   343 | BP | train loss: 0.1996 | test acc: 0.9688\n",
      "EPOCH:   344 | BP | train loss: 0.1987 | test acc: 0.9688\n",
      "EPOCH:   345 | BP | train loss: 0.1977 | test acc: 0.9688\n",
      "EPOCH:   346 | BP | train loss: 0.1968 | test acc: 0.9688\n",
      "EPOCH:   347 | BP | train loss: 0.1959 | test acc: 0.9688\n",
      "EPOCH:   348 | BP | train loss: 0.1950 | test acc: 0.9688\n",
      "EPOCH:   349 | BP | train loss: 0.1941 | test acc: 0.9688\n",
      "EPOCH:   350 | BP | train loss: 0.1932 | test acc: 0.9688\n",
      "EPOCH:   351 | BP | train loss: 0.1924 | test acc: 0.9694\n",
      "EPOCH:   352 | BP | train loss: 0.1915 | test acc: 0.9694\n",
      "EPOCH:   353 | BP | train loss: 0.1906 | test acc: 0.9694\n",
      "EPOCH:   354 | BP | train loss: 0.1898 | test acc: 0.9694\n",
      "EPOCH:   355 | BP | train loss: 0.1889 | test acc: 0.9699\n",
      "EPOCH:   356 | BP | train loss: 0.1881 | test acc: 0.9699\n",
      "EPOCH:   357 | BP | train loss: 0.1873 | test acc: 0.9705\n",
      "EPOCH:   358 | BP | train loss: 0.1864 | test acc: 0.9711\n",
      "EPOCH:   359 | BP | train loss: 0.1856 | test acc: 0.9711\n",
      "EPOCH:   360 | BP | train loss: 0.1848 | test acc: 0.9711\n",
      "EPOCH:   361 | BP | train loss: 0.1840 | test acc: 0.9711\n",
      "EPOCH:   362 | BP | train loss: 0.1832 | test acc: 0.9711\n",
      "EPOCH:   363 | BP | train loss: 0.1824 | test acc: 0.9711\n",
      "EPOCH:   364 | BP | train loss: 0.1815 | test acc: 0.9711\n",
      "EPOCH:   365 | BP | train loss: 0.1807 | test acc: 0.9716\n",
      "EPOCH:   366 | BP | train loss: 0.1799 | test acc: 0.9716\n",
      "EPOCH:   367 | BP | train loss: 0.1792 | test acc: 0.9716\n",
      "EPOCH:   368 | BP | train loss: 0.1784 | test acc: 0.9716\n",
      "EPOCH:   369 | BP | train loss: 0.1776 | test acc: 0.9716\n",
      "EPOCH:   370 | BP | train loss: 0.1768 | test acc: 0.9716\n",
      "EPOCH:   371 | BP | train loss: 0.1760 | test acc: 0.9716\n",
      "EPOCH:   372 | BP | train loss: 0.1753 | test acc: 0.9716\n",
      "EPOCH:   373 | BP | train loss: 0.1745 | test acc: 0.9716\n",
      "EPOCH:   374 | BP | train loss: 0.1737 | test acc: 0.9716\n",
      "EPOCH:   375 | BP | train loss: 0.1729 | test acc: 0.9716\n",
      "EPOCH:   376 | BP | train loss: 0.1722 | test acc: 0.9716\n",
      "EPOCH:   377 | BP | train loss: 0.1714 | test acc: 0.9716\n",
      "EPOCH:   378 | BP | train loss: 0.1707 | test acc: 0.9722\n",
      "EPOCH:   379 | BP | train loss: 0.1699 | test acc: 0.9722\n",
      "EPOCH:   380 | BP | train loss: 0.1692 | test acc: 0.9722\n",
      "EPOCH:   381 | BP | train loss: 0.1684 | test acc: 0.9722\n",
      "EPOCH:   382 | BP | train loss: 0.1676 | test acc: 0.9722\n",
      "EPOCH:   383 | BP | train loss: 0.1669 | test acc: 0.9722\n",
      "EPOCH:   384 | BP | train loss: 0.1662 | test acc: 0.9722\n",
      "EPOCH:   385 | BP | train loss: 0.1654 | test acc: 0.9722\n",
      "EPOCH:   386 | BP | train loss: 0.1647 | test acc: 0.9722\n",
      "EPOCH:   387 | BP | train loss: 0.1639 | test acc: 0.9722\n",
      "EPOCH:   388 | BP | train loss: 0.1632 | test acc: 0.9722\n",
      "EPOCH:   389 | BP | train loss: 0.1625 | test acc: 0.9722\n",
      "EPOCH:   390 | BP | train loss: 0.1617 | test acc: 0.9727\n",
      "EPOCH:   391 | BP | train loss: 0.1610 | test acc: 0.9727\n",
      "EPOCH:   392 | BP | train loss: 0.1603 | test acc: 0.9727\n",
      "EPOCH:   393 | BP | train loss: 0.1595 | test acc: 0.9727\n",
      "EPOCH:   394 | BP | train loss: 0.1588 | test acc: 0.9727\n",
      "EPOCH:   395 | BP | train loss: 0.1581 | test acc: 0.9727\n",
      "EPOCH:   396 | BP | train loss: 0.1574 | test acc: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   397 | BP | train loss: 0.1567 | test acc: 0.9738\n",
      "EPOCH:   398 | BP | train loss: 0.1560 | test acc: 0.9738\n",
      "EPOCH:   399 | BP | train loss: 0.1553 | test acc: 0.9738\n",
      "EPOCH:   400 | BP | train loss: 0.1547 | test acc: 0.9738\n",
      "EPOCH:   401 | BP | train loss: 0.1540 | test acc: 0.9738\n",
      "EPOCH:   402 | BP | train loss: 0.1533 | test acc: 0.9738\n",
      "EPOCH:   403 | BP | train loss: 0.1526 | test acc: 0.9750\n",
      "EPOCH:   404 | BP | train loss: 0.1519 | test acc: 0.9750\n",
      "EPOCH:   405 | BP | train loss: 0.1513 | test acc: 0.9750\n",
      "EPOCH:   406 | BP | train loss: 0.1506 | test acc: 0.9750\n",
      "EPOCH:   407 | BP | train loss: 0.1500 | test acc: 0.9750\n",
      "EPOCH:   408 | BP | train loss: 0.1493 | test acc: 0.9750\n",
      "EPOCH:   409 | BP | train loss: 0.1487 | test acc: 0.9750\n",
      "EPOCH:   410 | BP | train loss: 0.1480 | test acc: 0.9750\n",
      "EPOCH:   411 | BP | train loss: 0.1474 | test acc: 0.9750\n",
      "EPOCH:   412 | BP | train loss: 0.1468 | test acc: 0.9750\n",
      "EPOCH:   413 | BP | train loss: 0.1462 | test acc: 0.9755\n",
      "EPOCH:   414 | BP | train loss: 0.1456 | test acc: 0.9755\n",
      "EPOCH:   415 | BP | train loss: 0.1449 | test acc: 0.9755\n",
      "EPOCH:   416 | BP | train loss: 0.1444 | test acc: 0.9755\n",
      "EPOCH:   417 | BP | train loss: 0.1438 | test acc: 0.9755\n",
      "EPOCH:   418 | BP | train loss: 0.1432 | test acc: 0.9755\n",
      "EPOCH:   419 | BP | train loss: 0.1426 | test acc: 0.9755\n",
      "EPOCH:   420 | BP | train loss: 0.1420 | test acc: 0.9755\n",
      "EPOCH:   421 | BP | train loss: 0.1414 | test acc: 0.9755\n",
      "EPOCH:   422 | BP | train loss: 0.1409 | test acc: 0.9755\n",
      "EPOCH:   423 | BP | train loss: 0.1403 | test acc: 0.9755\n",
      "EPOCH:   424 | BP | train loss: 0.1397 | test acc: 0.9761\n",
      "EPOCH:   425 | BP | train loss: 0.1392 | test acc: 0.9761\n",
      "EPOCH:   426 | BP | train loss: 0.1386 | test acc: 0.9761\n",
      "EPOCH:   427 | BP | train loss: 0.1381 | test acc: 0.9761\n",
      "EPOCH:   428 | BP | train loss: 0.1375 | test acc: 0.9766\n",
      "EPOCH:   429 | BP | train loss: 0.1370 | test acc: 0.9766\n",
      "EPOCH:   430 | BP | train loss: 0.1365 | test acc: 0.9766\n",
      "EPOCH:   431 | BP | train loss: 0.1359 | test acc: 0.9766\n",
      "EPOCH:   432 | BP | train loss: 0.1354 | test acc: 0.9766\n",
      "EPOCH:   433 | BP | train loss: 0.1349 | test acc: 0.9766\n",
      "EPOCH:   434 | BP | train loss: 0.1344 | test acc: 0.9766\n",
      "EPOCH:   435 | BP | train loss: 0.1338 | test acc: 0.9766\n",
      "EPOCH:   436 | BP | train loss: 0.1333 | test acc: 0.9772\n",
      "EPOCH:   437 | BP | train loss: 0.1328 | test acc: 0.9772\n",
      "EPOCH:   438 | BP | train loss: 0.1323 | test acc: 0.9772\n",
      "EPOCH:   439 | BP | train loss: 0.1318 | test acc: 0.9777\n",
      "EPOCH:   440 | BP | train loss: 0.1313 | test acc: 0.9783\n",
      "EPOCH:   441 | BP | train loss: 0.1308 | test acc: 0.9783\n",
      "EPOCH:   442 | BP | train loss: 0.1303 | test acc: 0.9789\n",
      "EPOCH:   443 | BP | train loss: 0.1298 | test acc: 0.9789\n",
      "EPOCH:   444 | BP | train loss: 0.1293 | test acc: 0.9789\n",
      "EPOCH:   445 | BP | train loss: 0.1288 | test acc: 0.9789\n",
      "EPOCH:   446 | BP | train loss: 0.1283 | test acc: 0.9789\n",
      "EPOCH:   447 | BP | train loss: 0.1278 | test acc: 0.9789\n",
      "EPOCH:   448 | BP | train loss: 0.1273 | test acc: 0.9789\n",
      "EPOCH:   449 | BP | train loss: 0.1268 | test acc: 0.9789\n",
      "EPOCH:   450 | BP | train loss: 0.1264 | test acc: 0.9789\n",
      "EPOCH:   451 | BP | train loss: 0.1259 | test acc: 0.9789\n",
      "EPOCH:   452 | BP | train loss: 0.1254 | test acc: 0.9789\n",
      "EPOCH:   453 | BP | train loss: 0.1249 | test acc: 0.9789\n",
      "EPOCH:   454 | BP | train loss: 0.1244 | test acc: 0.9794\n",
      "EPOCH:   455 | BP | train loss: 0.1239 | test acc: 0.9794\n",
      "EPOCH:   456 | BP | train loss: 0.1235 | test acc: 0.9794\n",
      "EPOCH:   457 | BP | train loss: 0.1230 | test acc: 0.9794\n",
      "EPOCH:   458 | BP | train loss: 0.1225 | test acc: 0.9794\n",
      "EPOCH:   459 | BP | train loss: 0.1221 | test acc: 0.9794\n",
      "EPOCH:   460 | BP | train loss: 0.1216 | test acc: 0.9794\n",
      "EPOCH:   461 | BP | train loss: 0.1211 | test acc: 0.9794\n",
      "EPOCH:   462 | BP | train loss: 0.1207 | test acc: 0.9794\n",
      "EPOCH:   463 | BP | train loss: 0.1202 | test acc: 0.9794\n",
      "EPOCH:   464 | BP | train loss: 0.1198 | test acc: 0.9794\n",
      "EPOCH:   465 | BP | train loss: 0.1193 | test acc: 0.9800\n",
      "EPOCH:   466 | BP | train loss: 0.1189 | test acc: 0.9800\n",
      "EPOCH:   467 | BP | train loss: 0.1184 | test acc: 0.9800\n",
      "EPOCH:   468 | BP | train loss: 0.1180 | test acc: 0.9800\n",
      "EPOCH:   469 | BP | train loss: 0.1175 | test acc: 0.9800\n",
      "EPOCH:   470 | BP | train loss: 0.1171 | test acc: 0.9800\n",
      "EPOCH:   471 | BP | train loss: 0.1167 | test acc: 0.9800\n",
      "EPOCH:   472 | BP | train loss: 0.1162 | test acc: 0.9800\n",
      "EPOCH:   473 | BP | train loss: 0.1158 | test acc: 0.9800\n",
      "EPOCH:   474 | BP | train loss: 0.1154 | test acc: 0.9800\n",
      "EPOCH:   475 | BP | train loss: 0.1149 | test acc: 0.9800\n",
      "EPOCH:   476 | BP | train loss: 0.1145 | test acc: 0.9800\n",
      "EPOCH:   477 | BP | train loss: 0.1141 | test acc: 0.9800\n",
      "EPOCH:   478 | BP | train loss: 0.1137 | test acc: 0.9800\n",
      "EPOCH:   479 | BP | train loss: 0.1132 | test acc: 0.9800\n",
      "EPOCH:   480 | BP | train loss: 0.1128 | test acc: 0.9800\n",
      "EPOCH:   481 | BP | train loss: 0.1124 | test acc: 0.9800\n",
      "EPOCH:   482 | BP | train loss: 0.1120 | test acc: 0.9800\n",
      "EPOCH:   483 | BP | train loss: 0.1116 | test acc: 0.9800\n",
      "EPOCH:   484 | BP | train loss: 0.1112 | test acc: 0.9800\n",
      "EPOCH:   485 | BP | train loss: 0.1108 | test acc: 0.9800\n",
      "EPOCH:   486 | BP | train loss: 0.1103 | test acc: 0.9800\n",
      "EPOCH:   487 | BP | train loss: 0.1099 | test acc: 0.9800\n",
      "EPOCH:   488 | BP | train loss: 0.1095 | test acc: 0.9800\n",
      "EPOCH:   489 | BP | train loss: 0.1091 | test acc: 0.9800\n",
      "EPOCH:   490 | BP | train loss: 0.1087 | test acc: 0.9800\n",
      "EPOCH:   491 | BP | train loss: 0.1083 | test acc: 0.9800\n",
      "EPOCH:   492 | BP | train loss: 0.1079 | test acc: 0.9800\n",
      "EPOCH:   493 | BP | train loss: 0.1075 | test acc: 0.9800\n",
      "EPOCH:   494 | BP | train loss: 0.1071 | test acc: 0.9805\n",
      "EPOCH:   495 | BP | train loss: 0.1067 | test acc: 0.9805\n",
      "EPOCH:   496 | BP | train loss: 0.1063 | test acc: 0.9805\n",
      "EPOCH:   497 | BP | train loss: 0.1059 | test acc: 0.9805\n",
      "EPOCH:   498 | BP | train loss: 0.1056 | test acc: 0.9805\n",
      "EPOCH:   499 | BP | train loss: 0.1052 | test acc: 0.9805\n",
      "EPOCH:   500 | BP | train loss: 0.1048 | test acc: 0.9805\n",
      "EPOCH:   501 | BP | train loss: 0.1044 | test acc: 0.9805\n",
      "EPOCH:   502 | BP | train loss: 0.1040 | test acc: 0.9805\n",
      "EPOCH:   503 | BP | train loss: 0.1036 | test acc: 0.9805\n",
      "EPOCH:   504 | BP | train loss: 0.1033 | test acc: 0.9805\n",
      "EPOCH:   505 | BP | train loss: 0.1029 | test acc: 0.9805\n",
      "EPOCH:   506 | BP | train loss: 0.1025 | test acc: 0.9805\n",
      "EPOCH:   507 | BP | train loss: 0.1021 | test acc: 0.9805\n",
      "EPOCH:   508 | BP | train loss: 0.1018 | test acc: 0.9805\n",
      "EPOCH:   509 | BP | train loss: 0.1014 | test acc: 0.9805\n",
      "EPOCH:   510 | BP | train loss: 0.1010 | test acc: 0.9805\n",
      "EPOCH:   511 | BP | train loss: 0.1007 | test acc: 0.9805\n",
      "EPOCH:   512 | BP | train loss: 0.1003 | test acc: 0.9805\n",
      "EPOCH:   513 | BP | train loss: 0.0999 | test acc: 0.9805\n",
      "EPOCH:   514 | BP | train loss: 0.0996 | test acc: 0.9805\n",
      "EPOCH:   515 | BP | train loss: 0.0992 | test acc: 0.9811\n",
      "EPOCH:   516 | BP | train loss: 0.0988 | test acc: 0.9816\n",
      "EPOCH:   517 | BP | train loss: 0.0985 | test acc: 0.9816\n",
      "EPOCH:   518 | BP | train loss: 0.0981 | test acc: 0.9816\n",
      "EPOCH:   519 | BP | train loss: 0.0978 | test acc: 0.9816\n",
      "EPOCH:   520 | BP | train loss: 0.0974 | test acc: 0.9816\n",
      "EPOCH:   521 | BP | train loss: 0.0970 | test acc: 0.9816\n",
      "EPOCH:   522 | BP | train loss: 0.0967 | test acc: 0.9816\n",
      "EPOCH:   523 | BP | train loss: 0.0963 | test acc: 0.9816\n",
      "EPOCH:   524 | BP | train loss: 0.0960 | test acc: 0.9816\n",
      "EPOCH:   525 | BP | train loss: 0.0956 | test acc: 0.9816\n",
      "EPOCH:   526 | BP | train loss: 0.0953 | test acc: 0.9816\n",
      "EPOCH:   527 | BP | train loss: 0.0949 | test acc: 0.9816\n",
      "EPOCH:   528 | BP | train loss: 0.0946 | test acc: 0.9816\n",
      "EPOCH:   529 | BP | train loss: 0.0942 | test acc: 0.9816\n",
      "EPOCH:   530 | BP | train loss: 0.0939 | test acc: 0.9816\n",
      "EPOCH:   531 | BP | train loss: 0.0935 | test acc: 0.9816\n",
      "EPOCH:   532 | BP | train loss: 0.0932 | test acc: 0.9816\n",
      "EPOCH:   533 | BP | train loss: 0.0928 | test acc: 0.9816\n",
      "EPOCH:   534 | BP | train loss: 0.0925 | test acc: 0.9816\n",
      "EPOCH:   535 | BP | train loss: 0.0922 | test acc: 0.9816\n",
      "EPOCH:   536 | BP | train loss: 0.0918 | test acc: 0.9816\n",
      "EPOCH:   537 | BP | train loss: 0.0915 | test acc: 0.9816\n",
      "EPOCH:   538 | BP | train loss: 0.0911 | test acc: 0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   539 | BP | train loss: 0.0908 | test acc: 0.9816\n",
      "EPOCH:   540 | BP | train loss: 0.0905 | test acc: 0.9816\n",
      "EPOCH:   541 | BP | train loss: 0.0901 | test acc: 0.9816\n",
      "EPOCH:   542 | BP | train loss: 0.0898 | test acc: 0.9816\n",
      "EPOCH:   543 | BP | train loss: 0.0895 | test acc: 0.9816\n",
      "EPOCH:   544 | BP | train loss: 0.0892 | test acc: 0.9816\n",
      "EPOCH:   545 | BP | train loss: 0.0888 | test acc: 0.9816\n",
      "EPOCH:   546 | BP | train loss: 0.0885 | test acc: 0.9816\n",
      "EPOCH:   547 | BP | train loss: 0.0882 | test acc: 0.9816\n",
      "EPOCH:   548 | BP | train loss: 0.0879 | test acc: 0.9816\n",
      "EPOCH:   549 | BP | train loss: 0.0875 | test acc: 0.9816\n",
      "EPOCH:   550 | BP | train loss: 0.0872 | test acc: 0.9816\n",
      "EPOCH:   551 | BP | train loss: 0.0869 | test acc: 0.9816\n",
      "EPOCH:   552 | BP | train loss: 0.0866 | test acc: 0.9816\n",
      "EPOCH:   553 | BP | train loss: 0.0863 | test acc: 0.9816\n",
      "EPOCH:   554 | BP | train loss: 0.0859 | test acc: 0.9816\n",
      "EPOCH:   555 | BP | train loss: 0.0856 | test acc: 0.9816\n",
      "EPOCH:   556 | BP | train loss: 0.0853 | test acc: 0.9816\n",
      "EPOCH:   557 | BP | train loss: 0.0850 | test acc: 0.9816\n",
      "EPOCH:   558 | BP | train loss: 0.0847 | test acc: 0.9816\n",
      "EPOCH:   559 | BP | train loss: 0.0844 | test acc: 0.9816\n",
      "EPOCH:   560 | BP | train loss: 0.0841 | test acc: 0.9816\n",
      "EPOCH:   561 | BP | train loss: 0.0838 | test acc: 0.9816\n",
      "EPOCH:   562 | BP | train loss: 0.0835 | test acc: 0.9816\n",
      "EPOCH:   563 | BP | train loss: 0.0832 | test acc: 0.9822\n",
      "EPOCH:   564 | BP | train loss: 0.0829 | test acc: 0.9822\n",
      "EPOCH:   565 | BP | train loss: 0.0826 | test acc: 0.9827\n",
      "EPOCH:   566 | BP | train loss: 0.0823 | test acc: 0.9827\n",
      "EPOCH:   567 | BP | train loss: 0.0820 | test acc: 0.9833\n",
      "EPOCH:   568 | BP | train loss: 0.0817 | test acc: 0.9833\n",
      "EPOCH:   569 | BP | train loss: 0.0814 | test acc: 0.9833\n",
      "EPOCH:   570 | BP | train loss: 0.0811 | test acc: 0.9833\n",
      "EPOCH:   571 | BP | train loss: 0.0808 | test acc: 0.9833\n",
      "EPOCH:   572 | BP | train loss: 0.0805 | test acc: 0.9833\n",
      "EPOCH:   573 | BP | train loss: 0.0802 | test acc: 0.9833\n",
      "EPOCH:   574 | BP | train loss: 0.0799 | test acc: 0.9833\n",
      "EPOCH:   575 | BP | train loss: 0.0796 | test acc: 0.9833\n",
      "EPOCH:   576 | BP | train loss: 0.0793 | test acc: 0.9833\n",
      "EPOCH:   577 | BP | train loss: 0.0791 | test acc: 0.9833\n",
      "EPOCH:   578 | BP | train loss: 0.0788 | test acc: 0.9833\n",
      "EPOCH:   579 | BP | train loss: 0.0785 | test acc: 0.9833\n",
      "EPOCH:   580 | BP | train loss: 0.0782 | test acc: 0.9833\n",
      "EPOCH:   581 | BP | train loss: 0.0779 | test acc: 0.9833\n",
      "EPOCH:   582 | BP | train loss: 0.0776 | test acc: 0.9833\n",
      "EPOCH:   583 | BP | train loss: 0.0774 | test acc: 0.9844\n",
      "EPOCH:   584 | BP | train loss: 0.0771 | test acc: 0.9844\n",
      "EPOCH:   585 | BP | train loss: 0.0768 | test acc: 0.9844\n",
      "EPOCH:   586 | BP | train loss: 0.0765 | test acc: 0.9850\n",
      "EPOCH:   587 | BP | train loss: 0.0763 | test acc: 0.9850\n",
      "EPOCH:   588 | BP | train loss: 0.0760 | test acc: 0.9850\n",
      "EPOCH:   589 | BP | train loss: 0.0757 | test acc: 0.9850\n",
      "EPOCH:   590 | BP | train loss: 0.0755 | test acc: 0.9850\n",
      "EPOCH:   591 | BP | train loss: 0.0752 | test acc: 0.9850\n",
      "EPOCH:   592 | BP | train loss: 0.0749 | test acc: 0.9850\n",
      "EPOCH:   593 | BP | train loss: 0.0747 | test acc: 0.9850\n",
      "EPOCH:   594 | BP | train loss: 0.0744 | test acc: 0.9850\n",
      "EPOCH:   595 | BP | train loss: 0.0741 | test acc: 0.9850\n",
      "EPOCH:   596 | BP | train loss: 0.0739 | test acc: 0.9850\n",
      "EPOCH:   597 | BP | train loss: 0.0736 | test acc: 0.9850\n",
      "EPOCH:   598 | BP | train loss: 0.0733 | test acc: 0.9850\n",
      "EPOCH:   599 | BP | train loss: 0.0731 | test acc: 0.9850\n",
      "EPOCH:   600 | BP | train loss: 0.0728 | test acc: 0.9850\n",
      "EPOCH:   601 | BP | train loss: 0.0726 | test acc: 0.9850\n",
      "EPOCH:   602 | BP | train loss: 0.0723 | test acc: 0.9850\n",
      "EPOCH:   603 | BP | train loss: 0.0720 | test acc: 0.9850\n",
      "EPOCH:   604 | BP | train loss: 0.0718 | test acc: 0.9850\n",
      "EPOCH:   605 | BP | train loss: 0.0715 | test acc: 0.9850\n",
      "EPOCH:   606 | BP | train loss: 0.0713 | test acc: 0.9850\n",
      "EPOCH:   607 | BP | train loss: 0.0710 | test acc: 0.9850\n",
      "EPOCH:   608 | BP | train loss: 0.0708 | test acc: 0.9850\n",
      "EPOCH:   609 | BP | train loss: 0.0705 | test acc: 0.9850\n",
      "EPOCH:   610 | BP | train loss: 0.0703 | test acc: 0.9850\n",
      "EPOCH:   611 | BP | train loss: 0.0700 | test acc: 0.9855\n",
      "EPOCH:   612 | BP | train loss: 0.0698 | test acc: 0.9855\n",
      "EPOCH:   613 | BP | train loss: 0.0695 | test acc: 0.9855\n",
      "EPOCH:   614 | BP | train loss: 0.0693 | test acc: 0.9855\n",
      "EPOCH:   615 | BP | train loss: 0.0691 | test acc: 0.9855\n",
      "EPOCH:   616 | BP | train loss: 0.0688 | test acc: 0.9855\n",
      "EPOCH:   617 | BP | train loss: 0.0686 | test acc: 0.9855\n",
      "EPOCH:   618 | BP | train loss: 0.0683 | test acc: 0.9855\n",
      "EPOCH:   619 | BP | train loss: 0.0681 | test acc: 0.9855\n",
      "EPOCH:   620 | BP | train loss: 0.0679 | test acc: 0.9855\n",
      "EPOCH:   621 | BP | train loss: 0.0676 | test acc: 0.9855\n",
      "EPOCH:   622 | BP | train loss: 0.0674 | test acc: 0.9861\n",
      "EPOCH:   623 | BP | train loss: 0.0672 | test acc: 0.9861\n",
      "EPOCH:   624 | BP | train loss: 0.0669 | test acc: 0.9861\n",
      "EPOCH:   625 | BP | train loss: 0.0667 | test acc: 0.9866\n",
      "EPOCH:   626 | BP | train loss: 0.0665 | test acc: 0.9866\n",
      "EPOCH:   627 | BP | train loss: 0.0662 | test acc: 0.9866\n",
      "EPOCH:   628 | BP | train loss: 0.0660 | test acc: 0.9866\n",
      "EPOCH:   629 | BP | train loss: 0.0658 | test acc: 0.9866\n",
      "EPOCH:   630 | BP | train loss: 0.0656 | test acc: 0.9866\n",
      "EPOCH:   631 | BP | train loss: 0.0653 | test acc: 0.9866\n",
      "EPOCH:   632 | BP | train loss: 0.0651 | test acc: 0.9866\n",
      "EPOCH:   633 | BP | train loss: 0.0649 | test acc: 0.9866\n",
      "EPOCH:   634 | BP | train loss: 0.0647 | test acc: 0.9866\n",
      "EPOCH:   635 | BP | train loss: 0.0644 | test acc: 0.9866\n",
      "EPOCH:   636 | BP | train loss: 0.0642 | test acc: 0.9866\n",
      "EPOCH:   637 | BP | train loss: 0.0640 | test acc: 0.9866\n",
      "EPOCH:   638 | BP | train loss: 0.0638 | test acc: 0.9866\n",
      "EPOCH:   639 | BP | train loss: 0.0636 | test acc: 0.9866\n",
      "EPOCH:   640 | BP | train loss: 0.0633 | test acc: 0.9866\n",
      "EPOCH:   641 | BP | train loss: 0.0631 | test acc: 0.9866\n",
      "EPOCH:   642 | BP | train loss: 0.0629 | test acc: 0.9866\n",
      "EPOCH:   643 | BP | train loss: 0.0627 | test acc: 0.9866\n",
      "EPOCH:   644 | BP | train loss: 0.0625 | test acc: 0.9866\n",
      "EPOCH:   645 | BP | train loss: 0.0623 | test acc: 0.9866\n",
      "EPOCH:   646 | BP | train loss: 0.0621 | test acc: 0.9866\n",
      "EPOCH:   647 | BP | train loss: 0.0619 | test acc: 0.9866\n",
      "EPOCH:   648 | BP | train loss: 0.0617 | test acc: 0.9866\n",
      "EPOCH:   649 | BP | train loss: 0.0615 | test acc: 0.9872\n",
      "EPOCH:   650 | BP | train loss: 0.0613 | test acc: 0.9878\n",
      "EPOCH:   651 | BP | train loss: 0.0611 | test acc: 0.9878\n",
      "EPOCH:   652 | BP | train loss: 0.0609 | test acc: 0.9878\n",
      "EPOCH:   653 | BP | train loss: 0.0607 | test acc: 0.9878\n",
      "EPOCH:   654 | BP | train loss: 0.0605 | test acc: 0.9889\n",
      "EPOCH:   655 | BP | train loss: 0.0603 | test acc: 0.9889\n",
      "EPOCH:   656 | BP | train loss: 0.0601 | test acc: 0.9889\n",
      "EPOCH:   657 | BP | train loss: 0.0599 | test acc: 0.9889\n",
      "EPOCH:   658 | BP | train loss: 0.0597 | test acc: 0.9889\n",
      "EPOCH:   659 | BP | train loss: 0.0595 | test acc: 0.9889\n",
      "EPOCH:   660 | BP | train loss: 0.0593 | test acc: 0.9889\n",
      "EPOCH:   661 | BP | train loss: 0.0591 | test acc: 0.9889\n",
      "EPOCH:   662 | BP | train loss: 0.0589 | test acc: 0.9889\n",
      "EPOCH:   663 | BP | train loss: 0.0587 | test acc: 0.9889\n",
      "EPOCH:   664 | BP | train loss: 0.0585 | test acc: 0.9889\n",
      "EPOCH:   665 | BP | train loss: 0.0583 | test acc: 0.9894\n",
      "EPOCH:   666 | BP | train loss: 0.0581 | test acc: 0.9894\n",
      "EPOCH:   667 | BP | train loss: 0.0579 | test acc: 0.9894\n",
      "EPOCH:   668 | BP | train loss: 0.0577 | test acc: 0.9894\n",
      "EPOCH:   669 | BP | train loss: 0.0576 | test acc: 0.9894\n",
      "EPOCH:   670 | BP | train loss: 0.0574 | test acc: 0.9894\n",
      "EPOCH:   671 | BP | train loss: 0.0572 | test acc: 0.9894\n",
      "EPOCH:   672 | BP | train loss: 0.0570 | test acc: 0.9894\n",
      "EPOCH:   673 | BP | train loss: 0.0568 | test acc: 0.9894\n",
      "EPOCH:   674 | BP | train loss: 0.0567 | test acc: 0.9894\n",
      "EPOCH:   675 | BP | train loss: 0.0565 | test acc: 0.9900\n",
      "EPOCH:   676 | BP | train loss: 0.0563 | test acc: 0.9900\n",
      "EPOCH:   677 | BP | train loss: 0.0561 | test acc: 0.9900\n",
      "EPOCH:   678 | BP | train loss: 0.0559 | test acc: 0.9900\n",
      "EPOCH:   679 | BP | train loss: 0.0558 | test acc: 0.9905\n",
      "EPOCH:   680 | BP | train loss: 0.0556 | test acc: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   681 | BP | train loss: 0.0554 | test acc: 0.9905\n",
      "EPOCH:   682 | BP | train loss: 0.0553 | test acc: 0.9905\n",
      "EPOCH:   683 | BP | train loss: 0.0551 | test acc: 0.9905\n",
      "EPOCH:   684 | BP | train loss: 0.0549 | test acc: 0.9905\n",
      "EPOCH:   685 | BP | train loss: 0.0548 | test acc: 0.9905\n",
      "EPOCH:   686 | BP | train loss: 0.0546 | test acc: 0.9905\n",
      "EPOCH:   687 | BP | train loss: 0.0544 | test acc: 0.9905\n",
      "EPOCH:   688 | BP | train loss: 0.0543 | test acc: 0.9905\n",
      "EPOCH:   689 | BP | train loss: 0.0541 | test acc: 0.9905\n",
      "EPOCH:   690 | BP | train loss: 0.0539 | test acc: 0.9905\n",
      "EPOCH:   691 | BP | train loss: 0.0538 | test acc: 0.9905\n",
      "EPOCH:   692 | BP | train loss: 0.0536 | test acc: 0.9905\n",
      "EPOCH:   693 | BP | train loss: 0.0535 | test acc: 0.9905\n",
      "EPOCH:   694 | BP | train loss: 0.0533 | test acc: 0.9905\n",
      "EPOCH:   695 | BP | train loss: 0.0531 | test acc: 0.9905\n",
      "EPOCH:   696 | BP | train loss: 0.0530 | test acc: 0.9905\n",
      "EPOCH:   697 | BP | train loss: 0.0528 | test acc: 0.9905\n",
      "EPOCH:   698 | BP | train loss: 0.0527 | test acc: 0.9905\n",
      "EPOCH:   699 | BP | train loss: 0.0525 | test acc: 0.9911\n",
      "EPOCH:   700 | BP | train loss: 0.0524 | test acc: 0.9917\n",
      "EPOCH:   701 | BP | train loss: 0.0522 | test acc: 0.9917\n",
      "EPOCH:   702 | BP | train loss: 0.0521 | test acc: 0.9917\n",
      "EPOCH:   703 | BP | train loss: 0.0519 | test acc: 0.9917\n",
      "EPOCH:   704 | BP | train loss: 0.0518 | test acc: 0.9917\n",
      "EPOCH:   705 | BP | train loss: 0.0516 | test acc: 0.9917\n",
      "EPOCH:   706 | BP | train loss: 0.0515 | test acc: 0.9917\n",
      "EPOCH:   707 | BP | train loss: 0.0513 | test acc: 0.9917\n",
      "EPOCH:   708 | BP | train loss: 0.0512 | test acc: 0.9917\n",
      "EPOCH:   709 | BP | train loss: 0.0510 | test acc: 0.9922\n",
      "EPOCH:   710 | BP | train loss: 0.0509 | test acc: 0.9922\n",
      "EPOCH:   711 | BP | train loss: 0.0507 | test acc: 0.9922\n",
      "EPOCH:   712 | BP | train loss: 0.0506 | test acc: 0.9922\n",
      "EPOCH:   713 | BP | train loss: 0.0505 | test acc: 0.9922\n",
      "EPOCH:   714 | BP | train loss: 0.0503 | test acc: 0.9928\n",
      "EPOCH:   715 | BP | train loss: 0.0502 | test acc: 0.9928\n",
      "EPOCH:   716 | BP | train loss: 0.0501 | test acc: 0.9928\n",
      "EPOCH:   717 | BP | train loss: 0.0499 | test acc: 0.9928\n",
      "EPOCH:   718 | BP | train loss: 0.0498 | test acc: 0.9928\n",
      "EPOCH:   719 | BP | train loss: 0.0496 | test acc: 0.9928\n",
      "EPOCH:   720 | BP | train loss: 0.0495 | test acc: 0.9928\n",
      "EPOCH:   721 | BP | train loss: 0.0494 | test acc: 0.9928\n",
      "EPOCH:   722 | BP | train loss: 0.0493 | test acc: 0.9928\n",
      "EPOCH:   723 | BP | train loss: 0.0491 | test acc: 0.9928\n",
      "EPOCH:   724 | BP | train loss: 0.0490 | test acc: 0.9928\n",
      "EPOCH:   725 | BP | train loss: 0.0489 | test acc: 0.9928\n",
      "EPOCH:   726 | BP | train loss: 0.0487 | test acc: 0.9928\n",
      "EPOCH:   727 | BP | train loss: 0.0486 | test acc: 0.9928\n",
      "EPOCH:   728 | BP | train loss: 0.0485 | test acc: 0.9928\n",
      "EPOCH:   729 | BP | train loss: 0.0484 | test acc: 0.9928\n",
      "EPOCH:   730 | BP | train loss: 0.0482 | test acc: 0.9928\n",
      "EPOCH:   731 | BP | train loss: 0.0481 | test acc: 0.9928\n",
      "EPOCH:   732 | BP | train loss: 0.0480 | test acc: 0.9928\n",
      "EPOCH:   733 | BP | train loss: 0.0479 | test acc: 0.9928\n",
      "EPOCH:   734 | BP | train loss: 0.0477 | test acc: 0.9928\n",
      "EPOCH:   735 | BP | train loss: 0.0476 | test acc: 0.9928\n",
      "EPOCH:   736 | BP | train loss: 0.0475 | test acc: 0.9928\n",
      "EPOCH:   737 | BP | train loss: 0.0474 | test acc: 0.9928\n",
      "EPOCH:   738 | BP | train loss: 0.0473 | test acc: 0.9928\n",
      "EPOCH:   739 | BP | train loss: 0.0471 | test acc: 0.9928\n",
      "EPOCH:   740 | BP | train loss: 0.0470 | test acc: 0.9928\n",
      "EPOCH:   741 | BP | train loss: 0.0469 | test acc: 0.9928\n",
      "EPOCH:   742 | BP | train loss: 0.0468 | test acc: 0.9928\n",
      "EPOCH:   743 | BP | train loss: 0.0467 | test acc: 0.9928\n",
      "EPOCH:   744 | BP | train loss: 0.0466 | test acc: 0.9928\n",
      "EPOCH:   745 | BP | train loss: 0.0464 | test acc: 0.9928\n",
      "EPOCH:   746 | BP | train loss: 0.0463 | test acc: 0.9928\n",
      "EPOCH:   747 | BP | train loss: 0.0462 | test acc: 0.9928\n",
      "EPOCH:   748 | BP | train loss: 0.0461 | test acc: 0.9933\n",
      "EPOCH:   749 | BP | train loss: 0.0460 | test acc: 0.9933\n",
      "EPOCH:   750 | BP | train loss: 0.0459 | test acc: 0.9933\n",
      "EPOCH:   751 | BP | train loss: 0.0458 | test acc: 0.9933\n",
      "EPOCH:   752 | BP | train loss: 0.0457 | test acc: 0.9933\n",
      "EPOCH:   753 | BP | train loss: 0.0455 | test acc: 0.9933\n",
      "EPOCH:   754 | BP | train loss: 0.0454 | test acc: 0.9933\n",
      "EPOCH:   755 | BP | train loss: 0.0453 | test acc: 0.9933\n",
      "EPOCH:   756 | BP | train loss: 0.0452 | test acc: 0.9933\n",
      "EPOCH:   757 | BP | train loss: 0.0451 | test acc: 0.9933\n",
      "EPOCH:   758 | BP | train loss: 0.0450 | test acc: 0.9933\n",
      "EPOCH:   759 | BP | train loss: 0.0449 | test acc: 0.9933\n",
      "EPOCH:   760 | BP | train loss: 0.0448 | test acc: 0.9933\n",
      "EPOCH:   761 | BP | train loss: 0.0447 | test acc: 0.9933\n",
      "EPOCH:   762 | BP | train loss: 0.0446 | test acc: 0.9933\n",
      "EPOCH:   763 | BP | train loss: 0.0445 | test acc: 0.9933\n",
      "EPOCH:   764 | BP | train loss: 0.0444 | test acc: 0.9933\n",
      "EPOCH:   765 | BP | train loss: 0.0443 | test acc: 0.9933\n",
      "EPOCH:   766 | BP | train loss: 0.0441 | test acc: 0.9933\n",
      "EPOCH:   767 | BP | train loss: 0.0440 | test acc: 0.9933\n",
      "EPOCH:   768 | BP | train loss: 0.0439 | test acc: 0.9933\n",
      "EPOCH:   769 | BP | train loss: 0.0438 | test acc: 0.9933\n",
      "EPOCH:   770 | BP | train loss: 0.0437 | test acc: 0.9933\n",
      "EPOCH:   771 | BP | train loss: 0.0436 | test acc: 0.9933\n",
      "EPOCH:   772 | BP | train loss: 0.0435 | test acc: 0.9933\n",
      "EPOCH:   773 | BP | train loss: 0.0434 | test acc: 0.9933\n",
      "EPOCH:   774 | BP | train loss: 0.0433 | test acc: 0.9933\n",
      "EPOCH:   775 | BP | train loss: 0.0432 | test acc: 0.9933\n",
      "EPOCH:   776 | BP | train loss: 0.0431 | test acc: 0.9933\n",
      "EPOCH:   777 | BP | train loss: 0.0430 | test acc: 0.9939\n",
      "EPOCH:   778 | BP | train loss: 0.0429 | test acc: 0.9939\n",
      "EPOCH:   779 | BP | train loss: 0.0428 | test acc: 0.9939\n",
      "EPOCH:   780 | BP | train loss: 0.0427 | test acc: 0.9939\n",
      "EPOCH:   781 | BP | train loss: 0.0426 | test acc: 0.9939\n",
      "EPOCH:   782 | BP | train loss: 0.0425 | test acc: 0.9944\n",
      "EPOCH:   783 | BP | train loss: 0.0424 | test acc: 0.9944\n",
      "EPOCH:   784 | BP | train loss: 0.0424 | test acc: 0.9944\n",
      "EPOCH:   785 | BP | train loss: 0.0423 | test acc: 0.9950\n",
      "EPOCH:   786 | BP | train loss: 0.0422 | test acc: 0.9950\n",
      "EPOCH:   787 | BP | train loss: 0.0421 | test acc: 0.9950\n",
      "EPOCH:   788 | BP | train loss: 0.0420 | test acc: 0.9950\n",
      "EPOCH:   789 | BP | train loss: 0.0419 | test acc: 0.9950\n",
      "EPOCH:   790 | BP | train loss: 0.0418 | test acc: 0.9950\n",
      "EPOCH:   791 | BP | train loss: 0.0417 | test acc: 0.9950\n",
      "EPOCH:   792 | BP | train loss: 0.0416 | test acc: 0.9950\n",
      "EPOCH:   793 | BP | train loss: 0.0415 | test acc: 0.9950\n",
      "EPOCH:   794 | BP | train loss: 0.0414 | test acc: 0.9950\n",
      "EPOCH:   795 | BP | train loss: 0.0413 | test acc: 0.9950\n",
      "EPOCH:   796 | BP | train loss: 0.0412 | test acc: 0.9950\n",
      "EPOCH:   797 | BP | train loss: 0.0411 | test acc: 0.9950\n",
      "EPOCH:   798 | BP | train loss: 0.0411 | test acc: 0.9950\n",
      "EPOCH:   799 | BP | train loss: 0.0410 | test acc: 0.9950\n",
      "EPOCH:   800 | BP | train loss: 0.0409 | test acc: 0.9950\n",
      "EPOCH:   801 | BP | train loss: 0.0408 | test acc: 0.9950\n",
      "EPOCH:   802 | BP | train loss: 0.0407 | test acc: 0.9950\n",
      "EPOCH:   803 | BP | train loss: 0.0406 | test acc: 0.9950\n",
      "EPOCH:   804 | BP | train loss: 0.0405 | test acc: 0.9950\n",
      "EPOCH:   805 | BP | train loss: 0.0404 | test acc: 0.9950\n",
      "EPOCH:   806 | BP | train loss: 0.0403 | test acc: 0.9950\n",
      "EPOCH:   807 | BP | train loss: 0.0402 | test acc: 0.9950\n",
      "EPOCH:   808 | BP | train loss: 0.0402 | test acc: 0.9950\n",
      "EPOCH:   809 | BP | train loss: 0.0401 | test acc: 0.9950\n",
      "EPOCH:   810 | BP | train loss: 0.0400 | test acc: 0.9950\n",
      "EPOCH:   811 | BP | train loss: 0.0399 | test acc: 0.9950\n",
      "EPOCH:   812 | BP | train loss: 0.0398 | test acc: 0.9950\n",
      "EPOCH:   813 | BP | train loss: 0.0397 | test acc: 0.9950\n",
      "EPOCH:   814 | BP | train loss: 0.0396 | test acc: 0.9950\n",
      "EPOCH:   815 | BP | train loss: 0.0396 | test acc: 0.9950\n",
      "EPOCH:   816 | BP | train loss: 0.0395 | test acc: 0.9950\n",
      "EPOCH:   817 | BP | train loss: 0.0394 | test acc: 0.9950\n",
      "EPOCH:   818 | BP | train loss: 0.0393 | test acc: 0.9950\n",
      "EPOCH:   819 | BP | train loss: 0.0392 | test acc: 0.9950\n",
      "EPOCH:   820 | BP | train loss: 0.0391 | test acc: 0.9950\n",
      "EPOCH:   821 | BP | train loss: 0.0391 | test acc: 0.9950\n",
      "EPOCH:   822 | BP | train loss: 0.0390 | test acc: 0.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   823 | BP | train loss: 0.0389 | test acc: 0.9950\n",
      "EPOCH:   824 | BP | train loss: 0.0388 | test acc: 0.9950\n",
      "EPOCH:   825 | BP | train loss: 0.0387 | test acc: 0.9950\n",
      "EPOCH:   826 | BP | train loss: 0.0386 | test acc: 0.9955\n",
      "EPOCH:   827 | BP | train loss: 0.0386 | test acc: 0.9955\n",
      "EPOCH:   828 | BP | train loss: 0.0385 | test acc: 0.9955\n",
      "EPOCH:   829 | BP | train loss: 0.0384 | test acc: 0.9955\n",
      "EPOCH:   830 | BP | train loss: 0.0383 | test acc: 0.9955\n",
      "EPOCH:   831 | BP | train loss: 0.0382 | test acc: 0.9955\n",
      "EPOCH:   832 | BP | train loss: 0.0381 | test acc: 0.9955\n",
      "EPOCH:   833 | BP | train loss: 0.0381 | test acc: 0.9955\n",
      "EPOCH:   834 | BP | train loss: 0.0380 | test acc: 0.9955\n",
      "EPOCH:   835 | BP | train loss: 0.0379 | test acc: 0.9955\n",
      "EPOCH:   836 | BP | train loss: 0.0378 | test acc: 0.9955\n",
      "EPOCH:   837 | BP | train loss: 0.0377 | test acc: 0.9955\n",
      "EPOCH:   838 | BP | train loss: 0.0377 | test acc: 0.9955\n",
      "EPOCH:   839 | BP | train loss: 0.0376 | test acc: 0.9955\n",
      "EPOCH:   840 | BP | train loss: 0.0375 | test acc: 0.9955\n",
      "EPOCH:   841 | BP | train loss: 0.0374 | test acc: 0.9955\n",
      "EPOCH:   842 | BP | train loss: 0.0374 | test acc: 0.9955\n",
      "EPOCH:   843 | BP | train loss: 0.0373 | test acc: 0.9955\n",
      "EPOCH:   844 | BP | train loss: 0.0372 | test acc: 0.9955\n",
      "EPOCH:   845 | BP | train loss: 0.0371 | test acc: 0.9955\n",
      "EPOCH:   846 | BP | train loss: 0.0370 | test acc: 0.9955\n",
      "EPOCH:   847 | BP | train loss: 0.0370 | test acc: 0.9955\n",
      "EPOCH:   848 | BP | train loss: 0.0369 | test acc: 0.9955\n",
      "EPOCH:   849 | BP | train loss: 0.0368 | test acc: 0.9955\n",
      "EPOCH:   850 | BP | train loss: 0.0367 | test acc: 0.9955\n",
      "EPOCH:   851 | BP | train loss: 0.0367 | test acc: 0.9955\n",
      "EPOCH:   852 | BP | train loss: 0.0366 | test acc: 0.9955\n",
      "EPOCH:   853 | BP | train loss: 0.0365 | test acc: 0.9955\n",
      "EPOCH:   854 | BP | train loss: 0.0364 | test acc: 0.9955\n",
      "EPOCH:   855 | BP | train loss: 0.0364 | test acc: 0.9955\n",
      "EPOCH:   856 | BP | train loss: 0.0363 | test acc: 0.9955\n",
      "EPOCH:   857 | BP | train loss: 0.0362 | test acc: 0.9955\n",
      "EPOCH:   858 | BP | train loss: 0.0361 | test acc: 0.9955\n",
      "EPOCH:   859 | BP | train loss: 0.0361 | test acc: 0.9955\n",
      "EPOCH:   860 | BP | train loss: 0.0360 | test acc: 0.9955\n",
      "EPOCH:   861 | BP | train loss: 0.0359 | test acc: 0.9955\n",
      "EPOCH:   862 | BP | train loss: 0.0358 | test acc: 0.9955\n",
      "EPOCH:   863 | BP | train loss: 0.0358 | test acc: 0.9955\n",
      "EPOCH:   864 | BP | train loss: 0.0357 | test acc: 0.9955\n",
      "EPOCH:   865 | BP | train loss: 0.0356 | test acc: 0.9955\n",
      "EPOCH:   866 | BP | train loss: 0.0355 | test acc: 0.9955\n",
      "EPOCH:   867 | BP | train loss: 0.0355 | test acc: 0.9955\n",
      "EPOCH:   868 | BP | train loss: 0.0354 | test acc: 0.9955\n",
      "EPOCH:   869 | BP | train loss: 0.0353 | test acc: 0.9955\n",
      "EPOCH:   870 | BP | train loss: 0.0353 | test acc: 0.9955\n",
      "EPOCH:   871 | BP | train loss: 0.0352 | test acc: 0.9955\n",
      "EPOCH:   872 | BP | train loss: 0.0351 | test acc: 0.9955\n",
      "EPOCH:   873 | BP | train loss: 0.0350 | test acc: 0.9955\n",
      "EPOCH:   874 | BP | train loss: 0.0350 | test acc: 0.9955\n",
      "EPOCH:   875 | BP | train loss: 0.0349 | test acc: 0.9955\n",
      "EPOCH:   876 | BP | train loss: 0.0348 | test acc: 0.9955\n",
      "EPOCH:   877 | BP | train loss: 0.0348 | test acc: 0.9955\n",
      "EPOCH:   878 | BP | train loss: 0.0347 | test acc: 0.9955\n",
      "EPOCH:   879 | BP | train loss: 0.0346 | test acc: 0.9955\n",
      "EPOCH:   880 | BP | train loss: 0.0346 | test acc: 0.9955\n",
      "EPOCH:   881 | BP | train loss: 0.0345 | test acc: 0.9955\n",
      "EPOCH:   882 | BP | train loss: 0.0344 | test acc: 0.9955\n",
      "EPOCH:   883 | BP | train loss: 0.0344 | test acc: 0.9955\n",
      "EPOCH:   884 | BP | train loss: 0.0343 | test acc: 0.9955\n",
      "EPOCH:   885 | BP | train loss: 0.0342 | test acc: 0.9955\n",
      "EPOCH:   886 | BP | train loss: 0.0341 | test acc: 0.9955\n",
      "EPOCH:   887 | BP | train loss: 0.0341 | test acc: 0.9955\n",
      "EPOCH:   888 | BP | train loss: 0.0340 | test acc: 0.9955\n",
      "EPOCH:   889 | BP | train loss: 0.0339 | test acc: 0.9955\n",
      "EPOCH:   890 | BP | train loss: 0.0339 | test acc: 0.9955\n",
      "EPOCH:   891 | BP | train loss: 0.0338 | test acc: 0.9955\n",
      "EPOCH:   892 | BP | train loss: 0.0337 | test acc: 0.9955\n",
      "EPOCH:   893 | BP | train loss: 0.0337 | test acc: 0.9955\n",
      "EPOCH:   894 | BP | train loss: 0.0336 | test acc: 0.9955\n",
      "EPOCH:   895 | BP | train loss: 0.0335 | test acc: 0.9955\n",
      "EPOCH:   896 | BP | train loss: 0.0335 | test acc: 0.9955\n",
      "EPOCH:   897 | BP | train loss: 0.0334 | test acc: 0.9955\n",
      "EPOCH:   898 | BP | train loss: 0.0333 | test acc: 0.9955\n",
      "EPOCH:   899 | BP | train loss: 0.0333 | test acc: 0.9955\n",
      "EPOCH:   900 | BP | train loss: 0.0332 | test acc: 0.9955\n",
      "EPOCH:   901 | BP | train loss: 0.0331 | test acc: 0.9955\n",
      "EPOCH:   902 | BP | train loss: 0.0331 | test acc: 0.9955\n",
      "EPOCH:   903 | BP | train loss: 0.0330 | test acc: 0.9955\n",
      "EPOCH:   904 | BP | train loss: 0.0330 | test acc: 0.9955\n",
      "EPOCH:   905 | BP | train loss: 0.0329 | test acc: 0.9955\n",
      "EPOCH:   906 | BP | train loss: 0.0328 | test acc: 0.9955\n",
      "EPOCH:   907 | BP | train loss: 0.0328 | test acc: 0.9955\n",
      "EPOCH:   908 | BP | train loss: 0.0327 | test acc: 0.9955\n",
      "EPOCH:   909 | BP | train loss: 0.0326 | test acc: 0.9955\n",
      "EPOCH:   910 | BP | train loss: 0.0326 | test acc: 0.9955\n",
      "EPOCH:   911 | BP | train loss: 0.0325 | test acc: 0.9955\n",
      "EPOCH:   912 | BP | train loss: 0.0324 | test acc: 0.9955\n",
      "EPOCH:   913 | BP | train loss: 0.0324 | test acc: 0.9955\n",
      "EPOCH:   914 | BP | train loss: 0.0323 | test acc: 0.9961\n",
      "EPOCH:   915 | BP | train loss: 0.0323 | test acc: 0.9961\n",
      "EPOCH:   916 | BP | train loss: 0.0322 | test acc: 0.9961\n",
      "EPOCH:   917 | BP | train loss: 0.0321 | test acc: 0.9961\n",
      "EPOCH:   918 | BP | train loss: 0.0321 | test acc: 0.9961\n",
      "EPOCH:   919 | BP | train loss: 0.0320 | test acc: 0.9961\n",
      "EPOCH:   920 | BP | train loss: 0.0319 | test acc: 0.9961\n",
      "EPOCH:   921 | BP | train loss: 0.0319 | test acc: 0.9961\n",
      "EPOCH:   922 | BP | train loss: 0.0318 | test acc: 0.9961\n",
      "EPOCH:   923 | BP | train loss: 0.0318 | test acc: 0.9961\n",
      "EPOCH:   924 | BP | train loss: 0.0317 | test acc: 0.9961\n",
      "EPOCH:   925 | BP | train loss: 0.0316 | test acc: 0.9961\n",
      "EPOCH:   926 | BP | train loss: 0.0316 | test acc: 0.9961\n",
      "EPOCH:   927 | BP | train loss: 0.0315 | test acc: 0.9961\n",
      "EPOCH:   928 | BP | train loss: 0.0315 | test acc: 0.9961\n",
      "EPOCH:   929 | BP | train loss: 0.0314 | test acc: 0.9961\n",
      "EPOCH:   930 | BP | train loss: 0.0313 | test acc: 0.9961\n",
      "EPOCH:   931 | BP | train loss: 0.0313 | test acc: 0.9961\n",
      "EPOCH:   932 | BP | train loss: 0.0312 | test acc: 0.9961\n",
      "EPOCH:   933 | BP | train loss: 0.0312 | test acc: 0.9961\n",
      "EPOCH:   934 | BP | train loss: 0.0311 | test acc: 0.9961\n",
      "EPOCH:   935 | BP | train loss: 0.0310 | test acc: 0.9961\n",
      "EPOCH:   936 | BP | train loss: 0.0310 | test acc: 0.9961\n",
      "EPOCH:   937 | BP | train loss: 0.0309 | test acc: 0.9961\n",
      "EPOCH:   938 | BP | train loss: 0.0309 | test acc: 0.9961\n",
      "EPOCH:   939 | BP | train loss: 0.0308 | test acc: 0.9961\n",
      "EPOCH:   940 | BP | train loss: 0.0307 | test acc: 0.9961\n",
      "EPOCH:   941 | BP | train loss: 0.0307 | test acc: 0.9967\n",
      "EPOCH:   942 | BP | train loss: 0.0306 | test acc: 0.9967\n",
      "EPOCH:   943 | BP | train loss: 0.0306 | test acc: 0.9967\n",
      "EPOCH:   944 | BP | train loss: 0.0305 | test acc: 0.9967\n",
      "EPOCH:   945 | BP | train loss: 0.0305 | test acc: 0.9967\n",
      "EPOCH:   946 | BP | train loss: 0.0304 | test acc: 0.9967\n",
      "EPOCH:   947 | BP | train loss: 0.0303 | test acc: 0.9967\n",
      "EPOCH:   948 | BP | train loss: 0.0303 | test acc: 0.9967\n",
      "EPOCH:   949 | BP | train loss: 0.0302 | test acc: 0.9967\n",
      "EPOCH:   950 | BP | train loss: 0.0302 | test acc: 0.9967\n",
      "EPOCH:   951 | BP | train loss: 0.0301 | test acc: 0.9967\n",
      "EPOCH:   952 | BP | train loss: 0.0301 | test acc: 0.9967\n",
      "EPOCH:   953 | BP | train loss: 0.0300 | test acc: 0.9967\n",
      "EPOCH:   954 | BP | train loss: 0.0299 | test acc: 0.9967\n",
      "EPOCH:   955 | BP | train loss: 0.0299 | test acc: 0.9967\n",
      "EPOCH:   956 | BP | train loss: 0.0298 | test acc: 0.9967\n",
      "EPOCH:   957 | BP | train loss: 0.0298 | test acc: 0.9967\n",
      "EPOCH:   958 | BP | train loss: 0.0297 | test acc: 0.9967\n",
      "EPOCH:   959 | BP | train loss: 0.0297 | test acc: 0.9967\n",
      "EPOCH:   960 | BP | train loss: 0.0296 | test acc: 0.9967\n",
      "EPOCH:   961 | BP | train loss: 0.0295 | test acc: 0.9967\n",
      "EPOCH:   962 | BP | train loss: 0.0295 | test acc: 0.9967\n",
      "EPOCH:   963 | BP | train loss: 0.0294 | test acc: 0.9967\n",
      "EPOCH:   964 | BP | train loss: 0.0294 | test acc: 0.9972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   965 | BP | train loss: 0.0293 | test acc: 0.9972\n",
      "EPOCH:   966 | BP | train loss: 0.0293 | test acc: 0.9972\n",
      "EPOCH:   967 | BP | train loss: 0.0292 | test acc: 0.9972\n",
      "EPOCH:   968 | BP | train loss: 0.0292 | test acc: 0.9972\n",
      "EPOCH:   969 | BP | train loss: 0.0291 | test acc: 0.9972\n",
      "EPOCH:   970 | BP | train loss: 0.0291 | test acc: 0.9972\n",
      "EPOCH:   971 | BP | train loss: 0.0290 | test acc: 0.9972\n",
      "EPOCH:   972 | BP | train loss: 0.0289 | test acc: 0.9972\n",
      "EPOCH:   973 | BP | train loss: 0.0289 | test acc: 0.9972\n",
      "EPOCH:   974 | BP | train loss: 0.0288 | test acc: 0.9972\n",
      "EPOCH:   975 | BP | train loss: 0.0288 | test acc: 0.9972\n",
      "EPOCH:   976 | BP | train loss: 0.0287 | test acc: 0.9972\n",
      "EPOCH:   977 | BP | train loss: 0.0287 | test acc: 0.9972\n",
      "EPOCH:   978 | BP | train loss: 0.0286 | test acc: 0.9972\n",
      "EPOCH:   979 | BP | train loss: 0.0286 | test acc: 0.9972\n",
      "EPOCH:   980 | BP | train loss: 0.0285 | test acc: 0.9972\n",
      "EPOCH:   981 | BP | train loss: 0.0285 | test acc: 0.9972\n",
      "EPOCH:   982 | BP | train loss: 0.0284 | test acc: 0.9972\n",
      "EPOCH:   983 | BP | train loss: 0.0283 | test acc: 0.9972\n",
      "EPOCH:   984 | BP | train loss: 0.0283 | test acc: 0.9972\n",
      "EPOCH:   985 | BP | train loss: 0.0282 | test acc: 0.9972\n",
      "EPOCH:   986 | BP | train loss: 0.0282 | test acc: 0.9972\n",
      "EPOCH:   987 | BP | train loss: 0.0281 | test acc: 0.9972\n",
      "EPOCH:   988 | BP | train loss: 0.0281 | test acc: 0.9972\n",
      "EPOCH:   989 | BP | train loss: 0.0280 | test acc: 0.9972\n",
      "EPOCH:   990 | BP | train loss: 0.0280 | test acc: 0.9972\n",
      "EPOCH:   991 | BP | train loss: 0.0279 | test acc: 0.9972\n",
      "EPOCH:   992 | BP | train loss: 0.0279 | test acc: 0.9972\n",
      "EPOCH:   993 | BP | train loss: 0.0278 | test acc: 0.9972\n",
      "EPOCH:   994 | BP | train loss: 0.0278 | test acc: 0.9972\n",
      "EPOCH:   995 | BP | train loss: 0.0277 | test acc: 0.9972\n",
      "EPOCH:   996 | BP | train loss: 0.0277 | test acc: 0.9972\n",
      "EPOCH:   997 | BP | train loss: 0.0276 | test acc: 0.9972\n",
      "EPOCH:   998 | BP | train loss: 0.0276 | test acc: 0.9972\n",
      "EPOCH:   999 | BP | train loss: 0.0275 | test acc: 0.9972\n",
      "EPOCH:  1000 | BP | train loss: 0.0275 | test acc: 0.9972\n",
      "==================== finish training ====================\n",
      "  training time: 27.14 s\n",
      "  reach best train loss 0.0275 at epoch 1000\n",
      "  reach best test acc 0.9972 at epoch 964\n",
      "  reach 0.96 acc in 8.01 s\n",
      "  reach 0.98 acc in 13.54 s\n"
     ]
    }
   ],
   "source": [
    "# training example\n",
    "run_toy_example('digits', [7], model='64-129-10', train=True, analysis=True,\n",
    "                record_weight=True, save_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> example of the learning curves of the weights of BP and CBP \n",
    "![cbp](results/toy/digits/64-129-10/BP_CE_relu_initNone_seed7/fc1_weight.png)\n",
    "![cbp](results/toy/digits/64-129-10/CBP_CE_relu_initNone_seed7/fc1_weight.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> example of the learning curves of the loss anc acc of BP and CBP \n",
    "![cbp](results/toy/digits/64-129-10/BP_CE_relu_initNone_seed7/loss_acc.png)\n",
    "![cbp](results/toy/digits/64-129-10/CBP_CE_relu_initNone_seed7/loss_acc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def analysis_all_results(name, models):\n",
    "    save_prefix = f'results/toy/{name}/'\n",
    "    results = []\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for model in models:\n",
    "        dir = f'{save_prefix}{model}/'\n",
    "        results.append(pd.read_csv(dir + 'results.txt'))\n",
    "        train_loss.append(np.loadtxt(dir + 'loss.txt'))\n",
    "        train_acc.append(np.loadtxt(dir + 'acc.txt'))\n",
    "    df = pd.concat(results)\n",
    "    df.to_csv(f'{save_prefix}results.txt', sep=',', index=False)\n",
    "    sum_df = utils.results_summary(df, acc_train=True)\n",
    "    sum_df.to_csv(f'{save_prefix}results_summary.txt', sep=',', index=False)\n",
    "\n",
    "    n_line = train_loss[0].shape[1] // 2\n",
    "    n_model = len(models)\n",
    "    new_index = utils.generate_exchange_index(n_line, n_model)\n",
    "\n",
    "    train_loss = np.hstack(train_loss)[:, new_index]\n",
    "    train_acc = np.hstack(train_acc)[:, new_index]\n",
    "    np.savetxt(f'{save_prefix}loss.txt', train_loss)\n",
    "    np.savetxt(f'{save_prefix}acc.txt', train_acc)\n",
    "\n",
    "\n",
    "\n",
    "def plot_all_results(name,\n",
    "                     acc1,\n",
    "                     acc2,\n",
    "                     loss_lim=None,\n",
    "                     acc_lim=None,\n",
    "                     point=True,\n",
    "                     alpha=.8):\n",
    "    save_prefix = f'results/toy/{name}/'\n",
    "    df = pd.read_csv(f'{save_prefix}results.txt')\n",
    "    \n",
    "    figsize = (5, 6)\n",
    "    ylabels = ['minimal loss', 'maximal accuracy']\n",
    "    plot.plot_compare_loss_acc(df, save_prefix=save_prefix, point=point, acc_train=True, ylabels=ylabels)\n",
    "    plot.plot_compare_mul_loss_acc(df, save_prefix=save_prefix, point=point, acc_train=True,\n",
    "                                   xticks_rotation=30, figsize=figsize, despine_all=True, ylabels=ylabels)\n",
    "    if loss_lim is not None and acc_lim is not None:\n",
    "        plot.plot_compare_loss_acc(df, save_prefix=save_prefix, loss_lim=loss_lim,\n",
    "                                   acc_lim=acc_lim,point=point, acc_train=True, ylabels=ylabels)\n",
    "        plot.plot_compare_mul_loss_acc(df, save_prefix=save_prefix, loss_lim=loss_lim,\n",
    "                                       acc_lim=acc_lim, point=False, acc_train=True, legend=False,                           \n",
    "                                       xticks_rotation=30, figsize=figsize, despine_all=True, \n",
    "                                       ylabels=ylabels, dpi=300, ax1_xticks=True)\n",
    "\n",
    "    train_loss = np.loadtxt(f'{save_prefix}loss.txt')\n",
    "    train_acc = np.loadtxt(f'{save_prefix}acc.txt')\n",
    "    plot.plot_mul_loss_acc(train_loss, train_acc, save_prefix=save_prefix,\n",
    "                           acc1=acc1, acc2=acc2, alpha=alpha, acc_train=True)\n",
    "    plot.plot_mul_loss_acc(train_loss, train_acc, save_prefix=save_prefix,\n",
    "                           acc1=acc1, acc2=acc2, loss_lim=loss_lim,\n",
    "                           acc_lim=acc_lim, alpha=alpha, acc_train=True)\n",
    "\n",
    "\n",
    "def analysis_all_times(name, models):\n",
    "    save_prefix = f'results/toy/{name}/'\n",
    "    time_records = []\n",
    "    for model in models:\n",
    "        dir = f'{save_prefix}{model}/'\n",
    "        time_records.append(pd.read_csv(dir + 'times.txt'))\n",
    "    df = pd.concat(time_records)\n",
    "    df.to_csv(f'{save_prefix}times.txt', sep=',', index=False)\n",
    "    sum_df = utils.times_summary(df)\n",
    "    sum_df.to_csv(f'{save_prefix}times_summary.txt', sep=',', index=False)\n",
    "\n",
    "\n",
    "def plot_all_times(name, acc1, acc2, max_y=None):\n",
    "    save_prefix = f'results/toy/{name}/'\n",
    "    df = pd.read_csv(f'{save_prefix}times.txt')\n",
    "    plot.plot_train_time(df, acc1=acc1, acc2=acc2, max_y=max_y, save_prefix=save_prefix,\n",
    "                         dpi=300, figsize=(4.5, 4.5), despine_all=True, xlim=[-0.7, 1.7])\n",
    "\n",
    "\n",
    "def analysis_all(name, models):\n",
    "    analysis_all_results(name, models=models)\n",
    "    analysis_all_times(name, models=models)\n",
    "\n",
    "\n",
    "def plot_all(name, acc1, acc2, max_y, loss_lim, acc_lim):\n",
    "    plot_all_results(name, acc1=acc1, acc2=acc2, loss_lim=loss_lim, acc_lim=acc_lim)\n",
    "    plot_all_times(name, acc1=acc1, acc2=acc2, max_y=max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_default_models():\n",
    "    default_models = {\n",
    "        'iris': [f'4-{mid}-3' for mid in [3, 5, 7, 9, 11, 13, 15]],\n",
    "        'wine': [f'13-{mid}-3' for mid in [12, 17, 22, 27, 32, 37, 42]],\n",
    "        'blood': [f'4-{mid}-2' for mid in [3, 5, 7, 9, 11, 13, 15]],\n",
    "        'breast': [f'8-{mid}-2' for mid in [8, 11, 14, 17, 20, 23, 26]],\n",
    "        'titanic': [f'3-{mid}-2' for mid in [4, 5, 6, 7, 8, 9, 10]],\n",
    "        'twonorm': [f'20-{mid}-2' for mid in [20, 27, 34, 41, 48, 55, 62]],\n",
    "        'digits': [f'64-{mid}-10' for mid in [63, 85, 107, 129, 151, 173, 195]]\n",
    "    }\n",
    "    return default_models\n",
    "\n",
    "def main_toy(name, models, seeds=range(10), train=True, analysis=True, plot=True):\n",
    "    for model in models:\n",
    "        run_toy_example(name, seeds, model=model, train=train, analysis=analysis)\n",
    "    if analysis:\n",
    "        analysis_all(name, models)\n",
    "    if plot:\n",
    "        acc1, acc2, loss_lim, acc_lim, max_y = get_default_plot_params(name)\n",
    "        plot_all(name, acc1, acc2, max_y, loss_lim, acc_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main traning cell\n",
    "# may take several hours\n",
    "for name in ['iris', 'wine', 'breast', 'blood', 'digits', 'titanic', 'twonorm']:\n",
    "    models = get_default_models()[name]\n",
    "    main_toy(name, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_results_pvalue():\n",
    "    names = ['iris', 'wine', 'breast', 'blood', 'digits', 'titanic', 'twonorm']\n",
    "    n_name = len(names)\n",
    "    n_models = 7\n",
    "\n",
    "    loss_pv_mat = np.zeros((n_name, n_models + 1))\n",
    "    acc_pv_mat = np.zeros((n_name, n_models + 1))\n",
    "    for i, name in enumerate(names):\n",
    "        models = get_default_models()[name]\n",
    "        for j, model in enumerate(models):\n",
    "            dir = f'results/toy/{name}/{model}'\n",
    "            df = pd.read_csv(f'{dir}/results_summary.txt')\n",
    "            loss_pv_mat[i, j] = float(df.loc[0, 'loss_pvalue'])\n",
    "            acc_pv_mat[i, j] = float(df.loc[0, 'acc_pvalue'])\n",
    "        dir = f'results/toy/{name}'\n",
    "        df = pd.read_csv(f'{dir}/results_summary.txt')\n",
    "        loss_pv_mat[i, j+1] = float(df.loc[0, 'loss_pvalue'])\n",
    "        acc_pv_mat[i, j+1] = float(df.loc[0, 'acc_pvalue'])\n",
    "    loss_pv_df = pd.DataFrame(loss_pv_mat,\n",
    "                              columns=[f'model{i+1}' for i in range(n_models)] + ['all'],\n",
    "                              index=names)\n",
    "    acc_pv_df = pd.DataFrame(acc_pv_mat,\n",
    "                             columns=[f'model{i+1}' for i in range(n_models)] + ['all'],\n",
    "                             index=names)\n",
    "    loss_pv_df.to_csv('results/toy/train_loss_pvalue.txt')\n",
    "    acc_pv_df.to_csv('results/toy/train_acc_pvalue.txt')\n",
    "    return loss_pv_df, acc_pv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               model1        model2        model3        model4        model5  \\\n",
       " iris     1.580681e-01  1.482960e-01  5.680898e-05  1.942869e-06  3.545454e-11   \n",
       " wine     1.671029e-02  6.862499e-04  1.701239e-06  4.336415e-09  7.603193e-08   \n",
       " breast   9.975213e-01  8.452423e-01  9.675660e-01  1.547342e-01  1.453511e-01   \n",
       " blood    2.400969e-02  1.719567e-03  2.574702e-07  9.938518e-06  2.703999e-10   \n",
       " digits   7.420166e-15  1.224163e-12  3.458232e-14  9.540099e-16  3.404791e-13   \n",
       " titanic  3.124929e-01  3.868818e-01  6.509635e-03  4.677793e-06  3.380401e-03   \n",
       " twonorm  1.956837e-11  2.230210e-13  5.772613e-12  3.088057e-15  1.650982e-18   \n",
       " \n",
       "                model6        model7           all  \n",
       " iris     1.073695e-01  8.421600e-07  2.410833e-02  \n",
       " wine     1.348742e-11  6.602090e-13  8.575895e-23  \n",
       " breast   7.096439e-02  6.223313e-01  7.758360e-01  \n",
       " blood    3.501880e-12  6.561362e-13  1.152513e-06  \n",
       " digits   1.057586e-11  3.385822e-16  9.483743e-84  \n",
       " titanic  6.155285e-02  8.819558e-02  1.125458e-04  \n",
       " twonorm  2.955273e-15  4.590043e-14  2.030318e-76  ,\n",
       "                model1        model2        model3        model4        model5  \\\n",
       " iris     1.574126e-01  1.513426e-01  5.772934e-04  1.304565e-07  3.705747e-11   \n",
       " wine     5.000000e-01  5.000000e-01  5.000000e-01  5.000000e-01  5.000000e-01   \n",
       " breast   4.989047e-09  2.680273e-11  3.572801e-06  2.202139e-08  3.380109e-08   \n",
       " blood    9.076023e-03  4.540589e-03  9.087519e-10  6.404028e-07  5.927729e-10   \n",
       " digits   4.303621e-10  5.053564e-13  1.961302e-14  1.828220e-12  6.119086e-11   \n",
       " titanic  1.002167e-01  5.384492e-01  2.467163e-03  5.084308e-04  2.557334e-03   \n",
       " twonorm  5.847099e-05  3.389136e-05  6.162222e-05  9.410970e-06  5.436381e-07   \n",
       " \n",
       "                model6        model7           all  \n",
       " iris     2.007110e-02  1.304565e-07  2.393288e-02  \n",
       " wine     5.000000e-01  5.000000e-01  5.000000e-01  \n",
       " breast   3.778373e-08  2.382934e-10  5.864472e-50  \n",
       " blood    4.418306e-10  4.062703e-09  5.587983e-28  \n",
       " digits   1.058943e-14  6.469438e-16  2.662770e-68  \n",
       " titanic  1.813125e-02  5.800964e-02  1.617194e-07  \n",
       " twonorm  6.541726e-06  3.155161e-03  1.301292e-19  )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results_pvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loss = pd.read_csv(f'results/toy/train_loss_pvalue.txt', index_col=0)\n",
    "df_acc = pd.read_csv(f'results/toy/train_acc_pvalue.txt', index_col=0)\n",
    "pv_lists = []\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        pv_lists.append([df_loss.index[i], df_loss.columns[j], 'loss', df_loss.iloc[i, j]])\n",
    "        pv_lists.append([df_acc.index[i], df_acc.columns[j], 'acc', df_acc.iloc[i, j]])\n",
    "pv_df = pd.DataFrame(pv_lists, columns=['dataset', 'model', 'metric', 'p-value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 795.975x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.catplot(x='dataset', y='p-value', hue='model', kind='bar', \n",
    "                col='metric', data=pv_df, palette='rocket_r',\n",
    "                legend_out=True, height=5, aspect=1)\n",
    "g.fig.subplots_adjust(wspace=0.2, bottom=0.2)\n",
    "titles = ['significance of CBP better than BP (minimal loss)', \n",
    "          'significance of CBP better than BP (maximal accuracy)']\n",
    "g.set(yscale='log').despine(left=True, bottom=True)\n",
    "for i in range(2):\n",
    "    ax = g.axes[0, i]\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "    ax.set_title(titles[i])\n",
    "    for p in [0.05, 0.01, 0.001]:\n",
    "        ax.axhline(y=p, ls='--', c='grey')\n",
    "g.fig.savefig('results/toy/all_pvalue_barplot.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_pvalue_hetmap(loss_pv_df, acc_pv_df, save=True):\n",
    "    c = mpl.cm.get_cmap('Reds', 256)\n",
    "    colors = c(np.linspace(0, 1, 256))\n",
    "    newcolors = colors[::70, :][::-1]\n",
    "    cmap = mpl.colors.ListedColormap(newcolors)\n",
    "    bounds = [1e-4, 0.001, 0.01, 0.05, 0.1]\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N, clip=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "    sns.heatmap(loss_pv_df, vmin=0, vmax=1, norm=norm, cmap=cmap,\n",
    "                cbar_kws={'label': 'p value', 'extend': 'both',\n",
    "                          'format': '%.0e'}, linewidths=2)\n",
    "    ax.set_title('significance of CBP better than BP (minimal loss)')\n",
    "    ax.tick_params(labelrotation=45)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(f'results/toy/train_loss_pvalue.png', dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # acc_pv_df.fillna(.5, inplace=True)\n",
    "    fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "    sns.heatmap(acc_pv_df, vmin=0, vmax=1, norm=norm, cmap=cmap,\n",
    "                cbar_kws={'label': 'p value', 'extend': 'both',\n",
    "                          'format': '%.0e'}, linewidths=2)\n",
    "    ax.set_title('significance of CBP better than BP (maximal accuracy)')\n",
    "    ax.tick_params(labelrotation=45)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(f'results/toy/train_acc_pvalue.png', dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_pvalue_hetmap(df_loss, df_acc, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pvalue(pv_list, ref_pv_list=[0.05, 0.01, 0.001]):\n",
    "    pv_mat = np.array(pv_list)\n",
    "    counts = [len(pv_mat)]\n",
    "    for i, p in enumerate(ref_pv_list):\n",
    "        counts.append(len(pv_mat[pv_mat <= p]))\n",
    "    for i in range(len(ref_pv_list)):\n",
    "        counts[i] = counts[i] - counts[i+1]\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_pv = pv_df[pv_df.metric=='loss'].loc[:,'p-value']\n",
    "loss_sizes = count_pvalue(loss_pv)\n",
    "acc_pv = pv_df[pv_df.metric=='acc'].loc[:,'p-value']\n",
    "acc_sizes = count_pvalue(acc_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_both_pvalue(pv_list1, pv_list2, ref_pv_list=[0.05, 0.01, 0.001]):\n",
    "    counts_and = [len(pv_list1)]\n",
    "    counts_or = [len(pv_list1)]\n",
    "    for i, p in enumerate(ref_pv_list):\n",
    "        n1 = 0\n",
    "        n2 = 0\n",
    "        for p1, p2 in zip(pv_list1, pv_list2):\n",
    "            if p1 <= p and p2 <= p:\n",
    "                n1 += 1\n",
    "            if p1 <= p or p2 <= p:\n",
    "                n2 += 1\n",
    "        counts_and.append(n1)\n",
    "        counts_or.append(n2)\n",
    "    for i in range(len(ref_pv_list)):\n",
    "        counts_and[i] = counts_and[i] - counts_and[i+1]\n",
    "        counts_or[i] = counts_or[i] - counts_or[i+1]\n",
    "    return counts_and, counts_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_and, sizes_or = count_both_pvalue(loss_pv, acc_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x252 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explode = (0., 0., 0., 0.)\n",
    "labels = [r'p > 0.05 (-)',\n",
    "          r'0.05 $\\geqslant$ p > 0.01 (*)',\n",
    "          r'0.01 $\\geqslant$ p > 0.001 (**)',\n",
    "          r'0.001 $\\geqslant$ p (***)']\n",
    "titles = ['minimal loss', 'maximal accuracy', 'one of them']\n",
    "mycs = sns.color_palette('Blues', 9)[:4]\n",
    "\n",
    "in_labels=['-', '*', '**', '***']\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 3.5))\n",
    "ax[0].pie(loss_sizes, explode=explode, labels=loss_sizes, startangle=90, colors=mycs)\n",
    "ax[0].pie(loss_sizes, labels=in_labels, labeldistance=0.6, startangle=90,\n",
    "          colors=mycs, rotatelabels=True)\n",
    "wedges, _ = ax[1].pie(acc_sizes, explode=explode, labels=acc_sizes, startangle=90,\n",
    "                      colors=mycs)\n",
    "ax[1].pie(acc_sizes, labels=in_labels, labeldistance=0.6, startangle=90,\n",
    "          colors=mycs, rotatelabels=True)\n",
    "ax[2].pie(sizes_or, explode=explode, labels=sizes_or, startangle=90, colors=mycs)\n",
    "ax[2].pie(sizes_or, labels=in_labels, labeldistance=0.6, startangle=90,\n",
    "          colors=mycs, rotatelabels=True)\n",
    "for i in range(3):\n",
    "    ax[i].axis('equal')\n",
    "    ax[i].set_title(titles[i], fontsize=12, pad=-20)\n",
    "ax[1].legend(wedges, labels, title='significance level', loc='center',\n",
    "             bbox_to_anchor=(-.25, -.05, 1.5, 0.05), ncol=4, fontsize=10,\n",
    "             markerscale=1, title_fontsize=10, handlelength=1.5)\n",
    "fig.subplots_adjust(bottom=0.1, top=0.9, wspace=.3)\n",
    "fig.suptitle('the number of results where CBP is significantly better than BP in hypothesis test', fontsize=13)\n",
    "fig.savefig('results/toy/all_pvalue_pie.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
